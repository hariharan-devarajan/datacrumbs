
        #include <linux/sched.h>
        #include <uapi/linux/limits.h>
        #include <uapi/linux/ptrace.h>
        
        struct fn_key_t {
            u64 ip;
            s64 pid;
        };
        struct fn_t {
            u64 ts;
        };
        struct file_t {
          u64 id;
          int fd;  
        };
        struct filename_t {
            char fname[256];
        };
        
        BPF_HASH(pid_map, u32, u64); // map for apps to collect data
        BPF_HASH(fn_pid_map, struct fn_key_t, struct fn_t); // collect start time and ip for apps
        BPF_HASH(file_hash, u64, struct filename_t, 10240);
        BPF_HASH(latest_hash, struct fn_key_t, u64);
        BPF_HASH(latest_fd, u64, int);
        BPF_HASH(fd_hash, struct file_t, u64);
        BPF_HASH(pid_hash, u64, u64);
        
            BPF_RINGBUF_OUTPUT(events, 1 << 16); // emit events to python
            
        static u64 get_hash(unsigned char *str, u64 len) {
            u64 hash = 5381;
            int c = *str;
            int count = 0;
            while (count < len && c) {
                hash = ((hash << 5) + hash) + c; /* hash * 33 + c */
                c = *str++;
                count++;
            }
            return hash;
        }
        /*static u64 get_hash(u64 id) {
            u64 first_hash = 1;
            u64* hash_value = pid_hash.lookup_or_init(&id, &first_hash);
            (*hash_value)++;
            return *hash_value;
        }*/
        
        int trace_datacrumbs_start(struct pt_regs *ctx) {
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = 0;
            u64* start_ts = pid_map.lookup(&pid);
            u64 tsp = bpf_ktime_get_ns();
            if (start_ts != 0)                                      
                tsp = *start_ts;
            else
                pid_map.update(&pid, &tsp);
            pid = id;
            bpf_trace_printk("Tracing PID \%d",pid);
            pid_map.update(&pid, &tsp);
            return 0;
        }
        int trace_datacrumbs_stop(struct pt_regs *ctx) {
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            bpf_trace_printk("Stop tracing PID \%d",pid);
            pid_map.delete(&pid);
            return 0;
        }
        
        
            struct sys_openat_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            
        };
        
        int syscall__trace_entry_openat(struct pt_regs *ctx , int dfd, const char *filename, int flags) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 1;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        struct filename_t fname_i;
                        u64 filename_len = sizeof(fname_i.fname);
                        int len = bpf_probe_read_user_str(&fname_i.fname, filename_len, filename);
                        //fname_i.fname[len-1] = '\0';
                        u64 filehash = get_hash(fname_i.fname, filename_len);
                        bpf_trace_printk("Hash value is %d for filename \%s",filehash,filename);
                        file_hash.update(&filehash, &fname_i);
                        latest_hash.update(&key, &filehash);
                           
            return 0;
        }

        int sys__trace_exit_openat(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 1;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_openat_event_t stats_key_v = {};
            struct sys_openat_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 1;
            stats_key->ip = 1;
        
            
                        u64* hash_ptr = latest_hash.lookup(&key);
                        if (hash_ptr != 0) {
                            stats_key->file_hash = *hash_ptr; 
                        }
                        
                        
            struct sys_openat_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
                        if (hash_ptr != 0) {
                            int fd = PT_REGS_RC(ctx);
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = fd;
                            fd_hash.update(&file_key, hash_ptr);
                        }
                        
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_openat_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_read_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            u64 size_sum;
        };
        
        int syscall__trace_entry_read(struct pt_regs *ctx 
                        , int fd, void *data, u64 count
                        ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 2;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        latest_fd.update(&id,&fd);
                           
            return 0;
        }

        int sys__trace_exit_read(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 2;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_read_event_t stats_key_v = {};
            struct sys_read_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 2;
            stats_key->ip = 2;
        
            
                        int* fd_ptr = latest_fd.lookup(&id);
                        if (fd_ptr != 0 ) {
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = *fd_ptr;
                            u64* hash_ptr = fd_hash.lookup(&file_key);
                            if (hash_ptr != 0) {
                                stats_key->file_hash = *hash_ptr; 
                            }
                        }
                        
                        
            struct sys_read_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
                                 stats->size_sum += PT_REGS_RC(ctx);
                                 
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_read_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_write_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            u64 size_sum;
        };
        
        int syscall__trace_entry_write(struct pt_regs *ctx 
                        , int fd, const void *data, u64 count
                        ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 3;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        latest_fd.update(&id,&fd);
                           
            return 0;
        }

        int sys__trace_exit_write(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 3;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_write_event_t stats_key_v = {};
            struct sys_write_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 3;
            stats_key->ip = 3;
        
            
                        int* fd_ptr = latest_fd.lookup(&id);
                        if (fd_ptr != 0 ) {
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = *fd_ptr;
                            u64* hash_ptr = fd_hash.lookup(&file_key);
                            if (hash_ptr != 0) {
                                stats_key->file_hash = *hash_ptr; 
                            }
                        }
                        
                        
            struct sys_write_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
                                 stats->size_sum += PT_REGS_RC(ctx);
                                 
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_write_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_close_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            
        };
        
        int syscall__trace_entry_close(struct pt_regs *ctx 
                        , int fd
                        ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 4;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        latest_fd.update(&id,&fd);
                           
            return 0;
        }

        int sys__trace_exit_close(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 4;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_close_event_t stats_key_v = {};
            struct sys_close_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 4;
            stats_key->ip = 4;
        
            
                        int* fd_ptr = latest_fd.lookup(&id);
                        if (fd_ptr != 0 ) {
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = *fd_ptr;
                            u64* hash_ptr = fd_hash.lookup(&file_key);
                            if (hash_ptr != 0) {
                                stats_key->file_hash = *hash_ptr; 
                            }
                        }
                        
                        
            struct sys_close_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_close_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_copy_file_range_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_copy_file_range(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 5;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_copy_file_range(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 5;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_copy_file_range_event_t stats_key_v = {};
            struct sys_copy_file_range_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 5;
            stats_key->ip = 5;
        
            
                        
            struct sys_copy_file_range_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_copy_file_range_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_execve_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_execve(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 6;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_execve(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 6;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_execve_event_t stats_key_v = {};
            struct sys_execve_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 6;
            stats_key->ip = 6;
        
            
                        
            struct sys_execve_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_execve_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_execveat_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_execveat(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 7;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_execveat(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 7;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_execveat_event_t stats_key_v = {};
            struct sys_execveat_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 7;
            stats_key->ip = 7;
        
            
                        
            struct sys_execveat_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_execveat_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_exit_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_exit(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 8;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 8;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_exit_event_t stats_key_v = {};
            struct sys_exit_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 8;
            stats_key->ip = 8;
        
            
                        
            struct sys_exit_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_exit_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_faccessat_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_faccessat(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 9;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_faccessat(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 9;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_faccessat_event_t stats_key_v = {};
            struct sys_faccessat_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 9;
            stats_key->ip = 9;
        
            
                        
            struct sys_faccessat_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_faccessat_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_fcntl_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_fcntl(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 10;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_fcntl(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 10;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_fcntl_event_t stats_key_v = {};
            struct sys_fcntl_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 10;
            stats_key->ip = 10;
        
            
                        
            struct sys_fcntl_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_fcntl_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_fallocate_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            
        };
        
        int syscall__trace_entry_fallocate(struct pt_regs *ctx 
                        , int fd, int mode, int offset, int len
                        ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 11;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        latest_fd.update(&id,&fd);
                           
            return 0;
        }

        int sys__trace_exit_fallocate(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 11;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_fallocate_event_t stats_key_v = {};
            struct sys_fallocate_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 11;
            stats_key->ip = 11;
        
            
                        int* fd_ptr = latest_fd.lookup(&id);
                        if (fd_ptr != 0 ) {
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = *fd_ptr;
                            u64* hash_ptr = fd_hash.lookup(&file_key);
                            if (hash_ptr != 0) {
                                stats_key->file_hash = *hash_ptr; 
                            }
                        }
                        
                        
            struct sys_fallocate_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_fallocate_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_fdatasync_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            
        };
        
        int syscall__trace_entry_fdatasync(struct pt_regs *ctx 
                        , int fd
                        ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 12;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        latest_fd.update(&id,&fd);
                           
            return 0;
        }

        int sys__trace_exit_fdatasync(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 12;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_fdatasync_event_t stats_key_v = {};
            struct sys_fdatasync_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 12;
            stats_key->ip = 12;
        
            
                        int* fd_ptr = latest_fd.lookup(&id);
                        if (fd_ptr != 0 ) {
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = *fd_ptr;
                            u64* hash_ptr = fd_hash.lookup(&file_key);
                            if (hash_ptr != 0) {
                                stats_key->file_hash = *hash_ptr; 
                            }
                        }
                        
                        
            struct sys_fdatasync_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_fdatasync_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_flock_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            
        };
        
        int syscall__trace_entry_flock(struct pt_regs *ctx 
                        , int fd, int cmd
                        ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 13;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        latest_fd.update(&id,&fd);
                           
            return 0;
        }

        int sys__trace_exit_flock(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 13;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_flock_event_t stats_key_v = {};
            struct sys_flock_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 13;
            stats_key->ip = 13;
        
            
                        int* fd_ptr = latest_fd.lookup(&id);
                        if (fd_ptr != 0 ) {
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = *fd_ptr;
                            u64* hash_ptr = fd_hash.lookup(&file_key);
                            if (hash_ptr != 0) {
                                stats_key->file_hash = *hash_ptr; 
                            }
                        }
                        
                        
            struct sys_flock_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_flock_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_fsopen_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_fsopen(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 14;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_fsopen(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 14;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_fsopen_event_t stats_key_v = {};
            struct sys_fsopen_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 14;
            stats_key->ip = 14;
        
            
                        
            struct sys_fsopen_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_fsopen_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_fstatfs_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_fstatfs(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 15;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_fstatfs(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 15;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_fstatfs_event_t stats_key_v = {};
            struct sys_fstatfs_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 15;
            stats_key->ip = 15;
        
            
                        
            struct sys_fstatfs_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_fstatfs_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_fsync_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            
        };
        
        int syscall__trace_entry_fsync(struct pt_regs *ctx 
                        , int fd
                        ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 16;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        latest_fd.update(&id,&fd);
                           
            return 0;
        }

        int sys__trace_exit_fsync(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 16;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_fsync_event_t stats_key_v = {};
            struct sys_fsync_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 16;
            stats_key->ip = 16;
        
            
                        int* fd_ptr = latest_fd.lookup(&id);
                        if (fd_ptr != 0 ) {
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = *fd_ptr;
                            u64* hash_ptr = fd_hash.lookup(&file_key);
                            if (hash_ptr != 0) {
                                stats_key->file_hash = *hash_ptr; 
                            }
                        }
                        
                        
            struct sys_fsync_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_fsync_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_ftruncate_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            
        };
        
        int syscall__trace_entry_ftruncate(struct pt_regs *ctx 
                        , int fd, int length
                        ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 17;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        latest_fd.update(&id,&fd);
                           
            return 0;
        }

        int sys__trace_exit_ftruncate(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 17;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_ftruncate_event_t stats_key_v = {};
            struct sys_ftruncate_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 17;
            stats_key->ip = 17;
        
            
                        int* fd_ptr = latest_fd.lookup(&id);
                        if (fd_ptr != 0 ) {
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = *fd_ptr;
                            u64* hash_ptr = fd_hash.lookup(&file_key);
                            if (hash_ptr != 0) {
                                stats_key->file_hash = *hash_ptr; 
                            }
                        }
                        
                        
            struct sys_ftruncate_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_ftruncate_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_io_pgetevents_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_io_pgetevents(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 18;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_io_pgetevents(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 18;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_io_pgetevents_event_t stats_key_v = {};
            struct sys_io_pgetevents_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 18;
            stats_key->ip = 18;
        
            
                        
            struct sys_io_pgetevents_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_io_pgetevents_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_lseek_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            
        };
        
        int syscall__trace_entry_lseek(struct pt_regs *ctx 
                        , int fd, int offset, int whence
                        ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 19;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        latest_fd.update(&id,&fd);
                           
            return 0;
        }

        int sys__trace_exit_lseek(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 19;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_lseek_event_t stats_key_v = {};
            struct sys_lseek_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 19;
            stats_key->ip = 19;
        
            
                        int* fd_ptr = latest_fd.lookup(&id);
                        if (fd_ptr != 0 ) {
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = *fd_ptr;
                            u64* hash_ptr = fd_hash.lookup(&file_key);
                            if (hash_ptr != 0) {
                                stats_key->file_hash = *hash_ptr; 
                            }
                        }
                        
                        
            struct sys_lseek_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_lseek_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_memfd_create_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_memfd_create(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 20;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_memfd_create(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 20;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_memfd_create_event_t stats_key_v = {};
            struct sys_memfd_create_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 20;
            stats_key->ip = 20;
        
            
                        
            struct sys_memfd_create_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_memfd_create_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_migrate_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_migrate_pages(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 21;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_migrate_pages(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 21;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_migrate_pages_event_t stats_key_v = {};
            struct sys_migrate_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 21;
            stats_key->ip = 21;
        
            
                        
            struct sys_migrate_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_migrate_pages_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_mlock_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_mlock(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 22;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_mlock(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 22;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_mlock_event_t stats_key_v = {};
            struct sys_mlock_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 22;
            stats_key->ip = 22;
        
            
                        
            struct sys_mlock_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_mlock_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_mmap_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_mmap(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 23;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_mmap(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 23;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_mmap_event_t stats_key_v = {};
            struct sys_mmap_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 23;
            stats_key->ip = 23;
        
            
                        
            struct sys_mmap_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_mmap_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_msync_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_msync(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 24;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_msync(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 24;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_msync_event_t stats_key_v = {};
            struct sys_msync_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 24;
            stats_key->ip = 24;
        
            
                        
            struct sys_msync_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_msync_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_pread64_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            u64 size_sum;
        };
        
        int syscall__trace_entry_pread64(struct pt_regs *ctx 
                        , int fd, void *buf, u64 count, u64 pos
                        ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 25;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        latest_fd.update(&id,&fd);
                           
            return 0;
        }

        int sys__trace_exit_pread64(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 25;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_pread64_event_t stats_key_v = {};
            struct sys_pread64_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 25;
            stats_key->ip = 25;
        
            
                        int* fd_ptr = latest_fd.lookup(&id);
                        if (fd_ptr != 0 ) {
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = *fd_ptr;
                            u64* hash_ptr = fd_hash.lookup(&file_key);
                            if (hash_ptr != 0) {
                                stats_key->file_hash = *hash_ptr; 
                            }
                        }
                        
                        
            struct sys_pread64_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
                                 stats->size_sum += PT_REGS_RC(ctx);
                                 
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_pread64_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_preadv_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            u64 size_sum;
        };
        
        int syscall__trace_entry_preadv(struct pt_regs *ctx 
                        , int fd, u64 buf, u64 vlen, u64 pos_l, u64 pos_h
                        ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 26;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        latest_fd.update(&id,&fd);
                           
            return 0;
        }

        int sys__trace_exit_preadv(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 26;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_preadv_event_t stats_key_v = {};
            struct sys_preadv_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 26;
            stats_key->ip = 26;
        
            
                        int* fd_ptr = latest_fd.lookup(&id);
                        if (fd_ptr != 0 ) {
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = *fd_ptr;
                            u64* hash_ptr = fd_hash.lookup(&file_key);
                            if (hash_ptr != 0) {
                                stats_key->file_hash = *hash_ptr; 
                            }
                        }
                        
                        
            struct sys_preadv_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
                                 stats->size_sum += PT_REGS_RC(ctx);
                                 
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_preadv_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_preadv2_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            u64 size_sum;
        };
        
        int syscall__trace_entry_preadv2(struct pt_regs *ctx 
                        , int fd, u64 buf, u64 vlen, u64 pos_l, u64 pos_h, u64 flags
                        ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 27;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        latest_fd.update(&id,&fd);
                           
            return 0;
        }

        int sys__trace_exit_preadv2(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 27;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_preadv2_event_t stats_key_v = {};
            struct sys_preadv2_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 27;
            stats_key->ip = 27;
        
            
                        int* fd_ptr = latest_fd.lookup(&id);
                        if (fd_ptr != 0 ) {
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = *fd_ptr;
                            u64* hash_ptr = fd_hash.lookup(&file_key);
                            if (hash_ptr != 0) {
                                stats_key->file_hash = *hash_ptr; 
                            }
                        }
                        
                        
            struct sys_preadv2_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
                                 stats->size_sum += PT_REGS_RC(ctx);
                                 
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_preadv2_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_pwrite64_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            u64 size_sum;
        };
        
        int syscall__trace_entry_pwrite64(struct pt_regs *ctx 
                        , int fd, const void *data, u64 count, u64 pos
                        ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 28;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        latest_fd.update(&id,&fd);
                           
            return 0;
        }

        int sys__trace_exit_pwrite64(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 28;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_pwrite64_event_t stats_key_v = {};
            struct sys_pwrite64_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 28;
            stats_key->ip = 28;
        
            
                        int* fd_ptr = latest_fd.lookup(&id);
                        if (fd_ptr != 0 ) {
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = *fd_ptr;
                            u64* hash_ptr = fd_hash.lookup(&file_key);
                            if (hash_ptr != 0) {
                                stats_key->file_hash = *hash_ptr; 
                            }
                        }
                        
                        
            struct sys_pwrite64_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
                                 stats->size_sum += PT_REGS_RC(ctx);
                                 
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_pwrite64_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_pwritev_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            u64 size_sum;
        };
        
        int syscall__trace_entry_pwritev(struct pt_regs *ctx 
                        , int fd, u64 buf, u64 vlen, u64 pos_l, u64 pos_h
                        ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 29;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        latest_fd.update(&id,&fd);
                           
            return 0;
        }

        int sys__trace_exit_pwritev(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 29;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_pwritev_event_t stats_key_v = {};
            struct sys_pwritev_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 29;
            stats_key->ip = 29;
        
            
                        int* fd_ptr = latest_fd.lookup(&id);
                        if (fd_ptr != 0 ) {
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = *fd_ptr;
                            u64* hash_ptr = fd_hash.lookup(&file_key);
                            if (hash_ptr != 0) {
                                stats_key->file_hash = *hash_ptr; 
                            }
                        }
                        
                        
            struct sys_pwritev_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
                                 stats->size_sum += PT_REGS_RC(ctx);
                                 
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_pwritev_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_pwritev2_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            u64 size_sum;
        };
        
        int syscall__trace_entry_pwritev2(struct pt_regs *ctx 
                        , int fd, u64 buf, u64 vlen, u64 pos_l, u64 pos_h, u64 flags
                        ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 30;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        latest_fd.update(&id,&fd);
                           
            return 0;
        }

        int sys__trace_exit_pwritev2(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 30;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_pwritev2_event_t stats_key_v = {};
            struct sys_pwritev2_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 30;
            stats_key->ip = 30;
        
            
                        int* fd_ptr = latest_fd.lookup(&id);
                        if (fd_ptr != 0 ) {
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = *fd_ptr;
                            u64* hash_ptr = fd_hash.lookup(&file_key);
                            if (hash_ptr != 0) {
                                stats_key->file_hash = *hash_ptr; 
                            }
                        }
                        
                        
            struct sys_pwritev2_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
                                 stats->size_sum += PT_REGS_RC(ctx);
                                 
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_pwritev2_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_readahead_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            u64 size_sum;
        };
        
        int syscall__trace_entry_readahead(struct pt_regs *ctx 
                        , int fd, u64 offset, u64 count
                        ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 31;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        latest_fd.update(&id,&fd);
                           
            return 0;
        }

        int sys__trace_exit_readahead(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 31;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_readahead_event_t stats_key_v = {};
            struct sys_readahead_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 31;
            stats_key->ip = 31;
        
            
                        int* fd_ptr = latest_fd.lookup(&id);
                        if (fd_ptr != 0 ) {
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = *fd_ptr;
                            u64* hash_ptr = fd_hash.lookup(&file_key);
                            if (hash_ptr != 0) {
                                stats_key->file_hash = *hash_ptr; 
                            }
                        }
                        
                        
            struct sys_readahead_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
                                 stats->size_sum += PT_REGS_RC(ctx);
                                 
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_readahead_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_readlinkat_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_readlinkat(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 32;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_readlinkat(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 32;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_readlinkat_event_t stats_key_v = {};
            struct sys_readlinkat_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 32;
            stats_key->ip = 32;
        
            
                        
            struct sys_readlinkat_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_readlinkat_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_readv_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            u64 size_sum;
        };
        
        int syscall__trace_entry_readv(struct pt_regs *ctx 
                        , int fd, u64 vec, u64 vlen
                        ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 33;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        latest_fd.update(&id,&fd);
                           
            return 0;
        }

        int sys__trace_exit_readv(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 33;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_readv_event_t stats_key_v = {};
            struct sys_readv_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 33;
            stats_key->ip = 33;
        
            
                        int* fd_ptr = latest_fd.lookup(&id);
                        if (fd_ptr != 0 ) {
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = *fd_ptr;
                            u64* hash_ptr = fd_hash.lookup(&file_key);
                            if (hash_ptr != 0) {
                                stats_key->file_hash = *hash_ptr; 
                            }
                        }
                        
                        
            struct sys_readv_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
                                 stats->size_sum += PT_REGS_RC(ctx);
                                 
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_readv_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_renameat_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_renameat(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 34;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_renameat(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 34;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_renameat_event_t stats_key_v = {};
            struct sys_renameat_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 34;
            stats_key->ip = 34;
        
            
                        
            struct sys_renameat_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_renameat_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_renameat2_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_renameat2(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 35;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_renameat2(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 35;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_renameat2_event_t stats_key_v = {};
            struct sys_renameat2_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 35;
            stats_key->ip = 35;
        
            
                        
            struct sys_renameat2_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_renameat2_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_statfs_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_statfs(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 36;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_statfs(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 36;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_statfs_event_t stats_key_v = {};
            struct sys_statfs_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 36;
            stats_key->ip = 36;
        
            
                        
            struct sys_statfs_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_statfs_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_statx_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_statx(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 37;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_statx(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 37;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_statx_event_t stats_key_v = {};
            struct sys_statx_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 37;
            stats_key->ip = 37;
        
            
                        
            struct sys_statx_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_statx_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_sync_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_sync(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 38;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_sync(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 38;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_sync_event_t stats_key_v = {};
            struct sys_sync_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 38;
            stats_key->ip = 38;
        
            
                        
            struct sys_sync_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_sync_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_sync_file_range_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_sync_file_range(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 39;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_sync_file_range(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 39;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_sync_file_range_event_t stats_key_v = {};
            struct sys_sync_file_range_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 39;
            stats_key->ip = 39;
        
            
                        
            struct sys_sync_file_range_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_sync_file_range_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_syncfs_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        int syscall__trace_entry_syncfs(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 40;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
               
            return 0;
        }

        int sys__trace_exit_syncfs(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 40;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_syncfs_event_t stats_key_v = {};
            struct sys_syncfs_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 40;
            stats_key->ip = 40;
        
            
                        
            struct sys_syncfs_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_syncfs_event_t), 0);
            
            
        
            return 0;
        }
        
        
            struct sys_writev_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            u64 file_hash;
            u64 size_sum;
        };
        
        int syscall__trace_entry_writev(struct pt_regs *ctx 
                        , int fd, u64 vec, u64 vlen
                        ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 41;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
                        latest_fd.update(&id,&fd);
                           
            return 0;
        }

        int sys__trace_exit_writev(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 41;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
                    
            
            struct sys_writev_event_t stats_key_v = {};
            struct sys_writev_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 41;
            stats_key->ip = 41;
        
            
                        int* fd_ptr = latest_fd.lookup(&id);
                        if (fd_ptr != 0 ) {
                            struct file_t file_key = {};
                            file_key.id = id;
                            file_key.fd = *fd_ptr;
                            u64* hash_ptr = fd_hash.lookup(&file_key);
                            if (hash_ptr != 0) {
                                stats_key->file_hash = *hash_ptr; 
                            }
                        }
                        
                        
            struct sys_writev_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
                                 stats->size_sum += PT_REGS_RC(ctx);
                                 
            
                events.ringbuf_output(&stats_key_v, sizeof(struct sys_writev_event_t), 0);
            
            
        
            return 0;
        }
        
        
        
            struct c_fopen_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_fopen_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 42;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_fopen_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 42;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_fopen_event_t stats_key_v = {};
            struct c_fopen_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 42;
            stats_key->ip = 42;
        
            
            
            
                        
            struct c_fopen_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_fopen_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_fopen64_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_fopen64_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 43;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_fopen64_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 43;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_fopen64_event_t stats_key_v = {};
            struct c_fopen64_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 43;
            stats_key->ip = 43;
        
            
            
            
                        
            struct c_fopen64_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_fopen64_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_fclose_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_fclose_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 44;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_fclose_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 44;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_fclose_event_t stats_key_v = {};
            struct c_fclose_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 44;
            stats_key->ip = 44;
        
            
            
            
                        
            struct c_fclose_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_fclose_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_fread_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_fread_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 45;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_fread_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 45;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_fread_event_t stats_key_v = {};
            struct c_fread_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 45;
            stats_key->ip = 45;
        
            
            
            
                        
            struct c_fread_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_fread_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_fwrite_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_fwrite_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 46;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_fwrite_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 46;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_fwrite_event_t stats_key_v = {};
            struct c_fwrite_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 46;
            stats_key->ip = 46;
        
            
            
            
                        
            struct c_fwrite_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_fwrite_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_ftell_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_ftell_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 47;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_ftell_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 47;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_ftell_event_t stats_key_v = {};
            struct c_ftell_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 47;
            stats_key->ip = 47;
        
            
            
            
                        
            struct c_ftell_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_ftell_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_fseek_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_fseek_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 48;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_fseek_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 48;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_fseek_event_t stats_key_v = {};
            struct c_fseek_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 48;
            stats_key->ip = 48;
        
            
            
            
                        
            struct c_fseek_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_fseek_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_open_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_open_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 49;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_open_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 49;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_open_event_t stats_key_v = {};
            struct c_open_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 49;
            stats_key->ip = 49;
        
            
            
            
                        
            struct c_open_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_open_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_open64_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_open64_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 50;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_open64_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 50;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_open64_event_t stats_key_v = {};
            struct c_open64_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 50;
            stats_key->ip = 50;
        
            
            
            
                        
            struct c_open64_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_open64_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_creat_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_creat_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 51;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_creat_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 51;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_creat_event_t stats_key_v = {};
            struct c_creat_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 51;
            stats_key->ip = 51;
        
            
            
            
                        
            struct c_creat_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_creat_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_creat64_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_creat64_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 52;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_creat64_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 52;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_creat64_event_t stats_key_v = {};
            struct c_creat64_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 52;
            stats_key->ip = 52;
        
            
            
            
                        
            struct c_creat64_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_creat64_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_close_range_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_close_range_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 53;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_close_range_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 53;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_close_range_event_t stats_key_v = {};
            struct c_close_range_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 53;
            stats_key->ip = 53;
        
            
            
            
                        
            struct c_close_range_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_close_range_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_closefrom_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_closefrom_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 54;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_closefrom_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 54;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_closefrom_event_t stats_key_v = {};
            struct c_closefrom_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 54;
            stats_key->ip = 54;
        
            
            
            
                        
            struct c_closefrom_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_closefrom_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_pread_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_pread_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 55;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_pread_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 55;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_pread_event_t stats_key_v = {};
            struct c_pread_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 55;
            stats_key->ip = 55;
        
            
            
            
                        
            struct c_pread_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_pread_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_pwrite_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_pwrite_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 56;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_pwrite_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 56;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_pwrite_event_t stats_key_v = {};
            struct c_pwrite_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 56;
            stats_key->ip = 56;
        
            
            
            
                        
            struct c_pwrite_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_pwrite_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_lseek64_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_lseek64_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 57;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_lseek64_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 57;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_lseek64_event_t stats_key_v = {};
            struct c_lseek64_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 57;
            stats_key->ip = 57;
        
            
            
            
                        
            struct c_lseek64_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_lseek64_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_fdopen_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_fdopen_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 58;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_fdopen_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 58;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_fdopen_event_t stats_key_v = {};
            struct c_fdopen_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 58;
            stats_key->ip = 58;
        
            
            
            
                        
            struct c_fdopen_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_fdopen_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_fileno_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_fileno_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 59;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_fileno_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 59;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_fileno_event_t stats_key_v = {};
            struct c_fileno_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 59;
            stats_key->ip = 59;
        
            
            
            
                        
            struct c_fileno_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_fileno_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_fileno_unlocked_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_fileno_unlocked_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 60;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_fileno_unlocked_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 60;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_fileno_unlocked_event_t stats_key_v = {};
            struct c_fileno_unlocked_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 60;
            stats_key->ip = 60;
        
            
            
            
                        
            struct c_fileno_unlocked_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_fileno_unlocked_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_mmap64_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_mmap64_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 61;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_mmap64_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 61;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_mmap64_event_t stats_key_v = {};
            struct c_mmap64_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 61;
            stats_key->ip = 61;
        
            
            
            
                        
            struct c_mmap64_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_mmap64_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_munmap_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_munmap_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 62;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_munmap_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 62;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_munmap_event_t stats_key_v = {};
            struct c_munmap_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 62;
            stats_key->ip = 62;
        
            
            
            
                        
            struct c_munmap_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_munmap_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_mremap_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_mremap_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 63;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_mremap_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 63;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_mremap_event_t stats_key_v = {};
            struct c_mremap_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 63;
            stats_key->ip = 63;
        
            
            
            
                        
            struct c_mremap_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_mremap_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_madvise_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_madvise_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 64;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_madvise_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 64;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_madvise_event_t stats_key_v = {};
            struct c_madvise_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 64;
            stats_key->ip = 64;
        
            
            
            
                        
            struct c_madvise_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_madvise_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_shm_open_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_shm_open_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 65;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_shm_open_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 65;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_shm_open_event_t stats_key_v = {};
            struct c_shm_open_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 65;
            stats_key->ip = 65;
        
            
            
            
                        
            struct c_shm_open_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_shm_open_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_shm_unlink_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_shm_unlink_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 66;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_shm_unlink_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 66;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_shm_unlink_event_t stats_key_v = {};
            struct c_shm_unlink_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 66;
            stats_key->ip = 66;
        
            
            
            
                        
            struct c_shm_unlink_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_shm_unlink_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_malloc_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_malloc_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 67;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_malloc_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 67;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_malloc_event_t stats_key_v = {};
            struct c_malloc_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 67;
            stats_key->ip = 67;
        
            
            
            
                        
            struct c_malloc_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_malloc_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_calloc_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_calloc_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 68;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_calloc_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 68;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_calloc_event_t stats_key_v = {};
            struct c_calloc_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 68;
            stats_key->ip = 68;
        
            
            
            
                        
            struct c_calloc_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_calloc_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_realloc_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_realloc_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 69;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_realloc_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 69;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_realloc_event_t stats_key_v = {};
            struct c_realloc_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 69;
            stats_key->ip = 69;
        
            
            
            
                        
            struct c_realloc_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_realloc_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_posix_memalign_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_posix_memalign_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 70;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_posix_memalign_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 70;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_posix_memalign_event_t stats_key_v = {};
            struct c_posix_memalign_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 70;
            stats_key->ip = 70;
        
            
            
            
                        
            struct c_posix_memalign_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_posix_memalign_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_valloc_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_valloc_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 71;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_valloc_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 71;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_valloc_event_t stats_key_v = {};
            struct c_valloc_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 71;
            stats_key->ip = 71;
        
            
            
            
                        
            struct c_valloc_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_valloc_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_memalign_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_memalign_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 72;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_memalign_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 72;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_memalign_event_t stats_key_v = {};
            struct c_memalign_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 72;
            stats_key->ip = 72;
        
            
            
            
                        
            struct c_memalign_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_memalign_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_pvalloc_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_pvalloc_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 73;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_pvalloc_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 73;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_pvalloc_event_t stats_key_v = {};
            struct c_pvalloc_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 73;
            stats_key->ip = 73;
        
            
            
            
                        
            struct c_pvalloc_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_pvalloc_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_aligned_alloc_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_aligned_alloc_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 74;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_aligned_alloc_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 74;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_aligned_alloc_event_t stats_key_v = {};
            struct c_aligned_alloc_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 74;
            stats_key->ip = 74;
        
            
            
            
                        
            struct c_aligned_alloc_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_aligned_alloc_event_t), 0);
            
            return 0;
        }
        
        
        
            struct c_free_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_c_free_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 75;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_c_free_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 75;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct c_free_event_t stats_key_v = {};
            struct c_free_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 75;
            stats_key->ip = 75;
        
            
            
            
                        
            struct c_free_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct c_free_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_delete_from_page_cache_batch_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_delete_from_page_cache_batch_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 76;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_delete_from_page_cache_batch_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 76;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_delete_from_page_cache_batch_event_t stats_key_v = {};
            struct kernel_delete_from_page_cache_batch_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 76;
            stats_key->ip = 76;
        
            
            
            
                        
            struct kernel_delete_from_page_cache_batch_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_delete_from_page_cache_batch_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_invalidate_folio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_invalidate_folio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 77;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_invalidate_folio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 77;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_invalidate_folio_event_t stats_key_v = {};
            struct kernel_ext4_invalidate_folio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 77;
            stats_key->ip = 77;
        
            
            
            
                        
            struct kernel_ext4_invalidate_folio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_invalidate_folio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_meta_trans_blocks_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_meta_trans_blocks_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 78;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_meta_trans_blocks_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 78;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_meta_trans_blocks_event_t stats_key_v = {};
            struct kernel_ext4_meta_trans_blocks_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 78;
            stats_key->ip = 78;
        
            
            
            
                        
            struct kernel_ext4_meta_trans_blocks_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_meta_trans_blocks_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_alloc_bioset_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_alloc_bioset_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 79;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_alloc_bioset_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 79;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_alloc_bioset_event_t stats_key_v = {};
            struct kernel_bio_alloc_bioset_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 79;
            stats_key->ip = 79;
        
            
            
            
                        
            struct kernel_bio_alloc_bioset_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_alloc_bioset_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_alloc_file_pseudo_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_alloc_file_pseudo_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 80;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_alloc_file_pseudo_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 80;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_alloc_file_pseudo_event_t stats_key_v = {};
            struct kernel_alloc_file_pseudo_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 80;
            stats_key->ip = 80;
        
            
            
            
                        
            struct kernel_alloc_file_pseudo_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_alloc_file_pseudo_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_counter_charge_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_counter_charge_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 81;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_counter_charge_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 81;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_counter_charge_event_t stats_key_v = {};
            struct kernel_page_counter_charge_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 81;
            stats_key->ip = 81;
        
            
            
            
                        
            struct kernel_page_counter_charge_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_counter_charge_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_drop_inode_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_drop_inode_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 82;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_drop_inode_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 82;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_drop_inode_event_t stats_key_v = {};
            struct kernel_ext4_drop_inode_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 82;
            stats_key->ip = 82;
        
            
            
            
                        
            struct kernel_ext4_drop_inode_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_drop_inode_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_find_goal_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_find_goal_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 83;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_find_goal_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 83;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_find_goal_event_t stats_key_v = {};
            struct kernel_ext4_ext_find_goal_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 83;
            stats_key->ip = 83;
        
            
            
            
                        
            struct kernel_ext4_ext_find_goal_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_find_goal_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_inode_journal_mode_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_inode_journal_mode_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 84;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_inode_journal_mode_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 84;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_inode_journal_mode_event_t stats_key_v = {};
            struct kernel_ext4_inode_journal_mode_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 84;
            stats_key->ip = 84;
        
            
            
            
                        
            struct kernel_ext4_inode_journal_mode_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_inode_journal_mode_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_pagecache_get_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_pagecache_get_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 85;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_pagecache_get_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 85;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_pagecache_get_page_event_t stats_key_v = {};
            struct kernel_pagecache_get_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 85;
            stats_key->ip = 85;
        
            
            
            
                        
            struct kernel_pagecache_get_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_pagecache_get_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_copy_to_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_copy_to_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 86;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_copy_to_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 86;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_copy_to_page_event_t stats_key_v = {};
            struct kernel_copy_to_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 86;
            stats_key->ip = 86;
        
            
            
            
                        
            struct kernel_copy_to_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_copy_to_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___jbd2_journal_file_buffer_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___jbd2_journal_file_buffer_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 87;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___jbd2_journal_file_buffer_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 87;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___jbd2_journal_file_buffer_event_t stats_key_v = {};
            struct kernel___jbd2_journal_file_buffer_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 87;
            stats_key->ip = 87;
        
            
            
            
                        
            struct kernel___jbd2_journal_file_buffer_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___jbd2_journal_file_buffer_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_unlink_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_unlink_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 88;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_unlink_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 88;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_unlink_event_t stats_key_v = {};
            struct kernel_ext4_unlink_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 88;
            stats_key->ip = 88;
        
            
            
            
                        
            struct kernel_ext4_unlink_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_unlink_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_guard_bio_eod_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_guard_bio_eod_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 89;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_guard_bio_eod_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 89;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_guard_bio_eod_event_t stats_key_v = {};
            struct kernel_guard_bio_eod_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 89;
            stats_key->ip = 89;
        
            
            
            
                        
            struct kernel_guard_bio_eod_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_guard_bio_eod_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_cgroup_file_release_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_cgroup_file_release_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 90;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_cgroup_file_release_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 90;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_cgroup_file_release_event_t stats_key_v = {};
            struct kernel_cgroup_file_release_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 90;
            stats_key->ip = 90;
        
            
            
            
                        
            struct kernel_cgroup_file_release_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_cgroup_file_release_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_put_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_put_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 91;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_put_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 91;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_put_event_t stats_key_v = {};
            struct kernel_bio_put_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 91;
            stats_key->ip = 91;
        
            
            
            
                        
            struct kernel_bio_put_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_put_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_fname_prepare_lookup_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_fname_prepare_lookup_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 92;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_fname_prepare_lookup_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 92;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_fname_prepare_lookup_event_t stats_key_v = {};
            struct kernel_ext4_fname_prepare_lookup_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 92;
            stats_key->ip = 92;
        
            
            
            
                        
            struct kernel_ext4_fname_prepare_lookup_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_fname_prepare_lookup_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_get_group_desc_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_get_group_desc_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 93;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_get_group_desc_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 93;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_get_group_desc_event_t stats_key_v = {};
            struct kernel_ext4_get_group_desc_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 93;
            stats_key->ip = 93;
        
            
            
            
                        
            struct kernel_ext4_get_group_desc_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_get_group_desc_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_alloc_file_clone_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_alloc_file_clone_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 94;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_alloc_file_clone_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 94;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_alloc_file_clone_event_t stats_key_v = {};
            struct kernel_alloc_file_clone_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 94;
            stats_key->ip = 94;
        
            
            
            
                        
            struct kernel_alloc_file_clone_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_alloc_file_clone_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_init_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_init_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 95;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_init_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 95;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_init_event_t stats_key_v = {};
            struct kernel_bio_init_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 95;
            stats_key->ip = 95;
        
            
            
            
                        
            struct kernel_bio_init_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_init_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_vma_set_page_prot_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_vma_set_page_prot_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 96;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_vma_set_page_prot_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 96;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_vma_set_page_prot_event_t stats_key_v = {};
            struct kernel_vma_set_page_prot_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 96;
            stats_key->ip = 96;
        
            
            
            
                        
            struct kernel_vma_set_page_prot_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_vma_set_page_prot_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_cache_sync_ra_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_cache_sync_ra_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 97;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_cache_sync_ra_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 97;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_cache_sync_ra_event_t stats_key_v = {};
            struct kernel_page_cache_sync_ra_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 97;
            stats_key->ip = 97;
        
            
            
            
                        
            struct kernel_page_cache_sync_ra_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_cache_sync_ra_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_remove_space_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_remove_space_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 98;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_remove_space_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 98;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_remove_space_event_t stats_key_v = {};
            struct kernel_ext4_ext_remove_space_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 98;
            stats_key->ip = 98;
        
            
            
            
                        
            struct kernel_ext4_ext_remove_space_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_remove_space_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_insert_extent_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_insert_extent_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 99;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_insert_extent_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 99;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_insert_extent_event_t stats_key_v = {};
            struct kernel_ext4_ext_insert_extent_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 99;
            stats_key->ip = 99;
        
            
            
            
                        
            struct kernel_ext4_ext_insert_extent_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_insert_extent_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_block_invalidate_folio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_block_invalidate_folio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 100;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_block_invalidate_folio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 100;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_block_invalidate_folio_event_t stats_key_v = {};
            struct kernel_block_invalidate_folio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 100;
            stats_key->ip = 100;
        
            
            
            
                        
            struct kernel_block_invalidate_folio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_block_invalidate_folio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_vma_mapped_walk_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_vma_mapped_walk_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 101;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_vma_mapped_walk_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 101;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_vma_mapped_walk_event_t stats_key_v = {};
            struct kernel_page_vma_mapped_walk_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 101;
            stats_key->ip = 101;
        
            
            
            
                        
            struct kernel_page_vma_mapped_walk_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_vma_mapped_walk_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_free_folio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_free_folio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 102;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_free_folio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 102;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_free_folio_event_t stats_key_v = {};
            struct kernel_filemap_free_folio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 102;
            stats_key->ip = 102;
        
            
            
            
                        
            struct kernel_filemap_free_folio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_free_folio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_profile_tick_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_profile_tick_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 103;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_profile_tick_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 103;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_profile_tick_event_t stats_key_v = {};
            struct kernel_profile_tick_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 103;
            stats_key->ip = 103;
        
            
            
            
                        
            struct kernel_profile_tick_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_profile_tick_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_get_access_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_get_access_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 104;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_get_access_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 104;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_get_access_event_t stats_key_v = {};
            struct kernel_ext4_ext_get_access_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 104;
            stats_key->ip = 104;
        
            
            
            
                        
            struct kernel_ext4_ext_get_access_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_get_access_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_try_to_merge_up_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_try_to_merge_up_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 105;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_try_to_merge_up_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 105;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_try_to_merge_up_event_t stats_key_v = {};
            struct kernel_ext4_ext_try_to_merge_up_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 105;
            stats_key->ip = 105;
        
            
            
            
                        
            struct kernel_ext4_ext_try_to_merge_up_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_try_to_merge_up_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_security_file_free_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_security_file_free_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 106;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_security_file_free_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 106;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_security_file_free_event_t stats_key_v = {};
            struct kernel_security_file_free_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 106;
            stats_key->ip = 106;
        
            
            
            
                        
            struct kernel_security_file_free_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_security_file_free_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_init_pending_tree_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_init_pending_tree_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 107;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_init_pending_tree_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 107;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_init_pending_tree_event_t stats_key_v = {};
            struct kernel_ext4_init_pending_tree_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 107;
            stats_key->ip = 107;
        
            
            
            
                        
            struct kernel_ext4_init_pending_tree_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_init_pending_tree_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_mpage_process_folio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_mpage_process_folio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 108;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_mpage_process_folio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 108;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_mpage_process_folio_event_t stats_key_v = {};
            struct kernel_mpage_process_folio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 108;
            stats_key->ip = 108;
        
            
            
            
                        
            struct kernel_mpage_process_folio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_mpage_process_folio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_map_blocks_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_map_blocks_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 109;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_map_blocks_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 109;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_map_blocks_event_t stats_key_v = {};
            struct kernel_ext4_map_blocks_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 109;
            stats_key->ip = 109;
        
            
            
            
                        
            struct kernel_ext4_map_blocks_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_map_blocks_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_readdir_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_readdir_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 110;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_readdir_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 110;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_readdir_event_t stats_key_v = {};
            struct kernel_ext4_readdir_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 110;
            stats_key->ip = 110;
        
            
            
            
                        
            struct kernel_ext4_readdir_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_readdir_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_locks_delete_block_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_locks_delete_block_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 111;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_locks_delete_block_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 111;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_locks_delete_block_event_t stats_key_v = {};
            struct kernel_locks_delete_block_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 111;
            stats_key->ip = 111;
        
            
            
            
                        
            struct kernel_locks_delete_block_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_locks_delete_block_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_search_right_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_search_right_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 112;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_search_right_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 112;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_search_right_event_t stats_key_v = {};
            struct kernel_ext4_ext_search_right_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 112;
            stats_key->ip = 112;
        
            
            
            
                        
            struct kernel_ext4_ext_search_right_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_search_right_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_add_folio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_add_folio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 113;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_add_folio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 113;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_add_folio_event_t stats_key_v = {};
            struct kernel_filemap_add_folio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 113;
            stats_key->ip = 113;
        
            
            
            
                        
            struct kernel_filemap_add_folio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_add_folio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___free_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___free_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 114;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___free_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 114;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___free_pages_event_t stats_key_v = {};
            struct kernel___free_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 114;
            stats_key->ip = 114;
        
            
            
            
                        
            struct kernel___free_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___free_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_put_files_struct_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_put_files_struct_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 115;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_put_files_struct_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 115;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_put_files_struct_event_t stats_key_v = {};
            struct kernel_put_files_struct_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 115;
            stats_key->ip = 115;
        
            
            
            
                        
            struct kernel_put_files_struct_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_put_files_struct_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_aa_file_perm_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_aa_file_perm_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 116;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_aa_file_perm_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 116;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_aa_file_perm_event_t stats_key_v = {};
            struct kernel_aa_file_perm_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 116;
            stats_key->ip = 116;
        
            
            
            
                        
            struct kernel_aa_file_perm_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_aa_file_perm_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_submit_bio_wait_endio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_submit_bio_wait_endio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 117;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_submit_bio_wait_endio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 117;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_submit_bio_wait_endio_event_t stats_key_v = {};
            struct kernel_submit_bio_wait_endio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 117;
            stats_key->ip = 117;
        
            
            
            
                        
            struct kernel_submit_bio_wait_endio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_submit_bio_wait_endio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___tlb_remove_page_size_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___tlb_remove_page_size_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 118;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___tlb_remove_page_size_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 118;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___tlb_remove_page_size_event_t stats_key_v = {};
            struct kernel___tlb_remove_page_size_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 118;
            stats_key->ip = 118;
        
            
            
            
                        
            struct kernel___tlb_remove_page_size_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___tlb_remove_page_size_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_truncate_inode_pages_range_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_truncate_inode_pages_range_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 119;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_truncate_inode_pages_range_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 119;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_truncate_inode_pages_range_event_t stats_key_v = {};
            struct kernel_truncate_inode_pages_range_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 119;
            stats_key->ip = 119;
        
            
            
            
                        
            struct kernel_truncate_inode_pages_range_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_truncate_inode_pages_range_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_io_submit_init_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_io_submit_init_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 120;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_io_submit_init_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 120;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_io_submit_init_event_t stats_key_v = {};
            struct kernel_ext4_io_submit_init_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 120;
            stats_key->ip = 120;
        
            
            
            
                        
            struct kernel_ext4_io_submit_init_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_io_submit_init_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_es_lookup_extent_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_es_lookup_extent_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 121;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_es_lookup_extent_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 121;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_es_lookup_extent_event_t stats_key_v = {};
            struct kernel_ext4_es_lookup_extent_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 121;
            stats_key->ip = 121;
        
            
            
            
                        
            struct kernel_ext4_es_lookup_extent_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_es_lookup_extent_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_inode_attach_jinode_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_inode_attach_jinode_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 122;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_inode_attach_jinode_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 122;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_inode_attach_jinode_event_t stats_key_v = {};
            struct kernel_ext4_inode_attach_jinode_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 122;
            stats_key->ip = 122;
        
            
            
            
                        
            struct kernel_ext4_inode_attach_jinode_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_inode_attach_jinode_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_get_group_info_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_get_group_info_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 123;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_get_group_info_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 123;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_get_group_info_event_t stats_key_v = {};
            struct kernel_ext4_get_group_info_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 123;
            stats_key->ip = 123;
        
            
            
            
                        
            struct kernel_ext4_get_group_info_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_get_group_info_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_dd_bio_merge_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_dd_bio_merge_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 124;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_dd_bio_merge_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 124;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_dd_bio_merge_event_t stats_key_v = {};
            struct kernel_dd_bio_merge_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 124;
            stats_key->ip = 124;
        
            
            
            
                        
            struct kernel_dd_bio_merge_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_dd_bio_merge_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_fscrypt_set_bio_crypt_ctx_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_fscrypt_set_bio_crypt_ctx_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 125;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_fscrypt_set_bio_crypt_ctx_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 125;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_fscrypt_set_bio_crypt_ctx_event_t stats_key_v = {};
            struct kernel_fscrypt_set_bio_crypt_ctx_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 125;
            stats_key->ip = 125;
        
            
            
            
                        
            struct kernel_fscrypt_set_bio_crypt_ctx_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_fscrypt_set_bio_crypt_ctx_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_inode_bitmap_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_inode_bitmap_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 126;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_inode_bitmap_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 126;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_inode_bitmap_event_t stats_key_v = {};
            struct kernel_ext4_inode_bitmap_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 126;
            stats_key->ip = 126;
        
            
            
            
                        
            struct kernel_ext4_inode_bitmap_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_inode_bitmap_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_use_inode_pa_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_use_inode_pa_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 127;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_use_inode_pa_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 127;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_use_inode_pa_event_t stats_key_v = {};
            struct kernel_ext4_mb_use_inode_pa_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 127;
            stats_key->ip = 127;
        
            
            
            
                        
            struct kernel_ext4_mb_use_inode_pa_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_use_inode_pa_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_read_block_bitmap_nowait_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_read_block_bitmap_nowait_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 128;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_read_block_bitmap_nowait_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 128;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_read_block_bitmap_nowait_event_t stats_key_v = {};
            struct kernel_ext4_read_block_bitmap_nowait_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 128;
            stats_key->ip = 128;
        
            
            
            
                        
            struct kernel_ext4_read_block_bitmap_nowait_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_read_block_bitmap_nowait_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___mod_zone_page_state_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___mod_zone_page_state_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 129;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___mod_zone_page_state_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 129;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___mod_zone_page_state_event_t stats_key_v = {};
            struct kernel___mod_zone_page_state_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 129;
            stats_key->ip = 129;
        
            
            
            
                        
            struct kernel___mod_zone_page_state_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___mod_zone_page_state_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_sb_block_valid_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_sb_block_valid_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 130;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_sb_block_valid_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 130;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_sb_block_valid_event_t stats_key_v = {};
            struct kernel_ext4_sb_block_valid_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 130;
            stats_key->ip = 130;
        
            
            
            
                        
            struct kernel_ext4_sb_block_valid_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_sb_block_valid_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_hugepage_vma_check_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_hugepage_vma_check_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 131;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_hugepage_vma_check_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 131;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_hugepage_vma_check_event_t stats_key_v = {};
            struct kernel_hugepage_vma_check_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 131;
            stats_key->ip = 131;
        
            
            
            
                        
            struct kernel_hugepage_vma_check_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_hugepage_vma_check_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_counter_cancel_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_counter_cancel_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 132;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_counter_cancel_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 132;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_counter_cancel_event_t stats_key_v = {};
            struct kernel_page_counter_cancel_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 132;
            stats_key->ip = 132;
        
            
            
            
                        
            struct kernel_page_counter_cancel_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_counter_cancel_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_rm_idx_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_rm_idx_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 133;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_rm_idx_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 133;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_rm_idx_event_t stats_key_v = {};
            struct kernel_ext4_ext_rm_idx_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 133;
            stats_key->ip = 133;
        
            
            
            
                        
            struct kernel_ext4_ext_rm_idx_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_rm_idx_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_cache_ra_unbounded_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_cache_ra_unbounded_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 134;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_cache_ra_unbounded_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 134;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_cache_ra_unbounded_event_t stats_key_v = {};
            struct kernel_page_cache_ra_unbounded_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 134;
            stats_key->ip = 134;
        
            
            
            
                        
            struct kernel_page_cache_ra_unbounded_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_cache_ra_unbounded_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_release_folio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_release_folio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 135;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_release_folio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 135;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_release_folio_event_t stats_key_v = {};
            struct kernel_filemap_release_folio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 135;
            stats_key->ip = 135;
        
            
            
            
                        
            struct kernel_filemap_release_folio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_release_folio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_itable_unused_count_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_itable_unused_count_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 136;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_itable_unused_count_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 136;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_itable_unused_count_event_t stats_key_v = {};
            struct kernel_ext4_itable_unused_count_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 136;
            stats_key->ip = 136;
        
            
            
            
                        
            struct kernel_ext4_itable_unused_count_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_itable_unused_count_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_apparmor_file_lock_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_apparmor_file_lock_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 137;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_apparmor_file_lock_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 137;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_apparmor_file_lock_event_t stats_key_v = {};
            struct kernel_apparmor_file_lock_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 137;
            stats_key->ip = 137;
        
            
            
            
                        
            struct kernel_apparmor_file_lock_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_apparmor_file_lock_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_nr_blockdev_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_nr_blockdev_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 138;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_nr_blockdev_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 138;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_nr_blockdev_pages_event_t stats_key_v = {};
            struct kernel_nr_blockdev_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 138;
            stats_key->ip = 138;
        
            
            
            
                        
            struct kernel_nr_blockdev_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_nr_blockdev_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_to_wbt_flags_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_to_wbt_flags_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 139;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_to_wbt_flags_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 139;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_to_wbt_flags_event_t stats_key_v = {};
            struct kernel_bio_to_wbt_flags_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 139;
            stats_key->ip = 139;
        
            
            
            
                        
            struct kernel_bio_to_wbt_flags_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_to_wbt_flags_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_get_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_get_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 140;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_get_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 140;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_get_pages_event_t stats_key_v = {};
            struct kernel_filemap_get_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 140;
            stats_key->ip = 140;
        
            
            
            
                        
            struct kernel_filemap_get_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_get_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_set_pages_dirty_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_set_pages_dirty_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 141;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_set_pages_dirty_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 141;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_set_pages_dirty_event_t stats_key_v = {};
            struct kernel_bio_set_pages_dirty_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 141;
            stats_key->ip = 141;
        
            
            
            
                        
            struct kernel_bio_set_pages_dirty_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_set_pages_dirty_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___submit_bio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___submit_bio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 142;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___submit_bio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 142;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___submit_bio_event_t stats_key_v = {};
            struct kernel___submit_bio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 142;
            stats_key->ip = 142;
        
            
            
            
                        
            struct kernel___submit_bio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___submit_bio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ima_file_free_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ima_file_free_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 143;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ima_file_free_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 143;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ima_file_free_event_t stats_key_v = {};
            struct kernel_ima_file_free_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 143;
            stats_key->ip = 143;
        
            
            
            
                        
            struct kernel_ima_file_free_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ima_file_free_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_file_open_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_file_open_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 144;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_file_open_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 144;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_file_open_event_t stats_key_v = {};
            struct kernel_ext4_file_open_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 144;
            stats_key->ip = 144;
        
            
            
            
                        
            struct kernel_ext4_file_open_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_file_open_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_add_folio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_add_folio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 145;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_add_folio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 145;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_add_folio_event_t stats_key_v = {};
            struct kernel_bio_add_folio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 145;
            stats_key->ip = 145;
        
            
            
            
                        
            struct kernel_bio_add_folio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_add_folio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_hook_file_alloc_security_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_hook_file_alloc_security_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 146;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_hook_file_alloc_security_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 146;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_hook_file_alloc_security_event_t stats_key_v = {};
            struct kernel_hook_file_alloc_security_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 146;
            stats_key->ip = 146;
        
            
            
            
                        
            struct kernel_hook_file_alloc_security_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_hook_file_alloc_security_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_io_submit_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_io_submit_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 147;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_io_submit_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 147;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_io_submit_event_t stats_key_v = {};
            struct kernel_ext4_io_submit_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 147;
            stats_key->ip = 147;
        
            
            
            
                        
            struct kernel_ext4_io_submit_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_io_submit_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_alloc_pages_bulk_array_mempolicy_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_alloc_pages_bulk_array_mempolicy_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 148;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_alloc_pages_bulk_array_mempolicy_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 148;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_alloc_pages_bulk_array_mempolicy_event_t stats_key_v = {};
            struct kernel_alloc_pages_bulk_array_mempolicy_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 148;
            stats_key->ip = 148;
        
            
            
            
                        
            struct kernel_alloc_pages_bulk_array_mempolicy_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_alloc_pages_bulk_array_mempolicy_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_remove_rmap_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_remove_rmap_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 149;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_remove_rmap_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 149;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_remove_rmap_event_t stats_key_v = {};
            struct kernel_page_remove_rmap_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 149;
            stats_key->ip = 149;
        
            
            
            
                        
            struct kernel_page_remove_rmap_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_remove_rmap_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_map_pmd_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_map_pmd_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 150;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_map_pmd_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 150;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_map_pmd_event_t stats_key_v = {};
            struct kernel_filemap_map_pmd_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 150;
            stats_key->ip = 150;
        
            
            
            
                        
            struct kernel_filemap_map_pmd_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_map_pmd_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_tag_pages_for_writeback_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_tag_pages_for_writeback_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 151;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_tag_pages_for_writeback_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 151;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_tag_pages_for_writeback_event_t stats_key_v = {};
            struct kernel_tag_pages_for_writeback_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 151;
            stats_key->ip = 151;
        
            
            
            
                        
            struct kernel_tag_pages_for_writeback_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_tag_pages_for_writeback_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_rm_leaf_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_rm_leaf_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 152;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_rm_leaf_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 152;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_rm_leaf_event_t stats_key_v = {};
            struct kernel_ext4_ext_rm_leaf_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 152;
            stats_key->ip = 152;
        
            
            
            
                        
            struct kernel_ext4_ext_rm_leaf_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_rm_leaf_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___find_get_block_slow_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___find_get_block_slow_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 153;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___find_get_block_slow_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 153;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___find_get_block_slow_event_t stats_key_v = {};
            struct kernel___find_get_block_slow_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 153;
            stats_key->ip = 153;
        
            
            
            
                        
            struct kernel___find_get_block_slow_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___find_get_block_slow_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_fname_from_fscrypt_name_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_fname_from_fscrypt_name_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 154;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_fname_from_fscrypt_name_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 154;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_fname_from_fscrypt_name_event_t stats_key_v = {};
            struct kernel_ext4_fname_from_fscrypt_name_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 154;
            stats_key->ip = 154;
        
            
            
            
                        
            struct kernel_ext4_fname_from_fscrypt_name_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_fname_from_fscrypt_name_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_free_clusters_after_init_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_free_clusters_after_init_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 155;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_free_clusters_after_init_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 155;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_free_clusters_after_init_event_t stats_key_v = {};
            struct kernel_ext4_free_clusters_after_init_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 155;
            stats_key->ip = 155;
        
            
            
            
                        
            struct kernel_ext4_free_clusters_after_init_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_free_clusters_after_init_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bvec_try_merge_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bvec_try_merge_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 156;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bvec_try_merge_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 156;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bvec_try_merge_page_event_t stats_key_v = {};
            struct kernel_bvec_try_merge_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 156;
            stats_key->ip = 156;
        
            
            
            
                        
            struct kernel_bvec_try_merge_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bvec_try_merge_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_journal_get_create_access_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_journal_get_create_access_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 157;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_journal_get_create_access_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 157;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_journal_get_create_access_event_t stats_key_v = {};
            struct kernel___ext4_journal_get_create_access_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 157;
            stats_key->ip = 157;
        
            
            
            
                        
            struct kernel___ext4_journal_get_create_access_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_journal_get_create_access_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_claim_free_clusters_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_claim_free_clusters_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 158;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_claim_free_clusters_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 158;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_claim_free_clusters_event_t stats_key_v = {};
            struct kernel_ext4_claim_free_clusters_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 158;
            stats_key->ip = 158;
        
            
            
            
                        
            struct kernel_ext4_claim_free_clusters_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_claim_free_clusters_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_fc_commit_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_fc_commit_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 159;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_fc_commit_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 159;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_fc_commit_event_t stats_key_v = {};
            struct kernel_ext4_fc_commit_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 159;
            stats_key->ip = 159;
        
            
            
            
                        
            struct kernel_ext4_fc_commit_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_fc_commit_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_ext_dirty_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_ext_dirty_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 160;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_ext_dirty_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 160;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_ext_dirty_event_t stats_key_v = {};
            struct kernel___ext4_ext_dirty_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 160;
            stats_key->ip = 160;
        
            
            
            
                        
            struct kernel___ext4_ext_dirty_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_ext_dirty_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_split_rw_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_split_rw_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 161;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_split_rw_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 161;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_split_rw_event_t stats_key_v = {};
            struct kernel_bio_split_rw_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 161;
            stats_key->ip = 161;
        
            
            
            
                        
            struct kernel_bio_split_rw_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_split_rw_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___bio_clone_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___bio_clone_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 162;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___bio_clone_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 162;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___bio_clone_event_t stats_key_v = {};
            struct kernel___bio_clone_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 162;
            stats_key->ip = 162;
        
            
            
            
                        
            struct kernel___bio_clone_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___bio_clone_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_do_vfs_ioctl_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_do_vfs_ioctl_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 163;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_do_vfs_ioctl_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 163;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_do_vfs_ioctl_event_t stats_key_v = {};
            struct kernel_do_vfs_ioctl_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 163;
            stats_key->ip = 163;
        
            
            
            
                        
            struct kernel_do_vfs_ioctl_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_do_vfs_ioctl_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_free_blocks_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_free_blocks_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 164;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_free_blocks_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 164;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_free_blocks_event_t stats_key_v = {};
            struct kernel_ext4_free_blocks_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 164;
            stats_key->ip = 164;
        
            
            
            
                        
            struct kernel_ext4_free_blocks_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_free_blocks_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_validate_inode_bitmap_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_validate_inode_bitmap_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 165;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_validate_inode_bitmap_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 165;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_validate_inode_bitmap_event_t stats_key_v = {};
            struct kernel_ext4_validate_inode_bitmap_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 165;
            stats_key->ip = 165;
        
            
            
            
                        
            struct kernel_ext4_validate_inode_bitmap_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_validate_inode_bitmap_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_from_vfsgid_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_from_vfsgid_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 166;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_from_vfsgid_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 166;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_from_vfsgid_event_t stats_key_v = {};
            struct kernel_from_vfsgid_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 166;
            stats_key->ip = 166;
        
            
            
            
                        
            struct kernel_from_vfsgid_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_from_vfsgid_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_new_meta_blocks_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_new_meta_blocks_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 167;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_new_meta_blocks_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 167;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_new_meta_blocks_event_t stats_key_v = {};
            struct kernel_ext4_new_meta_blocks_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 167;
            stats_key->ip = 167;
        
            
            
            
                        
            struct kernel_ext4_new_meta_blocks_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_new_meta_blocks_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_hook_file_truncate_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_hook_file_truncate_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 168;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_hook_file_truncate_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 168;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_hook_file_truncate_event_t stats_key_v = {};
            struct kernel_hook_file_truncate_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 168;
            stats_key->ip = 168;
        
            
            
            
                        
            struct kernel_hook_file_truncate_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_hook_file_truncate_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_security_file_open_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_security_file_open_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 169;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_security_file_open_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 169;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_security_file_open_event_t stats_key_v = {};
            struct kernel_security_file_open_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 169;
            stats_key->ip = 169;
        
            
            
            
                        
            struct kernel_security_file_open_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_security_file_open_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_read_dirblock_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_read_dirblock_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 170;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_read_dirblock_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 170;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_read_dirblock_event_t stats_key_v = {};
            struct kernel___ext4_read_dirblock_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 170;
            stats_key->ip = 170;
        
            
            
            
                        
            struct kernel___ext4_read_dirblock_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_read_dirblock_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ima_file_mmap_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ima_file_mmap_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 171;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ima_file_mmap_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 171;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ima_file_mmap_event_t stats_key_v = {};
            struct kernel_ima_file_mmap_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 171;
            stats_key->ip = 171;
        
            
            
            
                        
            struct kernel_ima_file_mmap_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ima_file_mmap_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_xattr_ibody_get_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_xattr_ibody_get_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 172;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_xattr_ibody_get_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 172;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_xattr_ibody_get_event_t stats_key_v = {};
            struct kernel_ext4_xattr_ibody_get_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 172;
            stats_key->ip = 172;
        
            
            
            
                        
            struct kernel_ext4_xattr_ibody_get_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_xattr_ibody_get_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_pick_file_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_pick_file_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 173;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_pick_file_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 173;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_pick_file_event_t stats_key_v = {};
            struct kernel_pick_file_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 173;
            stats_key->ip = 173;
        
            
            
            
                        
            struct kernel_pick_file_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_pick_file_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_free_pages_and_swap_cache_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_free_pages_and_swap_cache_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 174;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_free_pages_and_swap_cache_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 174;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_free_pages_and_swap_cache_event_t stats_key_v = {};
            struct kernel_free_pages_and_swap_cache_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 174;
            stats_key->ip = 174;
        
            
            
            
                        
            struct kernel_free_pages_and_swap_cache_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_free_pages_and_swap_cache_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_file_modified_flags_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_file_modified_flags_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 175;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_file_modified_flags_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 175;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_file_modified_flags_event_t stats_key_v = {};
            struct kernel_file_modified_flags_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 175;
            stats_key->ip = 175;
        
            
            
            
                        
            struct kernel_file_modified_flags_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_file_modified_flags_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___filemap_fdatawrite_range_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___filemap_fdatawrite_range_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 176;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___filemap_fdatawrite_range_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 176;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___filemap_fdatawrite_range_event_t stats_key_v = {};
            struct kernel___filemap_fdatawrite_range_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 176;
            stats_key->ip = 176;
        
            
            
            
                        
            struct kernel___filemap_fdatawrite_range_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___filemap_fdatawrite_range_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_get_page_from_freelist_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_get_page_from_freelist_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 177;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_get_page_from_freelist_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 177;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_get_page_from_freelist_event_t stats_key_v = {};
            struct kernel_get_page_from_freelist_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 177;
            stats_key->ip = 177;
        
            
            
            
                        
            struct kernel_get_page_from_freelist_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_get_page_from_freelist_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_group_desc_csum_verify_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_group_desc_csum_verify_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 178;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_group_desc_csum_verify_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 178;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_group_desc_csum_verify_event_t stats_key_v = {};
            struct kernel_ext4_group_desc_csum_verify_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 178;
            stats_key->ip = 178;
        
            
            
            
                        
            struct kernel_ext4_group_desc_csum_verify_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_group_desc_csum_verify_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_new_inode_pa_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_new_inode_pa_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 179;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_new_inode_pa_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 179;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_new_inode_pa_event_t stats_key_v = {};
            struct kernel_ext4_mb_new_inode_pa_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 179;
            stats_key->ip = 179;
        
            
            
            
                        
            struct kernel_ext4_mb_new_inode_pa_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_new_inode_pa_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_follow_page_mask_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_follow_page_mask_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 180;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_follow_page_mask_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 180;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_follow_page_mask_event_t stats_key_v = {};
            struct kernel_follow_page_mask_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 180;
            stats_key->ip = 180;
        
            
            
            
                        
            struct kernel_follow_page_mask_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_follow_page_mask_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_new_blocks_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_new_blocks_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 181;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_new_blocks_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 181;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_new_blocks_event_t stats_key_v = {};
            struct kernel_ext4_mb_new_blocks_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 181;
            stats_key->ip = 181;
        
            
            
            
                        
            struct kernel_ext4_mb_new_blocks_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_new_blocks_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___memcg_kmem_charge_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___memcg_kmem_charge_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 182;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___memcg_kmem_charge_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 182;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___memcg_kmem_charge_page_event_t stats_key_v = {};
            struct kernel___memcg_kmem_charge_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 182;
            stats_key->ip = 182;
        
            
            
            
                        
            struct kernel___memcg_kmem_charge_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___memcg_kmem_charge_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_try_to_merge_right_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_try_to_merge_right_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 183;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_try_to_merge_right_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 183;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_try_to_merge_right_event_t stats_key_v = {};
            struct kernel_ext4_ext_try_to_merge_right_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 183;
            stats_key->ip = 183;
        
            
            
            
                        
            struct kernel_ext4_ext_try_to_merge_right_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_try_to_merge_right_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_valid_block_bitmap_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_valid_block_bitmap_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 184;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_valid_block_bitmap_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 184;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_valid_block_bitmap_event_t stats_key_v = {};
            struct kernel_ext4_valid_block_bitmap_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 184;
            stats_key->ip = 184;
        
            
            
            
                        
            struct kernel_ext4_valid_block_bitmap_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_valid_block_bitmap_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_journal_get_superblock_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_journal_get_superblock_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 185;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_journal_get_superblock_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 185;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_journal_get_superblock_event_t stats_key_v = {};
            struct kernel_journal_get_superblock_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 185;
            stats_key->ip = 185;
        
            
            
            
                        
            struct kernel_journal_get_superblock_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_journal_get_superblock_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_try_to_merge_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_try_to_merge_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 186;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_try_to_merge_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 186;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_try_to_merge_event_t stats_key_v = {};
            struct kernel_ext4_ext_try_to_merge_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 186;
            stats_key->ip = 186;
        
            
            
            
                        
            struct kernel_ext4_ext_try_to_merge_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_try_to_merge_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_vfs_fstatat_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_vfs_fstatat_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 187;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_vfs_fstatat_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 187;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_vfs_fstatat_event_t stats_key_v = {};
            struct kernel_vfs_fstatat_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 187;
            stats_key->ip = 187;
        
            
            
            
                        
            struct kernel_vfs_fstatat_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_vfs_fstatat_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_security_file_mprotect_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_security_file_mprotect_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 188;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_security_file_mprotect_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 188;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_security_file_mprotect_event_t stats_key_v = {};
            struct kernel_security_file_mprotect_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 188;
            stats_key->ip = 188;
        
            
            
            
                        
            struct kernel_security_file_mprotect_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_security_file_mprotect_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_try_grab_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_try_grab_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 189;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_try_grab_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 189;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_try_grab_page_event_t stats_key_v = {};
            struct kernel_try_grab_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 189;
            stats_key->ip = 189;
        
            
            
            
                        
            struct kernel_try_grab_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_try_grab_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_iomap_begin_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_iomap_begin_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 190;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_iomap_begin_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 190;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_iomap_begin_event_t stats_key_v = {};
            struct kernel_ext4_iomap_begin_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 190;
            stats_key->ip = 190;
        
            
            
            
                        
            struct kernel_ext4_iomap_begin_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_iomap_begin_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_pcpu_block_update_hint_free_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_pcpu_block_update_hint_free_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 191;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_pcpu_block_update_hint_free_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 191;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_pcpu_block_update_hint_free_event_t stats_key_v = {};
            struct kernel_pcpu_block_update_hint_free_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 191;
            stats_key->ip = 191;
        
            
            
            
                        
            struct kernel_pcpu_block_update_hint_free_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_pcpu_block_update_hint_free_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_bread_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_bread_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 192;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_bread_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 192;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_bread_event_t stats_key_v = {};
            struct kernel_ext4_bread_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 192;
            stats_key->ip = 192;
        
            
            
            
                        
            struct kernel_ext4_bread_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_bread_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mpage_readpages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mpage_readpages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 193;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mpage_readpages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 193;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mpage_readpages_event_t stats_key_v = {};
            struct kernel_ext4_mpage_readpages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 193;
            stats_key->ip = 193;
        
            
            
            
                        
            struct kernel_ext4_mpage_readpages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mpage_readpages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___get_free_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___get_free_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 194;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___get_free_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 194;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___get_free_pages_event_t stats_key_v = {};
            struct kernel___get_free_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 194;
            stats_key->ip = 194;
        
            
            
            
                        
            struct kernel___get_free_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___get_free_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_dax_layout_busy_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_dax_layout_busy_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 195;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_dax_layout_busy_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 195;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_dax_layout_busy_page_event_t stats_key_v = {};
            struct kernel_dax_layout_busy_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 195;
            stats_key->ip = 195;
        
            
            
            
                        
            struct kernel_dax_layout_busy_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_dax_layout_busy_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_es_remove_extent_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_es_remove_extent_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 196;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_es_remove_extent_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 196;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_es_remove_extent_event_t stats_key_v = {};
            struct kernel_ext4_es_remove_extent_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 196;
            stats_key->ip = 196;
        
            
            
            
                        
            struct kernel_ext4_es_remove_extent_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_es_remove_extent_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_da_release_space_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_da_release_space_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 197;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_da_release_space_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 197;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_da_release_space_event_t stats_key_v = {};
            struct kernel_ext4_da_release_space_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 197;
            stats_key->ip = 197;
        
            
            
            
                        
            struct kernel_ext4_da_release_space_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_da_release_space_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_sum_zone_node_page_state_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_sum_zone_node_page_state_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 198;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_sum_zone_node_page_state_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 198;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_sum_zone_node_page_state_event_t stats_key_v = {};
            struct kernel_sum_zone_node_page_state_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 198;
            stats_key->ip = 198;
        
            
            
            
                        
            struct kernel_sum_zone_node_page_state_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_sum_zone_node_page_state_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_inode_bitmap_csum_verify_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_inode_bitmap_csum_verify_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 199;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_inode_bitmap_csum_verify_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 199;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_inode_bitmap_csum_verify_event_t stats_key_v = {};
            struct kernel_ext4_inode_bitmap_csum_verify_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 199;
            stats_key->ip = 199;
        
            
            
            
                        
            struct kernel_ext4_inode_bitmap_csum_verify_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_inode_bitmap_csum_verify_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_unmap_page_range_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_unmap_page_range_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 200;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_unmap_page_range_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 200;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_unmap_page_range_event_t stats_key_v = {};
            struct kernel_unmap_page_range_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 200;
            stats_key->ip = 200;
        
            
            
            
                        
            struct kernel_unmap_page_range_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_unmap_page_range_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_cgroup_file_open_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_cgroup_file_open_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 201;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_cgroup_file_open_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 201;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_cgroup_file_open_event_t stats_key_v = {};
            struct kernel_cgroup_file_open_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 201;
            stats_key->ip = 201;
        
            
            
            
                        
            struct kernel_cgroup_file_open_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_cgroup_file_open_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_exit_aio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_exit_aio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 202;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_exit_aio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 202;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_exit_aio_event_t stats_key_v = {};
            struct kernel_exit_aio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 202;
            stats_key->ip = 202;
        
            
            
            
                        
            struct kernel_exit_aio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_exit_aio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_security_file_lock_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_security_file_lock_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 203;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_security_file_lock_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 203;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_security_file_lock_event_t stats_key_v = {};
            struct kernel_security_file_lock_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 203;
            stats_key->ip = 203;
        
            
            
            
                        
            struct kernel_security_file_lock_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_security_file_lock_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_bio_write_folio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_bio_write_folio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 204;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_bio_write_folio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 204;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_bio_write_folio_event_t stats_key_v = {};
            struct kernel_ext4_bio_write_folio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 204;
            stats_key->ip = 204;
        
            
            
            
                        
            struct kernel_ext4_bio_write_folio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_bio_write_folio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_pin_user_pages_fast_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_pin_user_pages_fast_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 205;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_pin_user_pages_fast_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 205;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_pin_user_pages_fast_event_t stats_key_v = {};
            struct kernel_pin_user_pages_fast_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 205;
            stats_key->ip = 205;
        
            
            
            
                        
            struct kernel_pin_user_pages_fast_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_pin_user_pages_fast_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_alloc_empty_file_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_alloc_empty_file_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 206;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_alloc_empty_file_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 206;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_alloc_empty_file_event_t stats_key_v = {};
            struct kernel_alloc_empty_file_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 206;
            stats_key->ip = 206;
        
            
            
            
                        
            struct kernel_alloc_empty_file_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_alloc_empty_file_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_inode_table_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_inode_table_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 207;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_inode_table_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 207;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_inode_table_event_t stats_key_v = {};
            struct kernel_ext4_inode_table_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 207;
            stats_key->ip = 207;
        
            
            
            
                        
            struct kernel_ext4_inode_table_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_inode_table_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_anon_inode_getfile_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_anon_inode_getfile_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 208;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_anon_inode_getfile_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 208;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_anon_inode_getfile_event_t stats_key_v = {};
            struct kernel_anon_inode_getfile_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 208;
            stats_key->ip = 208;
        
            
            
            
                        
            struct kernel_anon_inode_getfile_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_anon_inode_getfile_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___mnt_want_write_file_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___mnt_want_write_file_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 209;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___mnt_want_write_file_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 209;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___mnt_want_write_file_event_t stats_key_v = {};
            struct kernel___mnt_want_write_file_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 209;
            stats_key->ip = 209;
        
            
            
            
                        
            struct kernel___mnt_want_write_file_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___mnt_want_write_file_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_cache_async_ra_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_cache_async_ra_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 210;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_cache_async_ra_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 210;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_cache_async_ra_event_t stats_key_v = {};
            struct kernel_page_cache_async_ra_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 210;
            stats_key->ip = 210;
        
            
            
            
                        
            struct kernel_page_cache_async_ra_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_cache_async_ra_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_mpage_process_page_bufs_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_mpage_process_page_bufs_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 211;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_mpage_process_page_bufs_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 211;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_mpage_process_page_bufs_event_t stats_key_v = {};
            struct kernel_mpage_process_page_bufs_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 211;
            stats_key->ip = 211;
        
            
            
            
                        
            struct kernel_mpage_process_page_bufs_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_mpage_process_page_bufs_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_collect_stats_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_collect_stats_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 212;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_collect_stats_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 212;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_collect_stats_event_t stats_key_v = {};
            struct kernel_ext4_mb_collect_stats_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 212;
            stats_key->ip = 212;
        
            
            
            
                        
            struct kernel_ext4_mb_collect_stats_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_collect_stats_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_reserve_inode_write_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_reserve_inode_write_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 213;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_reserve_inode_write_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 213;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_reserve_inode_write_event_t stats_key_v = {};
            struct kernel_ext4_reserve_inode_write_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 213;
            stats_key->ip = 213;
        
            
            
            
                        
            struct kernel_ext4_reserve_inode_write_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_reserve_inode_write_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___update_blocked_fair_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___update_blocked_fair_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 214;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___update_blocked_fair_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 214;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___update_blocked_fair_event_t stats_key_v = {};
            struct kernel___update_blocked_fair_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 214;
            stats_key->ip = 214;
        
            
            
            
                        
            struct kernel___update_blocked_fair_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___update_blocked_fair_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_generate_buddy_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_generate_buddy_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 215;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_generate_buddy_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 215;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_generate_buddy_event_t stats_key_v = {};
            struct kernel_ext4_mb_generate_buddy_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 215;
            stats_key->ip = 215;
        
            
            
            
                        
            struct kernel_ext4_mb_generate_buddy_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_generate_buddy_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_find_extent_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_find_extent_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 216;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_find_extent_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 216;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_find_extent_event_t stats_key_v = {};
            struct kernel_ext4_find_extent_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 216;
            stats_key->ip = 216;
        
            
            
            
                        
            struct kernel_ext4_find_extent_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_find_extent_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_tree_init_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_tree_init_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 217;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_tree_init_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 217;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_tree_init_event_t stats_key_v = {};
            struct kernel_ext4_ext_tree_init_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 217;
            stats_key->ip = 217;
        
            
            
            
                        
            struct kernel_ext4_ext_tree_init_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_tree_init_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_should_fail_alloc_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_should_fail_alloc_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 218;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_should_fail_alloc_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 218;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_should_fail_alloc_page_event_t stats_key_v = {};
            struct kernel_should_fail_alloc_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 218;
            stats_key->ip = 218;
        
            
            
            
                        
            struct kernel_should_fail_alloc_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_should_fail_alloc_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_security_file_truncate_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_security_file_truncate_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 219;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_security_file_truncate_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 219;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_security_file_truncate_event_t stats_key_v = {};
            struct kernel_security_file_truncate_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 219;
            stats_key->ip = 219;
        
            
            
            
                        
            struct kernel_security_file_truncate_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_security_file_truncate_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_vmalloc_to_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_vmalloc_to_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 220;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_vmalloc_to_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 220;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_vmalloc_to_page_event_t stats_key_v = {};
            struct kernel_vmalloc_to_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 220;
            stats_key->ip = 220;
        
            
            
            
                        
            struct kernel_vmalloc_to_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_vmalloc_to_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_htree_fill_tree_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_htree_fill_tree_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 221;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_htree_fill_tree_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 221;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_htree_fill_tree_event_t stats_key_v = {};
            struct kernel_ext4_htree_fill_tree_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 221;
            stats_key->ip = 221;
        
            
            
            
                        
            struct kernel_ext4_htree_fill_tree_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_htree_fill_tree_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_getblk_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_getblk_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 222;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_getblk_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 222;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_getblk_event_t stats_key_v = {};
            struct kernel_ext4_getblk_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 222;
            stats_key->ip = 222;
        
            
            
            
                        
            struct kernel_ext4_getblk_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_getblk_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_init_file_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_init_file_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 223;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_init_file_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 223;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_init_file_event_t stats_key_v = {};
            struct kernel_init_file_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 223;
            stats_key->ip = 223;
        
            
            
            
                        
            struct kernel_init_file_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_init_file_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_map_blocks_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_map_blocks_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 224;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_map_blocks_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 224;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_map_blocks_event_t stats_key_v = {};
            struct kernel_ext4_ext_map_blocks_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 224;
            stats_key->ip = 224;
        
            
            
            
                        
            struct kernel_ext4_ext_map_blocks_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_map_blocks_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_da_update_reserve_space_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_da_update_reserve_space_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 225;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_da_update_reserve_space_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 225;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_da_update_reserve_space_event_t stats_key_v = {};
            struct kernel_ext4_da_update_reserve_space_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 225;
            stats_key->ip = 225;
        
            
            
            
                        
            struct kernel_ext4_da_update_reserve_space_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_da_update_reserve_space_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_fscrypt_file_open_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_fscrypt_file_open_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 226;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_fscrypt_file_open_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 226;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_fscrypt_file_open_event_t stats_key_v = {};
            struct kernel_fscrypt_file_open_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 226;
            stats_key->ip = 226;
        
            
            
            
                        
            struct kernel_fscrypt_file_open_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_fscrypt_file_open_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_generate_from_pa_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_generate_from_pa_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 227;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_generate_from_pa_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 227;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_generate_from_pa_event_t stats_key_v = {};
            struct kernel_ext4_mb_generate_from_pa_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 227;
            stats_key->ip = 227;
        
            
            
            
                        
            struct kernel_ext4_mb_generate_from_pa_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_generate_from_pa_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_release_file_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_release_file_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 228;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_release_file_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 228;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_release_file_event_t stats_key_v = {};
            struct kernel_ext4_release_file_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 228;
            stats_key->ip = 228;
        
            
            
            
                        
            struct kernel_ext4_release_file_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_release_file_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_nonda_switch_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_nonda_switch_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 229;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_nonda_switch_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 229;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_nonda_switch_event_t stats_key_v = {};
            struct kernel_ext4_nonda_switch_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 229;
            stats_key->ip = 229;
        
            
            
            
                        
            struct kernel_ext4_nonda_switch_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_nonda_switch_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_extent_block_csum_set_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_extent_block_csum_set_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 230;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_extent_block_csum_set_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 230;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_extent_block_csum_set_event_t stats_key_v = {};
            struct kernel_ext4_extent_block_csum_set_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 230;
            stats_key->ip = 230;
        
            
            
            
                        
            struct kernel_ext4_extent_block_csum_set_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_extent_block_csum_set_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_truncate_pagecache_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_truncate_pagecache_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 231;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_truncate_pagecache_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 231;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_truncate_pagecache_event_t stats_key_v = {};
            struct kernel_truncate_pagecache_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 231;
            stats_key->ip = 231;
        
            
            
            
                        
            struct kernel_truncate_pagecache_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_truncate_pagecache_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_free_inodes_count_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_free_inodes_count_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 232;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_free_inodes_count_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 232;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_free_inodes_count_event_t stats_key_v = {};
            struct kernel_ext4_free_inodes_count_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 232;
            stats_key->ip = 232;
        
            
            
            
                        
            struct kernel_ext4_free_inodes_count_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_free_inodes_count_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_num_overhead_clusters_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_num_overhead_clusters_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 233;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_num_overhead_clusters_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 233;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_num_overhead_clusters_event_t stats_key_v = {};
            struct kernel_ext4_num_overhead_clusters_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 233;
            stats_key->ip = 233;
        
            
            
            
                        
            struct kernel_ext4_num_overhead_clusters_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_num_overhead_clusters_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_do_lock_file_wait_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_do_lock_file_wait_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 234;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_do_lock_file_wait_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 234;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_do_lock_file_wait_event_t stats_key_v = {};
            struct kernel_do_lock_file_wait_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 234;
            stats_key->ip = 234;
        
            
            
            
                        
            struct kernel_do_lock_file_wait_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_do_lock_file_wait_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_free_inodes_set_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_free_inodes_set_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 235;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_free_inodes_set_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 235;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_free_inodes_set_event_t stats_key_v = {};
            struct kernel_ext4_free_inodes_set_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 235;
            stats_key->ip = 235;
        
            
            
            
                        
            struct kernel_ext4_free_inodes_set_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_free_inodes_set_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_da_get_block_prep_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_da_get_block_prep_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 236;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_da_get_block_prep_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 236;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_da_get_block_prep_event_t stats_key_v = {};
            struct kernel_ext4_da_get_block_prep_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 236;
            stats_key->ip = 236;
        
            
            
            
                        
            struct kernel_ext4_da_get_block_prep_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_da_get_block_prep_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mark_bitmap_end_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mark_bitmap_end_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 237;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mark_bitmap_end_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 237;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mark_bitmap_end_event_t stats_key_v = {};
            struct kernel_ext4_mark_bitmap_end_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 237;
            stats_key->ip = 237;
        
            
            
            
                        
            struct kernel_ext4_mark_bitmap_end_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mark_bitmap_end_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_kernfs_unlink_open_file_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_kernfs_unlink_open_file_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 238;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_kernfs_unlink_open_file_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 238;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_kernfs_unlink_open_file_event_t stats_key_v = {};
            struct kernel_kernfs_unlink_open_file_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 238;
            stats_key->ip = 238;
        
            
            
            
                        
            struct kernel_kernfs_unlink_open_file_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_kernfs_unlink_open_file_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_iget_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_iget_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 239;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_iget_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 239;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_iget_event_t stats_key_v = {};
            struct kernel___ext4_iget_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 239;
            stats_key->ip = 239;
        
            
            
            
                        
            struct kernel___ext4_iget_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_iget_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_counter_uncharge_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_counter_uncharge_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 240;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_counter_uncharge_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 240;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_counter_uncharge_event_t stats_key_v = {};
            struct kernel_page_counter_uncharge_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 240;
            stats_key->ip = 240;
        
            
            
            
                        
            struct kernel_page_counter_uncharge_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_counter_uncharge_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___anon_inode_getfile_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___anon_inode_getfile_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 241;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___anon_inode_getfile_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 241;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___anon_inode_getfile_event_t stats_key_v = {};
            struct kernel___anon_inode_getfile_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 241;
            stats_key->ip = 241;
        
            
            
            
                        
            struct kernel___anon_inode_getfile_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___anon_inode_getfile_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_apparmor_file_truncate_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_apparmor_file_truncate_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 242;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_apparmor_file_truncate_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 242;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_apparmor_file_truncate_event_t stats_key_v = {};
            struct kernel_apparmor_file_truncate_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 242;
            stats_key->ip = 242;
        
            
            
            
                        
            struct kernel_apparmor_file_truncate_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_apparmor_file_truncate_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_next_allocated_block_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_next_allocated_block_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 243;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_next_allocated_block_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 243;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_next_allocated_block_event_t stats_key_v = {};
            struct kernel_ext4_ext_next_allocated_block_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 243;
            stats_key->ip = 243;
        
            
            
            
                        
            struct kernel_ext4_ext_next_allocated_block_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_next_allocated_block_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_associate_blkg_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_associate_blkg_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 244;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_associate_blkg_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 244;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_associate_blkg_event_t stats_key_v = {};
            struct kernel_bio_associate_blkg_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 244;
            stats_key->ip = 244;
        
            
            
            
                        
            struct kernel_bio_associate_blkg_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_associate_blkg_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_dio_write_checks_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_dio_write_checks_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 245;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_dio_write_checks_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 245;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_dio_write_checks_event_t stats_key_v = {};
            struct kernel_ext4_dio_write_checks_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 245;
            stats_key->ip = 245;
        
            
            
            
                        
            struct kernel_ext4_dio_write_checks_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_dio_write_checks_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_cpupid_xchg_last_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_cpupid_xchg_last_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 246;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_cpupid_xchg_last_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 246;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_cpupid_xchg_last_event_t stats_key_v = {};
            struct kernel_page_cpupid_xchg_last_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 246;
            stats_key->ip = 246;
        
            
            
            
                        
            struct kernel_page_cpupid_xchg_last_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_cpupid_xchg_last_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_init_cache_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_init_cache_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 247;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_init_cache_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 247;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_init_cache_event_t stats_key_v = {};
            struct kernel_ext4_mb_init_cache_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 247;
            stats_key->ip = 247;
        
            
            
            
                        
            struct kernel_ext4_mb_init_cache_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_init_cache_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_get_inode_loc_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_get_inode_loc_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 248;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_get_inode_loc_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 248;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_get_inode_loc_event_t stats_key_v = {};
            struct kernel_ext4_get_inode_loc_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 248;
            stats_key->ip = 248;
        
            
            
            
                        
            struct kernel_ext4_get_inode_loc_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_get_inode_loc_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_do_anonymous_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_do_anonymous_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 249;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_do_anonymous_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 249;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_do_anonymous_page_event_t stats_key_v = {};
            struct kernel_do_anonymous_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 249;
            stats_key->ip = 249;
        
            
            
            
                        
            struct kernel_do_anonymous_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_do_anonymous_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_destroy_inode_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_destroy_inode_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 250;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_destroy_inode_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 250;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_destroy_inode_event_t stats_key_v = {};
            struct kernel_ext4_destroy_inode_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 250;
            stats_key->ip = 250;
        
            
            
            
                        
            struct kernel_ext4_destroy_inode_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_destroy_inode_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_hook_file_open_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_hook_file_open_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 251;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_hook_file_open_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 251;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_hook_file_open_event_t stats_key_v = {};
            struct kernel_hook_file_open_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 251;
            stats_key->ip = 251;
        
            
            
            
                        
            struct kernel_hook_file_open_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_hook_file_open_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_fill_raw_inode_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_fill_raw_inode_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 252;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_fill_raw_inode_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 252;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_fill_raw_inode_event_t stats_key_v = {};
            struct kernel_ext4_fill_raw_inode_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 252;
            stats_key->ip = 252;
        
            
            
            
                        
            struct kernel_ext4_fill_raw_inode_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_fill_raw_inode_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_frag_free_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_frag_free_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 253;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_frag_free_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 253;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_frag_free_event_t stats_key_v = {};
            struct kernel_page_frag_free_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 253;
            stats_key->ip = 253;
        
            
            
            
                        
            struct kernel_page_frag_free_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_frag_free_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___page_set_anon_rmap_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___page_set_anon_rmap_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 254;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___page_set_anon_rmap_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 254;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___page_set_anon_rmap_event_t stats_key_v = {};
            struct kernel___page_set_anon_rmap_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 254;
            stats_key->ip = 254;
        
            
            
            
                        
            struct kernel___page_set_anon_rmap_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___page_set_anon_rmap_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_es_delayed_clu_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_es_delayed_clu_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 255;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_es_delayed_clu_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 255;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_es_delayed_clu_event_t stats_key_v = {};
            struct kernel_ext4_es_delayed_clu_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 255;
            stats_key->ip = 255;
        
            
            
            
                        
            struct kernel_ext4_es_delayed_clu_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_es_delayed_clu_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_inode_csum_set_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_inode_csum_set_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 256;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_inode_csum_set_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 256;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_inode_csum_set_event_t stats_key_v = {};
            struct kernel_ext4_inode_csum_set_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 256;
            stats_key->ip = 256;
        
            
            
            
                        
            struct kernel_ext4_inode_csum_set_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_inode_csum_set_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_fscrypt_mergeable_bio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_fscrypt_mergeable_bio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 257;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_fscrypt_mergeable_bio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 257;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_fscrypt_mergeable_bio_event_t stats_key_v = {};
            struct kernel_fscrypt_mergeable_bio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 257;
            stats_key->ip = 257;
        
            
            
            
                        
            struct kernel_fscrypt_mergeable_bio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_fscrypt_mergeable_bio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_mpage_prepare_extent_to_map_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_mpage_prepare_extent_to_map_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 258;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_mpage_prepare_extent_to_map_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 258;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_mpage_prepare_extent_to_map_event_t stats_key_v = {};
            struct kernel_mpage_prepare_extent_to_map_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 258;
            stats_key->ip = 258;
        
            
            
            
                        
            struct kernel_mpage_prepare_extent_to_map_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_mpage_prepare_extent_to_map_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_update_blocked_averages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_update_blocked_averages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 259;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_update_blocked_averages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 259;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_update_blocked_averages_event_t stats_key_v = {};
            struct kernel_update_blocked_averages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 259;
            stats_key->ip = 259;
        
            
            
            
                        
            struct kernel_update_blocked_averages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_update_blocked_averages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_chacha_block_generic_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_chacha_block_generic_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 260;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_chacha_block_generic_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 260;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_chacha_block_generic_event_t stats_key_v = {};
            struct kernel_chacha_block_generic_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 260;
            stats_key->ip = 260;
        
            
            
            
                        
            struct kernel_chacha_block_generic_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_chacha_block_generic_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_xattr_security_get_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_xattr_security_get_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 261;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_xattr_security_get_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 261;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_xattr_security_get_event_t stats_key_v = {};
            struct kernel_ext4_xattr_security_get_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 261;
            stats_key->ip = 261;
        
            
            
            
                        
            struct kernel_ext4_xattr_security_get_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_xattr_security_get_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_sample_last_mounted_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_sample_last_mounted_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 262;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_sample_last_mounted_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 262;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_sample_last_mounted_event_t stats_key_v = {};
            struct kernel_ext4_sample_last_mounted_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 262;
            stats_key->ip = 262;
        
            
            
            
                        
            struct kernel_ext4_sample_last_mounted_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_sample_last_mounted_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_generic_file_read_iter_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_generic_file_read_iter_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 263;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_generic_file_read_iter_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 263;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_generic_file_read_iter_event_t stats_key_v = {};
            struct kernel_generic_file_read_iter_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 263;
            stats_key->ip = 263;
        
            
            
            
                        
            struct kernel_generic_file_read_iter_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_generic_file_read_iter_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_set_page_dirty_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_set_page_dirty_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 264;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_set_page_dirty_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 264;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_set_page_dirty_event_t stats_key_v = {};
            struct kernel_set_page_dirty_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 264;
            stats_key->ip = 264;
        
            
            
            
                        
            struct kernel_set_page_dirty_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_set_page_dirty_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_hugetlb_total_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_hugetlb_total_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 265;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_hugetlb_total_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 265;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_hugetlb_total_pages_event_t stats_key_v = {};
            struct kernel_hugetlb_total_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 265;
            stats_key->ip = 265;
        
            
            
            
                        
            struct kernel_hugetlb_total_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_hugetlb_total_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_dirblock_csum_verify_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_dirblock_csum_verify_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 266;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_dirblock_csum_verify_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 266;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_dirblock_csum_verify_event_t stats_key_v = {};
            struct kernel_ext4_dirblock_csum_verify_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 266;
            stats_key->ip = 266;
        
            
            
            
                        
            struct kernel_ext4_dirblock_csum_verify_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_dirblock_csum_verify_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filename_lookup_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filename_lookup_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 267;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filename_lookup_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 267;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filename_lookup_event_t stats_key_v = {};
            struct kernel_filename_lookup_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 267;
            stats_key->ip = 267;
        
            
            
            
                        
            struct kernel_filename_lookup_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filename_lookup_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_dio_write_iter_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_dio_write_iter_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 268;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_dio_write_iter_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 268;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_dio_write_iter_event_t stats_key_v = {};
            struct kernel_ext4_dio_write_iter_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 268;
            stats_key->ip = 268;
        
            
            
            
                        
            struct kernel_ext4_dio_write_iter_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_dio_write_iter_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_orphan_del_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_orphan_del_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 269;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_orphan_del_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 269;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_orphan_del_event_t stats_key_v = {};
            struct kernel_ext4_orphan_del_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 269;
            stats_key->ip = 269;
        
            
            
            
                        
            struct kernel_ext4_orphan_del_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_orphan_del_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_xattr_get_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_xattr_get_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 270;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_xattr_get_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 270;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_xattr_get_event_t stats_key_v = {};
            struct kernel_ext4_xattr_get_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 270;
            stats_key->ip = 270;
        
            
            
            
                        
            struct kernel_ext4_xattr_get_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_xattr_get_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_set_aops_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_set_aops_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 271;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_set_aops_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 271;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_set_aops_event_t stats_key_v = {};
            struct kernel_ext4_set_aops_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 271;
            stats_key->ip = 271;
        
            
            
            
                        
            struct kernel_ext4_set_aops_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_set_aops_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_migrate_pages_batch_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_migrate_pages_batch_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 272;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_migrate_pages_batch_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 272;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_migrate_pages_batch_event_t stats_key_v = {};
            struct kernel_migrate_pages_batch_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 272;
            stats_key->ip = 272;
        
            
            
            
                        
            struct kernel_migrate_pages_batch_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_migrate_pages_batch_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_check_errors_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_check_errors_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 273;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_check_errors_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 273;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_check_errors_event_t stats_key_v = {};
            struct kernel_filemap_check_errors_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 273;
            stats_key->ip = 273;
        
            
            
            
                        
            struct kernel_filemap_check_errors_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_check_errors_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_new_inode_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_new_inode_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 274;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_new_inode_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 274;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_new_inode_event_t stats_key_v = {};
            struct kernel___ext4_new_inode_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 274;
            stats_key->ip = 274;
        
            
            
            
                        
            struct kernel___ext4_new_inode_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_new_inode_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_complex_scan_group_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_complex_scan_group_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 275;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_complex_scan_group_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 275;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_complex_scan_group_event_t stats_key_v = {};
            struct kernel_ext4_mb_complex_scan_group_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 275;
            stats_key->ip = 275;
        
            
            
            
                        
            struct kernel_ext4_mb_complex_scan_group_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_complex_scan_group_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_evict_inode_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_evict_inode_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 276;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_evict_inode_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 276;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_evict_inode_event_t stats_key_v = {};
            struct kernel_ext4_evict_inode_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 276;
            stats_key->ip = 276;
        
            
            
            
                        
            struct kernel_ext4_evict_inode_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_evict_inode_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_da_write_begin_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_da_write_begin_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 277;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_da_write_begin_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 277;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_da_write_begin_event_t stats_key_v = {};
            struct kernel_ext4_da_write_begin_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 277;
            stats_key->ip = 277;
        
            
            
            
                        
            struct kernel_ext4_da_write_begin_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_da_write_begin_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_apparmor_file_permission_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_apparmor_file_permission_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 278;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_apparmor_file_permission_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 278;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_apparmor_file_permission_event_t stats_key_v = {};
            struct kernel_apparmor_file_permission_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 278;
            stats_key->ip = 278;
        
            
            
            
                        
            struct kernel_apparmor_file_permission_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_apparmor_file_permission_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_iomap_dio_submit_bio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_iomap_dio_submit_bio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 279;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_iomap_dio_submit_bio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 279;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_iomap_dio_submit_bio_event_t stats_key_v = {};
            struct kernel_iomap_dio_submit_bio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 279;
            stats_key->ip = 279;
        
            
            
            
                        
            struct kernel_iomap_dio_submit_bio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_iomap_dio_submit_bio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_do_writepages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_do_writepages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 280;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_do_writepages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 280;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_do_writepages_event_t stats_key_v = {};
            struct kernel_do_writepages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 280;
            stats_key->ip = 280;
        
            
            
            
                        
            struct kernel_do_writepages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_do_writepages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_alloc_da_blocks_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_alloc_da_blocks_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 281;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_alloc_da_blocks_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 281;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_alloc_da_blocks_event_t stats_key_v = {};
            struct kernel_ext4_alloc_da_blocks_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 281;
            stats_key->ip = 281;
        
            
            
            
                        
            struct kernel_ext4_alloc_da_blocks_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_alloc_da_blocks_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___bio_split_to_limits_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___bio_split_to_limits_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 282;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___bio_split_to_limits_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 282;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___bio_split_to_limits_event_t stats_key_v = {};
            struct kernel___bio_split_to_limits_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 282;
            stats_key->ip = 282;
        
            
            
            
                        
            struct kernel___bio_split_to_limits_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___bio_split_to_limits_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_unlink_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_unlink_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 283;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_unlink_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 283;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_unlink_event_t stats_key_v = {};
            struct kernel___ext4_unlink_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 283;
            stats_key->ip = 283;
        
            
            
            
                        
            struct kernel___ext4_unlink_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_unlink_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_alloc_io_end_vec_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_alloc_io_end_vec_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 284;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_alloc_io_end_vec_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 284;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_alloc_io_end_vec_event_t stats_key_v = {};
            struct kernel_ext4_alloc_io_end_vec_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 284;
            stats_key->ip = 284;
        
            
            
            
                        
            struct kernel_ext4_alloc_io_end_vec_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_alloc_io_end_vec_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___page_cache_release_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___page_cache_release_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 285;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___page_cache_release_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 285;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___page_cache_release_event_t stats_key_v = {};
            struct kernel___page_cache_release_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 285;
            stats_key->ip = 285;
        
            
            
            
                        
            struct kernel___page_cache_release_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___page_cache_release_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_get_folios_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_get_folios_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 286;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_get_folios_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 286;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_get_folios_event_t stats_key_v = {};
            struct kernel_filemap_get_folios_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 286;
            stats_key->ip = 286;
        
            
            
            
                        
            struct kernel_filemap_get_folios_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_get_folios_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_free_group_clusters_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_free_group_clusters_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 287;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_free_group_clusters_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 287;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_free_group_clusters_event_t stats_key_v = {};
            struct kernel_ext4_free_group_clusters_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 287;
            stats_key->ip = 287;
        
            
            
            
                        
            struct kernel_ext4_free_group_clusters_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_free_group_clusters_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_cgroup_seqfile_show_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_cgroup_seqfile_show_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 288;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_cgroup_seqfile_show_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 288;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_cgroup_seqfile_show_event_t stats_key_v = {};
            struct kernel_cgroup_seqfile_show_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 288;
            stats_key->ip = 288;
        
            
            
            
                        
            struct kernel_cgroup_seqfile_show_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_cgroup_seqfile_show_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_add_nondir_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_add_nondir_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 289;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_add_nondir_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 289;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_add_nondir_event_t stats_key_v = {};
            struct kernel_ext4_add_nondir_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 289;
            stats_key->ip = 289;
        
            
            
            
                        
            struct kernel_ext4_add_nondir_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_add_nondir_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_prefetch_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_prefetch_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 290;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_prefetch_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 290;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_prefetch_event_t stats_key_v = {};
            struct kernel_ext4_mb_prefetch_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 290;
            stats_key->ip = 290;
        
            
            
            
                        
            struct kernel_ext4_mb_prefetch_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_prefetch_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_regular_allocator_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_regular_allocator_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 291;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_regular_allocator_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 291;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_regular_allocator_event_t stats_key_v = {};
            struct kernel_ext4_mb_regular_allocator_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 291;
            stats_key->ip = 291;
        
            
            
            
                        
            struct kernel_ext4_mb_regular_allocator_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_regular_allocator_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_forget_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_forget_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 292;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_forget_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 292;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_forget_event_t stats_key_v = {};
            struct kernel___ext4_forget_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 292;
            stats_key->ip = 292;
        
            
            
            
                        
            struct kernel___ext4_forget_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_forget_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_release_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_release_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 293;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_release_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 293;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_release_pages_event_t stats_key_v = {};
            struct kernel_release_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 293;
            stats_key->ip = 293;
        
            
            
            
                        
            struct kernel_release_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_release_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_datasem_ensure_credits_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_datasem_ensure_credits_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 294;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_datasem_ensure_credits_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 294;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_datasem_ensure_credits_event_t stats_key_v = {};
            struct kernel_ext4_datasem_ensure_credits_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 294;
            stats_key->ip = 294;
        
            
            
            
                        
            struct kernel_ext4_datasem_ensure_credits_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_datasem_ensure_credits_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_submit_bio_noacct_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_submit_bio_noacct_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 295;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_submit_bio_noacct_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 295;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_submit_bio_noacct_event_t stats_key_v = {};
            struct kernel_submit_bio_noacct_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 295;
            stats_key->ip = 295;
        
            
            
            
                        
            struct kernel_submit_bio_noacct_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_submit_bio_noacct_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_numamigrate_isolate_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_numamigrate_isolate_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 296;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_numamigrate_isolate_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 296;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_numamigrate_isolate_page_event_t stats_key_v = {};
            struct kernel_numamigrate_isolate_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 296;
            stats_key->ip = 296;
        
            
            
            
                        
            struct kernel_numamigrate_isolate_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_numamigrate_isolate_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___filename_parentat_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___filename_parentat_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 297;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___filename_parentat_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 297;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___filename_parentat_event_t stats_key_v = {};
            struct kernel___filename_parentat_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 297;
            stats_key->ip = 297;
        
            
            
            
                        
            struct kernel___filename_parentat_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___filename_parentat_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_end_bio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_end_bio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 298;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_end_bio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 298;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_end_bio_event_t stats_key_v = {};
            struct kernel_ext4_end_bio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 298;
            stats_key->ip = 298;
        
            
            
            
                        
            struct kernel_ext4_end_bio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_end_bio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_free_inode_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_free_inode_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 299;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_free_inode_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 299;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_free_inode_event_t stats_key_v = {};
            struct kernel_ext4_free_inode_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 299;
            stats_key->ip = 299;
        
            
            
            
                        
            struct kernel_ext4_free_inode_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_free_inode_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_fc_track_unlink_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_fc_track_unlink_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 300;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_fc_track_unlink_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 300;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_fc_track_unlink_event_t stats_key_v = {};
            struct kernel_ext4_fc_track_unlink_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 300;
            stats_key->ip = 300;
        
            
            
            
                        
            struct kernel_ext4_fc_track_unlink_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_fc_track_unlink_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_read_inode_bitmap_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_read_inode_bitmap_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 301;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_read_inode_bitmap_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 301;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_read_inode_bitmap_event_t stats_key_v = {};
            struct kernel_ext4_read_inode_bitmap_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 301;
            stats_key->ip = 301;
        
            
            
            
                        
            struct kernel_ext4_read_inode_bitmap_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_read_inode_bitmap_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_fc_init_inode_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_fc_init_inode_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 302;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_fc_init_inode_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 302;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_fc_init_inode_event_t stats_key_v = {};
            struct kernel_ext4_fc_init_inode_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 302;
            stats_key->ip = 302;
        
            
            
            
                        
            struct kernel_ext4_fc_init_inode_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_fc_init_inode_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_balance_dirty_pages_ratelimited_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_balance_dirty_pages_ratelimited_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 303;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_balance_dirty_pages_ratelimited_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 303;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_balance_dirty_pages_ratelimited_event_t stats_key_v = {};
            struct kernel_balance_dirty_pages_ratelimited_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 303;
            stats_key->ip = 303;
        
            
            
            
                        
            struct kernel_balance_dirty_pages_ratelimited_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_balance_dirty_pages_ratelimited_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_group_desc_csum_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_group_desc_csum_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 304;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_group_desc_csum_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 304;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_group_desc_csum_event_t stats_key_v = {};
            struct kernel_ext4_group_desc_csum_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 304;
            stats_key->ip = 304;
        
            
            
            
                        
            struct kernel_ext4_group_desc_csum_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_group_desc_csum_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___mod_lruvec_page_state_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___mod_lruvec_page_state_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 305;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___mod_lruvec_page_state_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 305;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___mod_lruvec_page_state_event_t stats_key_v = {};
            struct kernel___mod_lruvec_page_state_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 305;
            stats_key->ip = 305;
        
            
            
            
                        
            struct kernel___mod_lruvec_page_state_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___mod_lruvec_page_state_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_check_limits_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_check_limits_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 306;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_check_limits_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 306;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_check_limits_event_t stats_key_v = {};
            struct kernel_ext4_mb_check_limits_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 306;
            stats_key->ip = 306;
        
            
            
            
                        
            struct kernel_ext4_mb_check_limits_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_check_limits_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_pa_put_free_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_pa_put_free_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 307;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_pa_put_free_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 307;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_pa_put_free_event_t stats_key_v = {};
            struct kernel_ext4_mb_pa_put_free_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 307;
            stats_key->ip = 307;
        
            
            
            
                        
            struct kernel_ext4_mb_pa_put_free_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_pa_put_free_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_search_dir_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_search_dir_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 308;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_search_dir_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 308;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_search_dir_event_t stats_key_v = {};
            struct kernel_ext4_search_dir_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 308;
            stats_key->ip = 308;
        
            
            
            
                        
            struct kernel_ext4_search_dir_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_search_dir_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_vmap_pages_pud_range_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_vmap_pages_pud_range_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 309;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_vmap_pages_pud_range_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 309;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_vmap_pages_pud_range_event_t stats_key_v = {};
            struct kernel_vmap_pages_pud_range_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 309;
            stats_key->ip = 309;
        
            
            
            
                        
            struct kernel_vmap_pages_pud_range_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_vmap_pages_pud_range_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_mod_node_page_state_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_mod_node_page_state_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 310;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_mod_node_page_state_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 310;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_mod_node_page_state_event_t stats_key_v = {};
            struct kernel_mod_node_page_state_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 310;
            stats_key->ip = 310;
        
            
            
            
                        
            struct kernel_mod_node_page_state_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_mod_node_page_state_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_crypt_rq_ctx_compatible_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_crypt_rq_ctx_compatible_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 311;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_crypt_rq_ctx_compatible_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 311;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_crypt_rq_ctx_compatible_event_t stats_key_v = {};
            struct kernel_bio_crypt_rq_ctx_compatible_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 311;
            stats_key->ip = 311;
        
            
            
            
                        
            struct kernel_bio_crypt_rq_ctx_compatible_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_crypt_rq_ctx_compatible_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_iomap_dio_bio_iter_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_iomap_dio_bio_iter_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 312;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_iomap_dio_bio_iter_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 312;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_iomap_dio_bio_iter_event_t stats_key_v = {};
            struct kernel_iomap_dio_bio_iter_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 312;
            stats_key->ip = 312;
        
            
            
            
                        
            struct kernel_iomap_dio_bio_iter_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_iomap_dio_bio_iter_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_associate_blkg_from_css_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_associate_blkg_from_css_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 313;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_associate_blkg_from_css_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 313;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_associate_blkg_from_css_event_t stats_key_v = {};
            struct kernel_bio_associate_blkg_from_css_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 313;
            stats_key->ip = 313;
        
            
            
            
                        
            struct kernel_bio_associate_blkg_from_css_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_associate_blkg_from_css_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_clear_inode_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_clear_inode_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 314;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_clear_inode_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 314;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_clear_inode_event_t stats_key_v = {};
            struct kernel_ext4_clear_inode_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 314;
            stats_key->ip = 314;
        
            
            
            
                        
            struct kernel_ext4_clear_inode_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_clear_inode_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_dax_layout_busy_page_range_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_dax_layout_busy_page_range_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 315;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_dax_layout_busy_page_range_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 315;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_dax_layout_busy_page_range_event_t stats_key_v = {};
            struct kernel_dax_layout_busy_page_range_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 315;
            stats_key->ip = 315;
        
            
            
            
                        
            struct kernel_dax_layout_busy_page_range_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_dax_layout_busy_page_range_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___filemap_fdatawait_range_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___filemap_fdatawait_range_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 316;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___filemap_fdatawait_range_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 316;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___filemap_fdatawait_range_event_t stats_key_v = {};
            struct kernel___filemap_fdatawait_range_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 316;
            stats_key->ip = 316;
        
            
            
            
                        
            struct kernel___filemap_fdatawait_range_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___filemap_fdatawait_range_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_set_pfnblock_flags_mask_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_set_pfnblock_flags_mask_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 317;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_set_pfnblock_flags_mask_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 317;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_set_pfnblock_flags_mask_event_t stats_key_v = {};
            struct kernel_set_pfnblock_flags_mask_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 317;
            stats_key->ip = 317;
        
            
            
            
                        
            struct kernel_set_pfnblock_flags_mask_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_set_pfnblock_flags_mask_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_get_user_pages_fast_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_get_user_pages_fast_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 318;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_get_user_pages_fast_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 318;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_get_user_pages_fast_event_t stats_key_v = {};
            struct kernel_get_user_pages_fast_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 318;
            stats_key->ip = 318;
        
            
            
            
                        
            struct kernel_get_user_pages_fast_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_get_user_pages_fast_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_put_io_end_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_put_io_end_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 319;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_put_io_end_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 319;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_put_io_end_event_t stats_key_v = {};
            struct kernel_ext4_put_io_end_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 319;
            stats_key->ip = 319;
        
            
            
            
                        
            struct kernel_ext4_put_io_end_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_put_io_end_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_get_dquots_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_get_dquots_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 320;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_get_dquots_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 320;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_get_dquots_event_t stats_key_v = {};
            struct kernel_ext4_get_dquots_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 320;
            stats_key->ip = 320;
        
            
            
            
                        
            struct kernel_ext4_get_dquots_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_get_dquots_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___vmap_pages_range_noflush_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___vmap_pages_range_noflush_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 321;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___vmap_pages_range_noflush_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 321;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___vmap_pages_range_noflush_event_t stats_key_v = {};
            struct kernel___vmap_pages_range_noflush_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 321;
            stats_key->ip = 321;
        
            
            
            
                        
            struct kernel___vmap_pages_range_noflush_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___vmap_pages_range_noflush_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_free_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_free_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 322;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_free_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 322;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_free_event_t stats_key_v = {};
            struct kernel_bio_free_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 322;
            stats_key->ip = 322;
        
            
            
            
                        
            struct kernel_bio_free_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_free_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_alloc_folio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_alloc_folio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 323;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_alloc_folio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 323;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_alloc_folio_event_t stats_key_v = {};
            struct kernel_filemap_alloc_folio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 323;
            stats_key->ip = 323;
        
            
            
            
                        
            struct kernel_filemap_alloc_folio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_alloc_folio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_is_file_shm_hugepages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_is_file_shm_hugepages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 324;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_is_file_shm_hugepages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 324;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_is_file_shm_hugepages_event_t stats_key_v = {};
            struct kernel_is_file_shm_hugepages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 324;
            stats_key->ip = 324;
        
            
            
            
                        
            struct kernel_is_file_shm_hugepages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_is_file_shm_hugepages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_frag_alloc_align_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_frag_alloc_align_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 325;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_frag_alloc_align_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 325;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_frag_alloc_align_event_t stats_key_v = {};
            struct kernel_page_frag_alloc_align_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 325;
            stats_key->ip = 325;
        
            
            
            
                        
            struct kernel_page_frag_alloc_align_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_frag_alloc_align_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_locks_remove_file_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_locks_remove_file_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 326;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_locks_remove_file_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 326;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_locks_remove_file_event_t stats_key_v = {};
            struct kernel_locks_remove_file_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 326;
            stats_key->ip = 326;
        
            
            
            
                        
            struct kernel_locks_remove_file_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_locks_remove_file_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_pagecache_isize_extended_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_pagecache_isize_extended_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 327;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_pagecache_isize_extended_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 327;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_pagecache_isize_extended_event_t stats_key_v = {};
            struct kernel_pagecache_isize_extended_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 327;
            stats_key->ip = 327;
        
            
            
            
                        
            struct kernel_pagecache_isize_extended_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_pagecache_isize_extended_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___update_load_avg_blocked_se_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___update_load_avg_blocked_se_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 328;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___update_load_avg_blocked_se_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 328;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___update_load_avg_blocked_se_event_t stats_key_v = {};
            struct kernel___update_load_avg_blocked_se_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 328;
            stats_key->ip = 328;
        
            
            
            
                        
            struct kernel___update_load_avg_blocked_se_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___update_load_avg_blocked_se_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel__ext4_show_options_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel__ext4_show_options_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 329;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel__ext4_show_options_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 329;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel__ext4_show_options_event_t stats_key_v = {};
            struct kernel__ext4_show_options_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 329;
            stats_key->ip = 329;
        
            
            
            
                        
            struct kernel__ext4_show_options_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel__ext4_show_options_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_file_write_iter_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_file_write_iter_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 330;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_file_write_iter_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 330;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_file_write_iter_event_t stats_key_v = {};
            struct kernel_ext4_file_write_iter_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 330;
            stats_key->ip = 330;
        
            
            
            
                        
            struct kernel_ext4_file_write_iter_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_file_write_iter_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_last_io_end_vec_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_last_io_end_vec_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 331;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_last_io_end_vec_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 331;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_last_io_end_vec_event_t stats_key_v = {};
            struct kernel_ext4_last_io_end_vec_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 331;
            stats_key->ip = 331;
        
            
            
            
                        
            struct kernel_ext4_last_io_end_vec_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_last_io_end_vec_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_crypt_ctx_mergeable_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_crypt_ctx_mergeable_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 332;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_crypt_ctx_mergeable_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 332;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_crypt_ctx_mergeable_event_t stats_key_v = {};
            struct kernel_bio_crypt_ctx_mergeable_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 332;
            stats_key->ip = 332;
        
            
            
            
                        
            struct kernel_bio_crypt_ctx_mergeable_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_crypt_ctx_mergeable_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_dquot_file_open_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_dquot_file_open_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 333;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_dquot_file_open_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 333;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_dquot_file_open_event_t stats_key_v = {};
            struct kernel_dquot_file_open_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 333;
            stats_key->ip = 333;
        
            
            
            
                        
            struct kernel_dquot_file_open_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_dquot_file_open_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___bio_add_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___bio_add_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 334;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___bio_add_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 334;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___bio_add_page_event_t stats_key_v = {};
            struct kernel___bio_add_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 334;
            stats_key->ip = 334;
        
            
            
            
                        
            struct kernel___bio_add_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___bio_add_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_unaccount_folio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_unaccount_folio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 335;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_unaccount_folio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 335;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_unaccount_folio_event_t stats_key_v = {};
            struct kernel_filemap_unaccount_folio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 335;
            stats_key->ip = 335;
        
            
            
            
                        
            struct kernel_filemap_unaccount_folio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_unaccount_folio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_mapping_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_mapping_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 336;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_mapping_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 336;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_mapping_event_t stats_key_v = {};
            struct kernel_page_mapping_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 336;
            stats_key->ip = 336;
        
            
            
            
                        
            struct kernel_page_mapping_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_mapping_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_get_inode_loc_noinmem_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_get_inode_loc_noinmem_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 337;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_get_inode_loc_noinmem_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 337;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_get_inode_loc_noinmem_event_t stats_key_v = {};
            struct kernel___ext4_get_inode_loc_noinmem_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 337;
            stats_key->ip = 337;
        
            
            
            
                        
            struct kernel___ext4_get_inode_loc_noinmem_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_get_inode_loc_noinmem_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_get_entry_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_get_entry_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 338;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_get_entry_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 338;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_get_entry_event_t stats_key_v = {};
            struct kernel_filemap_get_entry_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 338;
            stats_key->ip = 338;
        
            
            
            
                        
            struct kernel_filemap_get_entry_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_get_entry_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_queue_logical_block_size_show_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_queue_logical_block_size_show_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 339;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_queue_logical_block_size_show_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 339;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_queue_logical_block_size_show_event_t stats_key_v = {};
            struct kernel_queue_logical_block_size_show_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 339;
            stats_key->ip = 339;
        
            
            
            
                        
            struct kernel_queue_logical_block_size_show_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_queue_logical_block_size_show_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_block_bitmap_csum_verify_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_block_bitmap_csum_verify_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 340;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_block_bitmap_csum_verify_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 340;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_block_bitmap_csum_verify_event_t stats_key_v = {};
            struct kernel_ext4_block_bitmap_csum_verify_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 340;
            stats_key->ip = 340;
        
            
            
            
                        
            struct kernel_ext4_block_bitmap_csum_verify_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_block_bitmap_csum_verify_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_unlink_file_vma_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_unlink_file_vma_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 341;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_unlink_file_vma_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 341;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_unlink_file_vma_event_t stats_key_v = {};
            struct kernel_unlink_file_vma_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 341;
            stats_key->ip = 341;
        
            
            
            
                        
            struct kernel_unlink_file_vma_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_unlink_file_vma_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_pat_pagerange_is_ram_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_pat_pagerange_is_ram_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 342;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_pat_pagerange_is_ram_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 342;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_pat_pagerange_is_ram_event_t stats_key_v = {};
            struct kernel_pat_pagerange_is_ram_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 342;
            stats_key->ip = 342;
        
            
            
            
                        
            struct kernel_pat_pagerange_is_ram_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_pat_pagerange_is_ram_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_truncate_inode_pages_final_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_truncate_inode_pages_final_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 343;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_truncate_inode_pages_final_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 343;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_truncate_inode_pages_final_event_t stats_key_v = {};
            struct kernel_truncate_inode_pages_final_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 343;
            stats_key->ip = 343;
        
            
            
            
                        
            struct kernel_truncate_inode_pages_final_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_truncate_inode_pages_final_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_balance_dirty_pages_ratelimited_flags_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_balance_dirty_pages_ratelimited_flags_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 344;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_balance_dirty_pages_ratelimited_flags_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 344;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_balance_dirty_pages_ratelimited_flags_event_t stats_key_v = {};
            struct kernel_balance_dirty_pages_ratelimited_flags_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 344;
            stats_key->ip = 344;
        
            
            
            
                        
            struct kernel_balance_dirty_pages_ratelimited_flags_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_balance_dirty_pages_ratelimited_flags_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_journal_ensure_credits_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_journal_ensure_credits_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 345;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_journal_ensure_credits_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 345;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_journal_ensure_credits_event_t stats_key_v = {};
            struct kernel___ext4_journal_ensure_credits_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 345;
            stats_key->ip = 345;
        
            
            
            
                        
            struct kernel___ext4_journal_ensure_credits_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_journal_ensure_credits_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_blk_integrity_merge_bio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_blk_integrity_merge_bio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 346;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_blk_integrity_merge_bio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 346;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_blk_integrity_merge_bio_event_t stats_key_v = {};
            struct kernel_blk_integrity_merge_bio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 346;
            stats_key->ip = 346;
        
            
            
            
                        
            struct kernel_blk_integrity_merge_bio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_blk_integrity_merge_bio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_next_uptodate_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_next_uptodate_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 347;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_next_uptodate_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 347;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_next_uptodate_page_event_t stats_key_v = {};
            struct kernel_next_uptodate_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 347;
            stats_key->ip = 347;
        
            
            
            
                        
            struct kernel_next_uptodate_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_next_uptodate_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_blk_account_io_merge_bio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_blk_account_io_merge_bio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 348;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_blk_account_io_merge_bio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 348;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_blk_account_io_merge_bio_event_t stats_key_v = {};
            struct kernel_blk_account_io_merge_bio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 348;
            stats_key->ip = 348;
        
            
            
            
                        
            struct kernel_blk_account_io_merge_bio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_blk_account_io_merge_bio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_writepage_trans_blocks_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_writepage_trans_blocks_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 349;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_writepage_trans_blocks_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 349;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_writepage_trans_blocks_event_t stats_key_v = {};
            struct kernel_ext4_writepage_trans_blocks_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 349;
            stats_key->ip = 349;
        
            
            
            
                        
            struct kernel_ext4_writepage_trans_blocks_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_writepage_trans_blocks_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_da_write_end_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_da_write_end_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 350;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_da_write_end_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 350;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_da_write_end_event_t stats_key_v = {};
            struct kernel_ext4_da_write_end_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 350;
            stats_key->ip = 350;
        
            
            
            
                        
            struct kernel_ext4_da_write_end_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_da_write_end_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_vfs_getattr_nosec_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_vfs_getattr_nosec_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 351;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_vfs_getattr_nosec_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 351;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_vfs_getattr_nosec_event_t stats_key_v = {};
            struct kernel_vfs_getattr_nosec_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 351;
            stats_key->ip = 351;
        
            
            
            
                        
            struct kernel_vfs_getattr_nosec_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_vfs_getattr_nosec_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___memcg_kmem_uncharge_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___memcg_kmem_uncharge_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 352;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___memcg_kmem_uncharge_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 352;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___memcg_kmem_uncharge_page_event_t stats_key_v = {};
            struct kernel___memcg_kmem_uncharge_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 352;
            stats_key->ip = 352;
        
            
            
            
                        
            struct kernel___memcg_kmem_uncharge_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___memcg_kmem_uncharge_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_inode_extension_cleanup_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_inode_extension_cleanup_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 353;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_inode_extension_cleanup_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 353;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_inode_extension_cleanup_event_t stats_key_v = {};
            struct kernel_ext4_inode_extension_cleanup_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 353;
            stats_key->ip = 353;
        
            
            
            
                        
            struct kernel_ext4_inode_extension_cleanup_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_inode_extension_cleanup_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_fault_dirty_shared_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_fault_dirty_shared_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 354;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_fault_dirty_shared_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 354;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_fault_dirty_shared_page_event_t stats_key_v = {};
            struct kernel_fault_dirty_shared_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 354;
            stats_key->ip = 354;
        
            
            
            
                        
            struct kernel_fault_dirty_shared_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_fault_dirty_shared_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_handle_dirty_dirblock_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_handle_dirty_dirblock_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 355;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_handle_dirty_dirblock_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 355;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_handle_dirty_dirblock_event_t stats_key_v = {};
            struct kernel_ext4_handle_dirty_dirblock_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 355;
            stats_key->ip = 355;
        
            
            
            
                        
            struct kernel_ext4_handle_dirty_dirblock_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_handle_dirty_dirblock_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_iomap_end_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_iomap_end_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 356;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_iomap_end_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 356;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_iomap_end_event_t stats_key_v = {};
            struct kernel_ext4_iomap_end_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 356;
            stats_key->ip = 356;
        
            
            
            
                        
            struct kernel_ext4_iomap_end_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_iomap_end_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_kiocb_invalidate_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_kiocb_invalidate_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 357;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_kiocb_invalidate_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 357;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_kiocb_invalidate_pages_event_t stats_key_v = {};
            struct kernel_kiocb_invalidate_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 357;
            stats_key->ip = 357;
        
            
            
            
                        
            struct kernel_kiocb_invalidate_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_kiocb_invalidate_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_node_page_state_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_node_page_state_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 358;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_node_page_state_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 358;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_node_page_state_event_t stats_key_v = {};
            struct kernel_node_page_state_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 358;
            stats_key->ip = 358;
        
            
            
            
                        
            struct kernel_node_page_state_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_node_page_state_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___read_extent_tree_block_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___read_extent_tree_block_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 359;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___read_extent_tree_block_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 359;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___read_extent_tree_block_event_t stats_key_v = {};
            struct kernel___read_extent_tree_block_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 359;
            stats_key->ip = 359;
        
            
            
            
                        
            struct kernel___read_extent_tree_block_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___read_extent_tree_block_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_bread_batch_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_bread_batch_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 360;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_bread_batch_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 360;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_bread_batch_event_t stats_key_v = {};
            struct kernel_ext4_bread_batch_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 360;
            stats_key->ip = 360;
        
            
            
            
                        
            struct kernel_ext4_bread_batch_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_bread_batch_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___file_remove_privs_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___file_remove_privs_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 361;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___file_remove_privs_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 361;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___file_remove_privs_event_t stats_key_v = {};
            struct kernel___file_remove_privs_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 361;
            stats_key->ip = 361;
        
            
            
            
                        
            struct kernel___file_remove_privs_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___file_remove_privs_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_block_bitmap_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_block_bitmap_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 362;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_block_bitmap_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 362;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_block_bitmap_event_t stats_key_v = {};
            struct kernel_ext4_block_bitmap_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 362;
            stats_key->ip = 362;
        
            
            
            
                        
            struct kernel_ext4_block_bitmap_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_block_bitmap_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_vfs_open_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_vfs_open_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 363;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_vfs_open_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 363;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_vfs_open_event_t stats_key_v = {};
            struct kernel_vfs_open_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 363;
            stats_key->ip = 363;
        
            
            
            
                        
            struct kernel_vfs_open_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_vfs_open_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_init_security_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_init_security_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 364;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_init_security_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 364;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_init_security_event_t stats_key_v = {};
            struct kernel_ext4_init_security_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 364;
            stats_key->ip = 364;
        
            
            
            
                        
            struct kernel_ext4_init_security_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_init_security_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_fc_track_create_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_fc_track_create_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 365;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_fc_track_create_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 365;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_fc_track_create_event_t stats_key_v = {};
            struct kernel_ext4_fc_track_create_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 365;
            stats_key->ip = 365;
        
            
            
            
                        
            struct kernel_ext4_fc_track_create_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_fc_track_create_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_es_insert_delayed_block_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_es_insert_delayed_block_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 366;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_es_insert_delayed_block_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 366;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_es_insert_delayed_block_event_t stats_key_v = {};
            struct kernel_ext4_es_insert_delayed_block_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 366;
            stats_key->ip = 366;
        
            
            
            
                        
            struct kernel_ext4_es_insert_delayed_block_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_es_insert_delayed_block_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___mod_node_page_state_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___mod_node_page_state_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 367;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___mod_node_page_state_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 367;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___mod_node_page_state_event_t stats_key_v = {};
            struct kernel___mod_node_page_state_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 367;
            stats_key->ip = 367;
        
            
            
            
                        
            struct kernel___mod_node_page_state_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___mod_node_page_state_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_do_wp_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_do_wp_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 368;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_do_wp_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 368;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_do_wp_page_event_t stats_key_v = {};
            struct kernel_do_wp_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 368;
            stats_key->ip = 368;
        
            
            
            
                        
            struct kernel_do_wp_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_do_wp_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_init_io_end_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_init_io_end_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 369;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_init_io_end_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 369;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_init_io_end_event_t stats_key_v = {};
            struct kernel_ext4_init_io_end_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 369;
            stats_key->ip = 369;
        
            
            
            
                        
            struct kernel_ext4_init_io_end_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_init_io_end_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_shmem_kernel_file_setup_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_shmem_kernel_file_setup_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 370;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_shmem_kernel_file_setup_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 370;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_shmem_kernel_file_setup_event_t stats_key_v = {};
            struct kernel_shmem_kernel_file_setup_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 370;
            stats_key->ip = 370;
        
            
            
            
                        
            struct kernel_shmem_kernel_file_setup_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_shmem_kernel_file_setup_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_vfs_readlink_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_vfs_readlink_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 371;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_vfs_readlink_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 371;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_vfs_readlink_event_t stats_key_v = {};
            struct kernel_vfs_readlink_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 371;
            stats_key->ip = 371;
        
            
            
            
                        
            struct kernel_vfs_readlink_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_vfs_readlink_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_uninit_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_uninit_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 372;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_uninit_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 372;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_uninit_event_t stats_key_v = {};
            struct kernel_bio_uninit_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 372;
            stats_key->ip = 372;
        
            
            
            
                        
            struct kernel_bio_uninit_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_uninit_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_delete_entry_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_delete_entry_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 373;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_delete_entry_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 373;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_delete_entry_event_t stats_key_v = {};
            struct kernel_ext4_delete_entry_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 373;
            stats_key->ip = 373;
        
            
            
            
                        
            struct kernel_ext4_delete_entry_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_delete_entry_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_check_inode_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_check_inode_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 374;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_check_inode_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 374;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_check_inode_event_t stats_key_v = {};
            struct kernel_ext4_ext_check_inode_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 374;
            stats_key->ip = 374;
        
            
            
            
                        
            struct kernel_ext4_ext_check_inode_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_check_inode_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_obj_cgroup_uncharge_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_obj_cgroup_uncharge_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 375;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_obj_cgroup_uncharge_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 375;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_obj_cgroup_uncharge_pages_event_t stats_key_v = {};
            struct kernel_obj_cgroup_uncharge_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 375;
            stats_key->ip = 375;
        
            
            
            
                        
            struct kernel_obj_cgroup_uncharge_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_obj_cgroup_uncharge_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_vfs_statx_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_vfs_statx_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 376;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_vfs_statx_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 376;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_vfs_statx_event_t stats_key_v = {};
            struct kernel_vfs_statx_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 376;
            stats_key->ip = 376;
        
            
            
            
                        
            struct kernel_vfs_statx_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_vfs_statx_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___bio_iov_iter_get_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___bio_iov_iter_get_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 377;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___bio_iov_iter_get_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 377;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___bio_iov_iter_get_pages_event_t stats_key_v = {};
            struct kernel___bio_iov_iter_get_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 377;
            stats_key->ip = 377;
        
            
            
            
                        
            struct kernel___bio_iov_iter_get_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___bio_iov_iter_get_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ioctl_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ioctl_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 378;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ioctl_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 378;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ioctl_event_t stats_key_v = {};
            struct kernel_ext4_ioctl_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 378;
            stats_key->ip = 378;
        
            
            
            
                        
            struct kernel_ext4_ioctl_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ioctl_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_htree_dirblock_to_tree_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_htree_dirblock_to_tree_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 379;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_htree_dirblock_to_tree_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 379;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_htree_dirblock_to_tree_event_t stats_key_v = {};
            struct kernel_htree_dirblock_to_tree_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 379;
            stats_key->ip = 379;
        
            
            
            
                        
            struct kernel_htree_dirblock_to_tree_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_htree_dirblock_to_tree_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_map_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_map_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 380;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_map_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 380;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_map_pages_event_t stats_key_v = {};
            struct kernel_filemap_map_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 380;
            stats_key->ip = 380;
        
            
            
            
                        
            struct kernel_filemap_map_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_map_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_pcpu_block_update_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_pcpu_block_update_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 381;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_pcpu_block_update_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 381;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_pcpu_block_update_event_t stats_key_v = {};
            struct kernel_pcpu_block_update_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 381;
            stats_key->ip = 381;
        
            
            
            
                        
            struct kernel_pcpu_block_update_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_pcpu_block_update_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_sync_file_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_sync_file_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 382;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_sync_file_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 382;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_sync_file_event_t stats_key_v = {};
            struct kernel_ext4_sync_file_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 382;
            stats_key->ip = 382;
        
            
            
            
                        
            struct kernel_ext4_sync_file_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_sync_file_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_free_metadata_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_free_metadata_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 383;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_free_metadata_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 383;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_free_metadata_event_t stats_key_v = {};
            struct kernel_ext4_mb_free_metadata_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 383;
            stats_key->ip = 383;
        
            
            
            
                        
            struct kernel_ext4_mb_free_metadata_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_free_metadata_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_shmem_add_to_page_cache_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_shmem_add_to_page_cache_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 384;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_shmem_add_to_page_cache_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 384;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_shmem_add_to_page_cache_event_t stats_key_v = {};
            struct kernel_shmem_add_to_page_cache_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 384;
            stats_key->ip = 384;
        
            
            
            
                        
            struct kernel_shmem_add_to_page_cache_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_shmem_add_to_page_cache_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___set_task_blocked_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___set_task_blocked_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 385;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___set_task_blocked_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 385;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___set_task_blocked_event_t stats_key_v = {};
            struct kernel___set_task_blocked_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 385;
            stats_key->ip = 385;
        
            
            
            
                        
            struct kernel___set_task_blocked_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___set_task_blocked_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_chain_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_chain_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 386;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_chain_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 386;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_chain_event_t stats_key_v = {};
            struct kernel_bio_chain_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 386;
            stats_key->ip = 386;
        
            
            
            
                        
            struct kernel_bio_chain_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_chain_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___find_get_block_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___find_get_block_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 387;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___find_get_block_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 387;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___find_get_block_event_t stats_key_v = {};
            struct kernel___find_get_block_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 387;
            stats_key->ip = 387;
        
            
            
            
                        
            struct kernel___find_get_block_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___find_get_block_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_block_bitmap_csum_set_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_block_bitmap_csum_set_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 388;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_block_bitmap_csum_set_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 388;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_block_bitmap_csum_set_event_t stats_key_v = {};
            struct kernel_ext4_block_bitmap_csum_set_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 388;
            stats_key->ip = 388;
        
            
            
            
                        
            struct kernel_ext4_block_bitmap_csum_set_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_block_bitmap_csum_set_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_mod_zone_page_state_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_mod_zone_page_state_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 389;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_mod_zone_page_state_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 389;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_mod_zone_page_state_event_t stats_key_v = {};
            struct kernel_mod_zone_page_state_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 389;
            stats_key->ip = 389;
        
            
            
            
                        
            struct kernel_mod_zone_page_state_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_mod_zone_page_state_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_vmalloc_nr_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_vmalloc_nr_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 390;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_vmalloc_nr_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 390;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_vmalloc_nr_pages_event_t stats_key_v = {};
            struct kernel_vmalloc_nr_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 390;
            stats_key->ip = 390;
        
            
            
            
                        
            struct kernel_vmalloc_nr_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_vmalloc_nr_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_validate_block_bitmap_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_validate_block_bitmap_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 391;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_validate_block_bitmap_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 391;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_validate_block_bitmap_event_t stats_key_v = {};
            struct kernel_ext4_validate_block_bitmap_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 391;
            stats_key->ip = 391;
        
            
            
            
                        
            struct kernel_ext4_validate_block_bitmap_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_validate_block_bitmap_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_security_mmap_file_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_security_mmap_file_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 392;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_security_mmap_file_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 392;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_security_mmap_file_event_t stats_key_v = {};
            struct kernel_security_mmap_file_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 392;
            stats_key->ip = 392;
        
            
            
            
                        
            struct kernel_security_mmap_file_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_security_mmap_file_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_mpage_release_unused_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_mpage_release_unused_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 393;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_mpage_release_unused_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 393;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_mpage_release_unused_pages_event_t stats_key_v = {};
            struct kernel_mpage_release_unused_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 393;
            stats_key->ip = 393;
        
            
            
            
                        
            struct kernel_mpage_release_unused_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_mpage_release_unused_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___alloc_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___alloc_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 394;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___alloc_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 394;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___alloc_pages_event_t stats_key_v = {};
            struct kernel___alloc_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 394;
            stats_key->ip = 394;
        
            
            
            
                        
            struct kernel___alloc_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___alloc_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_getattr_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_getattr_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 395;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_getattr_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 395;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_getattr_event_t stats_key_v = {};
            struct kernel_ext4_getattr_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 395;
            stats_key->ip = 395;
        
            
            
            
                        
            struct kernel_ext4_getattr_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_getattr_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_match_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_match_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 396;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_match_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 396;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_match_event_t stats_key_v = {};
            struct kernel_ext4_match_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 396;
            stats_key->ip = 396;
        
            
            
            
                        
            struct kernel_ext4_match_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_match_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_add_anon_rmap_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_add_anon_rmap_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 397;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_add_anon_rmap_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 397;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_add_anon_rmap_event_t stats_key_v = {};
            struct kernel_page_add_anon_rmap_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 397;
            stats_key->ip = 397;
        
            
            
            
                        
            struct kernel_page_add_anon_rmap_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_add_anon_rmap_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___shmem_file_setup_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___shmem_file_setup_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 398;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___shmem_file_setup_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 398;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___shmem_file_setup_event_t stats_key_v = {};
            struct kernel___shmem_file_setup_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 398;
            stats_key->ip = 398;
        
            
            
            
                        
            struct kernel___shmem_file_setup_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___shmem_file_setup_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_da_reserve_space_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_da_reserve_space_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 399;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_da_reserve_space_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 399;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_da_reserve_space_event_t stats_key_v = {};
            struct kernel_ext4_da_reserve_space_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 399;
            stats_key->ip = 399;
        
            
            
            
                        
            struct kernel_ext4_da_reserve_space_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_da_reserve_space_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_unlock_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_unlock_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 400;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_unlock_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 400;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_unlock_page_event_t stats_key_v = {};
            struct kernel_unlock_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 400;
            stats_key->ip = 400;
        
            
            
            
                        
            struct kernel_unlock_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_unlock_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_handle_dirty_metadata_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_handle_dirty_metadata_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 401;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_handle_dirty_metadata_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 401;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_handle_dirty_metadata_event_t stats_key_v = {};
            struct kernel___ext4_handle_dirty_metadata_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 401;
            stats_key->ip = 401;
        
            
            
            
                        
            struct kernel___ext4_handle_dirty_metadata_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_handle_dirty_metadata_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_prefetch_fini_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_prefetch_fini_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 402;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_prefetch_fini_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 402;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_prefetch_fini_event_t stats_key_v = {};
            struct kernel_ext4_mb_prefetch_fini_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 402;
            stats_key->ip = 402;
        
            
            
            
                        
            struct kernel_ext4_mb_prefetch_fini_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_prefetch_fini_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_generic_delete_entry_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_generic_delete_entry_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 403;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_generic_delete_entry_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 403;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_generic_delete_entry_event_t stats_key_v = {};
            struct kernel_ext4_generic_delete_entry_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 403;
            stats_key->ip = 403;
        
            
            
            
                        
            struct kernel_ext4_generic_delete_entry_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_generic_delete_entry_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_add_file_rmap_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_add_file_rmap_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 404;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_add_file_rmap_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 404;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_add_file_rmap_event_t stats_key_v = {};
            struct kernel_page_add_file_rmap_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 404;
            stats_key->ip = 404;
        
            
            
            
                        
            struct kernel_page_add_file_rmap_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_add_file_rmap_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_setattr_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_setattr_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 405;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_setattr_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 405;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_setattr_event_t stats_key_v = {};
            struct kernel_ext4_setattr_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 405;
            stats_key->ip = 405;
        
            
            
            
                        
            struct kernel_ext4_setattr_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_setattr_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_tlb_batch_pages_flush_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_tlb_batch_pages_flush_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 406;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_tlb_batch_pages_flush_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 406;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_tlb_batch_pages_flush_event_t stats_key_v = {};
            struct kernel_tlb_batch_pages_flush_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 406;
            stats_key->ip = 406;
        
            
            
            
                        
            struct kernel_tlb_batch_pages_flush_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_tlb_batch_pages_flush_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_fscrypt_mergeable_bio_bh_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_fscrypt_mergeable_bio_bh_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 407;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_fscrypt_mergeable_bio_bh_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 407;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_fscrypt_mergeable_bio_bh_event_t stats_key_v = {};
            struct kernel_fscrypt_mergeable_bio_bh_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 407;
            stats_key->ip = 407;
        
            
            
            
                        
            struct kernel_fscrypt_mergeable_bio_bh_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_fscrypt_mergeable_bio_bh_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_journal_check_start_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_journal_check_start_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 408;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_journal_check_start_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 408;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_journal_check_start_event_t stats_key_v = {};
            struct kernel_ext4_journal_check_start_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 408;
            stats_key->ip = 408;
        
            
            
            
                        
            struct kernel_ext4_journal_check_start_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_journal_check_start_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_get_acl_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_get_acl_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 409;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_get_acl_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 409;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_get_acl_event_t stats_key_v = {};
            struct kernel_ext4_get_acl_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 409;
            stats_key->ip = 409;
        
            
            
            
                        
            struct kernel_ext4_get_acl_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_get_acl_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_journal_stop_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_journal_stop_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 410;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_journal_stop_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 410;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_journal_stop_event_t stats_key_v = {};
            struct kernel___ext4_journal_stop_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 410;
            stats_key->ip = 410;
        
            
            
            
                        
            struct kernel___ext4_journal_stop_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_journal_stop_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_create_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_create_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 411;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_create_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 411;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_create_event_t stats_key_v = {};
            struct kernel_ext4_create_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 411;
            stats_key->ip = 411;
        
            
            
            
                        
            struct kernel_ext4_create_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_create_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___get_user_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___get_user_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 412;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___get_user_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 412;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___get_user_pages_event_t stats_key_v = {};
            struct kernel___get_user_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 412;
            stats_key->ip = 412;
        
            
            
            
                        
            struct kernel___get_user_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___get_user_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_mpage_map_and_submit_extent_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_mpage_map_and_submit_extent_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 413;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_mpage_map_and_submit_extent_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 413;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_mpage_map_and_submit_extent_event_t stats_key_v = {};
            struct kernel_mpage_map_and_submit_extent_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 413;
            stats_key->ip = 413;
        
            
            
            
                        
            struct kernel_mpage_map_and_submit_extent_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_mpage_map_and_submit_extent_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_journal_get_write_access_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_journal_get_write_access_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 414;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_journal_get_write_access_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 414;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_journal_get_write_access_event_t stats_key_v = {};
            struct kernel___ext4_journal_get_write_access_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 414;
            stats_key->ip = 414;
        
            
            
            
                        
            struct kernel___ext4_journal_get_write_access_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_journal_get_write_access_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_alloc_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_alloc_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 415;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_alloc_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 415;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_alloc_pages_event_t stats_key_v = {};
            struct kernel_alloc_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 415;
            stats_key->ip = 415;
        
            
            
            
                        
            struct kernel_alloc_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_alloc_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_get_inode_loc_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_get_inode_loc_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 416;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_get_inode_loc_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 416;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_get_inode_loc_event_t stats_key_v = {};
            struct kernel___ext4_get_inode_loc_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 416;
            stats_key->ip = 416;
        
            
            
            
                        
            struct kernel___ext4_get_inode_loc_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_get_inode_loc_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_isolate_lru_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_isolate_lru_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 417;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_isolate_lru_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 417;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_isolate_lru_page_event_t stats_key_v = {};
            struct kernel_isolate_lru_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 417;
            stats_key->ip = 417;
        
            
            
            
                        
            struct kernel_isolate_lru_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_isolate_lru_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_fdatawrite_wbc_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_fdatawrite_wbc_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 418;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_fdatawrite_wbc_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 418;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_fdatawrite_wbc_event_t stats_key_v = {};
            struct kernel_filemap_fdatawrite_wbc_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 418;
            stats_key->ip = 418;
        
            
            
            
                        
            struct kernel_filemap_fdatawrite_wbc_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_fdatawrite_wbc_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_block_write_begin_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_block_write_begin_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 419;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_block_write_begin_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 419;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_block_write_begin_event_t stats_key_v = {};
            struct kernel_ext4_block_write_begin_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 419;
            stats_key->ip = 419;
        
            
            
            
                        
            struct kernel_ext4_block_write_begin_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_block_write_begin_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_search_left_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_search_left_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 420;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_search_left_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 420;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_search_left_event_t stats_key_v = {};
            struct kernel_ext4_ext_search_left_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 420;
            stats_key->ip = 420;
        
            
            
            
                        
            struct kernel_ext4_ext_search_left_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_search_left_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_fscrypt_setup_filename_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_fscrypt_setup_filename_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 421;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_fscrypt_setup_filename_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 421;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_fscrypt_setup_filename_event_t stats_key_v = {};
            struct kernel_fscrypt_setup_filename_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 421;
            stats_key->ip = 421;
        
            
            
            
                        
            struct kernel_fscrypt_setup_filename_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_fscrypt_setup_filename_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_free_unref_page_commit_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_free_unref_page_commit_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 422;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_free_unref_page_commit_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 422;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_free_unref_page_commit_event_t stats_key_v = {};
            struct kernel_free_unref_page_commit_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 422;
            stats_key->ip = 422;
        
            
            
            
                        
            struct kernel_free_unref_page_commit_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_free_unref_page_commit_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_journal_start_sb_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_journal_start_sb_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 423;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_journal_start_sb_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 423;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_journal_start_sb_event_t stats_key_v = {};
            struct kernel___ext4_journal_start_sb_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 423;
            stats_key->ip = 423;
        
            
            
            
                        
            struct kernel___ext4_journal_start_sb_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_journal_start_sb_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_inode_block_valid_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_inode_block_valid_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 424;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_inode_block_valid_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 424;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_inode_block_valid_event_t stats_key_v = {};
            struct kernel_ext4_inode_block_valid_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 424;
            stats_key->ip = 424;
        
            
            
            
                        
            struct kernel_ext4_inode_block_valid_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_inode_block_valid_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_es_find_extent_range_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_es_find_extent_range_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 425;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_es_find_extent_range_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 425;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_es_find_extent_range_event_t stats_key_v = {};
            struct kernel_ext4_es_find_extent_range_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 425;
            stats_key->ip = 425;
        
            
            
            
                        
            struct kernel_ext4_es_find_extent_range_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_es_find_extent_range_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_free_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_free_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 426;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_free_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 426;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_free_pages_event_t stats_key_v = {};
            struct kernel_free_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 426;
            stats_key->ip = 426;
        
            
            
            
                        
            struct kernel_free_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_free_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_break_layouts_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_break_layouts_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 427;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_break_layouts_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 427;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_break_layouts_event_t stats_key_v = {};
            struct kernel_ext4_break_layouts_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 427;
            stats_key->ip = 427;
        
            
            
            
                        
            struct kernel_ext4_break_layouts_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_break_layouts_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_get_folios_tag_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_get_folios_tag_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 428;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_get_folios_tag_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 428;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_get_folios_tag_event_t stats_key_v = {};
            struct kernel_filemap_get_folios_tag_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 428;
            stats_key->ip = 428;
        
            
            
            
                        
            struct kernel_filemap_get_folios_tag_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_get_folios_tag_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_balance_dirty_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_balance_dirty_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 429;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_balance_dirty_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 429;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_balance_dirty_pages_event_t stats_key_v = {};
            struct kernel_balance_dirty_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 429;
            stats_key->ip = 429;
        
            
            
            
                        
            struct kernel_balance_dirty_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_balance_dirty_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_set_iomap_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_set_iomap_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 430;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_set_iomap_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 430;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_set_iomap_event_t stats_key_v = {};
            struct kernel_ext4_set_iomap_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 430;
            stats_key->ip = 430;
        
            
            
            
                        
            struct kernel_ext4_set_iomap_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_set_iomap_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_submit_bio_noacct_nocheck_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_submit_bio_noacct_nocheck_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 431;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_submit_bio_noacct_nocheck_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 431;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_submit_bio_noacct_nocheck_event_t stats_key_v = {};
            struct kernel_submit_bio_noacct_nocheck_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 431;
            stats_key->ip = 431;
        
            
            
            
                        
            struct kernel_submit_bio_noacct_nocheck_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_submit_bio_noacct_nocheck_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_free_unref_page_prepare_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_free_unref_page_prepare_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 432;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_free_unref_page_prepare_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 432;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_free_unref_page_prepare_event_t stats_key_v = {};
            struct kernel_free_unref_page_prepare_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 432;
            stats_key->ip = 432;
        
            
            
            
                        
            struct kernel_free_unref_page_prepare_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_free_unref_page_prepare_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_free_pcppages_bulk_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_free_pcppages_bulk_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 433;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_free_pcppages_bulk_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 433;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_free_pcppages_bulk_event_t stats_key_v = {};
            struct kernel_free_pcppages_bulk_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 433;
            stats_key->ip = 433;
        
            
            
            
                        
            struct kernel_free_pcppages_bulk_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_free_pcppages_bulk_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_file_getattr_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_file_getattr_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 434;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_file_getattr_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 434;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_file_getattr_event_t stats_key_v = {};
            struct kernel_ext4_file_getattr_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 434;
            stats_key->ip = 434;
        
            
            
            
                        
            struct kernel_ext4_file_getattr_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_file_getattr_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_dio_write_end_io_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_dio_write_end_io_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 435;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_dio_write_end_io_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 435;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_dio_write_end_io_event_t stats_key_v = {};
            struct kernel_ext4_dio_write_end_io_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 435;
            stats_key->ip = 435;
        
            
            
            
                        
            struct kernel_ext4_dio_write_end_io_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_dio_write_end_io_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_get_dummy_policy_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_get_dummy_policy_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 436;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_get_dummy_policy_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 436;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_get_dummy_policy_event_t stats_key_v = {};
            struct kernel_ext4_get_dummy_policy_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 436;
            stats_key->ip = 436;
        
            
            
            
                        
            struct kernel_ext4_get_dummy_policy_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_get_dummy_policy_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_free_unref_page_list_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_free_unref_page_list_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 437;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_free_unref_page_list_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 437;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_free_unref_page_list_event_t stats_key_v = {};
            struct kernel_free_unref_page_list_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 437;
            stats_key->ip = 437;
        
            
            
            
                        
            struct kernel_free_unref_page_list_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_free_unref_page_list_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_cache_prev_miss_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_cache_prev_miss_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 438;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_cache_prev_miss_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 438;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_cache_prev_miss_event_t stats_key_v = {};
            struct kernel_page_cache_prev_miss_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 438;
            stats_key->ip = 438;
        
            
            
            
                        
            struct kernel_page_cache_prev_miss_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_cache_prev_miss_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_mpage_map_and_submit_buffers_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_mpage_map_and_submit_buffers_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 439;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_mpage_map_and_submit_buffers_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 439;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_mpage_map_and_submit_buffers_event_t stats_key_v = {};
            struct kernel_mpage_map_and_submit_buffers_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 439;
            stats_key->ip = 439;
        
            
            
            
                        
            struct kernel_mpage_map_and_submit_buffers_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_mpage_map_and_submit_buffers_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_flush_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_flush_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 440;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_flush_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 440;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_flush_event_t stats_key_v = {};
            struct kernel_filemap_flush_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 440;
            stats_key->ip = 440;
        
            
            
            
                        
            struct kernel_filemap_flush_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_flush_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_read_bh_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_read_bh_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 441;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_read_bh_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 441;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_read_bh_event_t stats_key_v = {};
            struct kernel_ext4_read_bh_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 441;
            stats_key->ip = 441;
        
            
            
            
                        
            struct kernel_ext4_read_bh_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_read_bh_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4fs_dirhash_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4fs_dirhash_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 442;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4fs_dirhash_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 442;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4fs_dirhash_event_t stats_key_v = {};
            struct kernel___ext4fs_dirhash_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 442;
            stats_key->ip = 442;
        
            
            
            
                        
            struct kernel___ext4fs_dirhash_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4fs_dirhash_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_fname_free_filename_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_fname_free_filename_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 443;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_fname_free_filename_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 443;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_fname_free_filename_event_t stats_key_v = {};
            struct kernel_ext4_fname_free_filename_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 443;
            stats_key->ip = 443;
        
            
            
            
                        
            struct kernel_ext4_fname_free_filename_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_fname_free_filename_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_submit_bio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_submit_bio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 444;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_submit_bio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 444;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_submit_bio_event_t stats_key_v = {};
            struct kernel_submit_bio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 444;
            stats_key->ip = 444;
        
            
            
            
                        
            struct kernel_submit_bio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_submit_bio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_fault_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_fault_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 445;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_fault_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 445;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_fault_event_t stats_key_v = {};
            struct kernel_filemap_fault_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 445;
            stats_key->ip = 445;
        
            
            
            
                        
            struct kernel_filemap_fault_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_fault_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_file_free_rcu_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_file_free_rcu_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 446;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_file_free_rcu_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 446;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_file_free_rcu_event_t stats_key_v = {};
            struct kernel_file_free_rcu_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 446;
            stats_key->ip = 446;
        
            
            
            
                        
            struct kernel_file_free_rcu_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_file_free_rcu_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_vfs_fsync_range_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_vfs_fsync_range_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 447;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_vfs_fsync_range_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 447;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_vfs_fsync_range_event_t stats_key_v = {};
            struct kernel_vfs_fsync_range_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 447;
            stats_key->ip = 447;
        
            
            
            
                        
            struct kernel_vfs_fsync_range_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_vfs_fsync_range_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_es_init_tree_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_es_init_tree_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 448;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_es_init_tree_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 448;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_es_init_tree_event_t stats_key_v = {};
            struct kernel_ext4_es_init_tree_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 448;
            stats_key->ip = 448;
        
            
            
            
                        
            struct kernel_ext4_es_init_tree_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_es_init_tree_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_create_pipe_files_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_create_pipe_files_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 449;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_create_pipe_files_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 449;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_create_pipe_files_event_t stats_key_v = {};
            struct kernel_create_pipe_files_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 449;
            stats_key->ip = 449;
        
            
            
            
                        
            struct kernel_create_pipe_files_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_create_pipe_files_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_apparmor_file_free_security_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_apparmor_file_free_security_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 450;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_apparmor_file_free_security_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 450;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_apparmor_file_free_security_event_t stats_key_v = {};
            struct kernel_apparmor_file_free_security_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 450;
            stats_key->ip = 450;
        
            
            
            
                        
            struct kernel_apparmor_file_free_security_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_apparmor_file_free_security_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_statfs_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_statfs_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 451;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_statfs_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 451;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_statfs_event_t stats_key_v = {};
            struct kernel_ext4_statfs_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 451;
            stats_key->ip = 451;
        
            
            
            
                        
            struct kernel_ext4_statfs_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_statfs_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_release_folio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_release_folio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 452;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_release_folio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 452;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_release_folio_event_t stats_key_v = {};
            struct kernel_ext4_release_folio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 452;
            stats_key->ip = 452;
        
            
            
            
                        
            struct kernel_ext4_release_folio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_release_folio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ima_file_check_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ima_file_check_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 453;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ima_file_check_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 453;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ima_file_check_event_t stats_key_v = {};
            struct kernel_ima_file_check_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 453;
            stats_key->ip = 453;
        
            
            
            
                        
            struct kernel_ima_file_check_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ima_file_check_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_pcpu_nr_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_pcpu_nr_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 454;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_pcpu_nr_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 454;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_pcpu_nr_pages_event_t stats_key_v = {};
            struct kernel_pcpu_nr_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 454;
            stats_key->ip = 454;
        
            
            
            
                        
            struct kernel_pcpu_nr_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_pcpu_nr_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_dirty_inode_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_dirty_inode_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 455;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_dirty_inode_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 455;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_dirty_inode_event_t stats_key_v = {};
            struct kernel_ext4_dirty_inode_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 455;
            stats_key->ip = 455;
        
            
            
            
                        
            struct kernel_ext4_dirty_inode_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_dirty_inode_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_submit_bio_wait_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_submit_bio_wait_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 456;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_submit_bio_wait_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 456;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_submit_bio_wait_event_t stats_key_v = {};
            struct kernel_submit_bio_wait_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 456;
            stats_key->ip = 456;
        
            
            
            
                        
            struct kernel_submit_bio_wait_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_submit_bio_wait_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_shmem_file_read_iter_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_shmem_file_read_iter_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 457;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_shmem_file_read_iter_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 457;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_shmem_file_read_iter_event_t stats_key_v = {};
            struct kernel_shmem_file_read_iter_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 457;
            stats_key->ip = 457;
        
            
            
            
                        
            struct kernel_shmem_file_read_iter_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_shmem_file_read_iter_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_jbd2_journal_file_inode_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_jbd2_journal_file_inode_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 458;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_jbd2_journal_file_inode_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 458;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_jbd2_journal_file_inode_event_t stats_key_v = {};
            struct kernel_jbd2_journal_file_inode_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 458;
            stats_key->ip = 458;
        
            
            
            
                        
            struct kernel_jbd2_journal_file_inode_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_jbd2_journal_file_inode_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_fname_setup_ci_filename_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_fname_setup_ci_filename_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 459;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_fname_setup_ci_filename_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 459;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_fname_setup_ci_filename_event_t stats_key_v = {};
            struct kernel_ext4_fname_setup_ci_filename_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 459;
            stats_key->ip = 459;
        
            
            
            
                        
            struct kernel_ext4_fname_setup_ci_filename_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_fname_setup_ci_filename_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_cache_next_miss_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_cache_next_miss_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 460;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_cache_next_miss_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 460;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_cache_next_miss_event_t stats_key_v = {};
            struct kernel_page_cache_next_miss_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 460;
            stats_key->ip = 460;
        
            
            
            
                        
            struct kernel_page_cache_next_miss_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_cache_next_miss_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_clone_blkg_association_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_clone_blkg_association_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 461;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_clone_blkg_association_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 461;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_clone_blkg_association_event_t stats_key_v = {};
            struct kernel_bio_clone_blkg_association_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 461;
            stats_key->ip = 461;
        
            
            
            
                        
            struct kernel_bio_clone_blkg_association_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_clone_blkg_association_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_blk_mq_sched_bio_merge_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_blk_mq_sched_bio_merge_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 462;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_blk_mq_sched_bio_merge_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 462;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_blk_mq_sched_bio_merge_event_t stats_key_v = {};
            struct kernel_blk_mq_sched_bio_merge_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 462;
            stats_key->ip = 462;
        
            
            
            
                        
            struct kernel_blk_mq_sched_bio_merge_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_blk_mq_sched_bio_merge_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___blk_bios_map_sg_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___blk_bios_map_sg_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 463;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___blk_bios_map_sg_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 463;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___blk_bios_map_sg_event_t stats_key_v = {};
            struct kernel___blk_bios_map_sg_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 463;
            stats_key->ip = 463;
        
            
            
            
                        
            struct kernel___blk_bios_map_sg_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___blk_bios_map_sg_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___bio_advance_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___bio_advance_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 464;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___bio_advance_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 464;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___bio_advance_event_t stats_key_v = {};
            struct kernel___bio_advance_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 464;
            stats_key->ip = 464;
        
            
            
            
                        
            struct kernel___bio_advance_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___bio_advance_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_mm_put_huge_zero_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_mm_put_huge_zero_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 465;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_mm_put_huge_zero_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 465;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_mm_put_huge_zero_page_event_t stats_key_v = {};
            struct kernel_mm_put_huge_zero_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 465;
            stats_key->ip = 465;
        
            
            
            
                        
            struct kernel_mm_put_huge_zero_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_mm_put_huge_zero_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_orphan_add_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_orphan_add_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 466;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_orphan_add_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 466;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_orphan_add_event_t stats_key_v = {};
            struct kernel_ext4_orphan_add_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 466;
            stats_key->ip = 466;
        
            
            
            
                        
            struct kernel_ext4_orphan_add_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_orphan_add_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_es_insert_extent_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_es_insert_extent_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 467;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_es_insert_extent_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 467;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_es_insert_extent_event_t stats_key_v = {};
            struct kernel_ext4_es_insert_extent_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 467;
            stats_key->ip = 467;
        
            
            
            
                        
            struct kernel_ext4_es_insert_extent_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_es_insert_extent_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_inode_is_fast_symlink_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_inode_is_fast_symlink_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 468;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_inode_is_fast_symlink_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 468;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_inode_is_fast_symlink_event_t stats_key_v = {};
            struct kernel_ext4_inode_is_fast_symlink_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 468;
            stats_key->ip = 468;
        
            
            
            
                        
            struct kernel_ext4_inode_is_fast_symlink_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_inode_is_fast_symlink_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_discard_preallocations_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_discard_preallocations_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 469;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_discard_preallocations_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 469;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_discard_preallocations_event_t stats_key_v = {};
            struct kernel_ext4_discard_preallocations_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 469;
            stats_key->ip = 469;
        
            
            
            
                        
            struct kernel_ext4_discard_preallocations_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_discard_preallocations_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_add_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_add_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 470;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_add_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 470;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_add_page_event_t stats_key_v = {};
            struct kernel_bio_add_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 470;
            stats_key->ip = 470;
        
            
            
            
                        
            struct kernel_bio_add_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_add_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_get_group_number_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_get_group_number_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 471;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_get_group_number_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 471;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_get_group_number_event_t stats_key_v = {};
            struct kernel_ext4_get_group_number_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 471;
            stats_key->ip = 471;
        
            
            
            
                        
            struct kernel_ext4_get_group_number_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_get_group_number_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_cache_extents_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_cache_extents_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 472;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_cache_extents_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 472;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_cache_extents_event_t stats_key_v = {};
            struct kernel_ext4_cache_extents_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 472;
            stats_key->ip = 472;
        
            
            
            
                        
            struct kernel_ext4_cache_extents_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_cache_extents_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_process_output_block_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_process_output_block_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 473;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_process_output_block_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 473;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_process_output_block_event_t stats_key_v = {};
            struct kernel_process_output_block_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 473;
            stats_key->ip = 473;
        
            
            
            
                        
            struct kernel_process_output_block_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_process_output_block_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_generic_file_open_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_generic_file_open_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 474;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_generic_file_open_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 474;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_generic_file_open_event_t stats_key_v = {};
            struct kernel_generic_file_open_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 474;
            stats_key->ip = 474;
        
            
            
            
                        
            struct kernel_generic_file_open_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_generic_file_open_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_inode_csum_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_inode_csum_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 475;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_inode_csum_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 475;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_inode_csum_event_t stats_key_v = {};
            struct kernel_ext4_inode_csum_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 475;
            stats_key->ip = 475;
        
            
            
            
                        
            struct kernel_ext4_inode_csum_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_inode_csum_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_dio_alignment_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_dio_alignment_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 476;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_dio_alignment_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 476;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_dio_alignment_event_t stats_key_v = {};
            struct kernel_ext4_dio_alignment_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 476;
            stats_key->ip = 476;
        
            
            
            
                        
            struct kernel_ext4_dio_alignment_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_dio_alignment_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_has_free_clusters_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_has_free_clusters_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 477;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_has_free_clusters_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 477;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_has_free_clusters_event_t stats_key_v = {};
            struct kernel_ext4_has_free_clusters_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 477;
            stats_key->ip = 477;
        
            
            
            
                        
            struct kernel_ext4_has_free_clusters_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_has_free_clusters_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_ioctl_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_ioctl_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 478;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_ioctl_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 478;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_ioctl_event_t stats_key_v = {};
            struct kernel___ext4_ioctl_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 478;
            stats_key->ip = 478;
        
            
            
            
                        
            struct kernel___ext4_ioctl_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_ioctl_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_num_base_meta_blocks_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_num_base_meta_blocks_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 479;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_num_base_meta_blocks_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 479;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_num_base_meta_blocks_event_t stats_key_v = {};
            struct kernel_ext4_num_base_meta_blocks_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 479;
            stats_key->ip = 479;
        
            
            
            
                        
            struct kernel_ext4_num_base_meta_blocks_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_num_base_meta_blocks_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_vfs_unlink_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_vfs_unlink_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 480;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_vfs_unlink_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 480;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_vfs_unlink_event_t stats_key_v = {};
            struct kernel_vfs_unlink_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 480;
            stats_key->ip = 480;
        
            
            
            
                        
            struct kernel_vfs_unlink_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_vfs_unlink_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_read_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_read_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 481;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_read_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 481;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_read_event_t stats_key_v = {};
            struct kernel_filemap_read_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 481;
            stats_key->ip = 481;
        
            
            
            
                        
            struct kernel_filemap_read_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_read_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_internal_get_user_pages_fast_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_internal_get_user_pages_fast_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 482;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_internal_get_user_pages_fast_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 482;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_internal_get_user_pages_fast_event_t stats_key_v = {};
            struct kernel_internal_get_user_pages_fast_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 482;
            stats_key->ip = 482;
        
            
            
            
                        
            struct kernel_internal_get_user_pages_fast_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_internal_get_user_pages_fast_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_dma_map_page_attrs_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_dma_map_page_attrs_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 483;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_dma_map_page_attrs_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 483;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_dma_map_page_attrs_event_t stats_key_v = {};
            struct kernel_dma_map_page_attrs_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 483;
            stats_key->ip = 483;
        
            
            
            
                        
            struct kernel_dma_map_page_attrs_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_dma_map_page_attrs_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_read_bh_lock_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_read_bh_lock_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 484;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_read_bh_lock_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 484;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_read_bh_lock_event_t stats_key_v = {};
            struct kernel_ext4_read_bh_lock_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 484;
            stats_key->ip = 484;
        
            
            
            
                        
            struct kernel_ext4_read_bh_lock_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_read_bh_lock_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_file_modified_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_file_modified_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 485;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_file_modified_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 485;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_file_modified_event_t stats_key_v = {};
            struct kernel_file_modified_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 485;
            stats_key->ip = 485;
        
            
            
            
                        
            struct kernel_file_modified_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_file_modified_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_security_file_fcntl_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_security_file_fcntl_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 486;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_security_file_fcntl_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 486;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_security_file_fcntl_event_t stats_key_v = {};
            struct kernel_security_file_fcntl_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 486;
            stats_key->ip = 486;
        
            
            
            
                        
            struct kernel_security_file_fcntl_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_security_file_fcntl_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___filemap_remove_folio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___filemap_remove_folio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 487;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___filemap_remove_folio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 487;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___filemap_remove_folio_event_t stats_key_v = {};
            struct kernel___filemap_remove_folio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 487;
            stats_key->ip = 487;
        
            
            
            
                        
            struct kernel___filemap_remove_folio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___filemap_remove_folio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_good_group_nolock_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_good_group_nolock_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 488;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_good_group_nolock_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 488;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_good_group_nolock_event_t stats_key_v = {};
            struct kernel_ext4_mb_good_group_nolock_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 488;
            stats_key->ip = 488;
        
            
            
            
                        
            struct kernel_ext4_mb_good_group_nolock_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_good_group_nolock_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_sock_alloc_file_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_sock_alloc_file_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 489;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_sock_alloc_file_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 489;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_sock_alloc_file_event_t stats_key_v = {};
            struct kernel_sock_alloc_file_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 489;
            stats_key->ip = 489;
        
            
            
            
                        
            struct kernel_sock_alloc_file_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_sock_alloc_file_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_ext_check_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_ext_check_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 490;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_ext_check_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 490;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_ext_check_event_t stats_key_v = {};
            struct kernel___ext4_ext_check_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 490;
            stats_key->ip = 490;
        
            
            
            
                        
            struct kernel___ext4_ext_check_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_ext_check_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_expand_files_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_expand_files_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 491;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_expand_files_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 491;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_expand_files_event_t stats_key_v = {};
            struct kernel_expand_files_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 491;
            stats_key->ip = 491;
        
            
            
            
                        
            struct kernel_expand_files_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_expand_files_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_xattr_block_get_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_xattr_block_get_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 492;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_xattr_block_get_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 492;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_xattr_block_get_event_t stats_key_v = {};
            struct kernel_ext4_xattr_block_get_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 492;
            stats_key->ip = 492;
        
            
            
            
                        
            struct kernel_ext4_xattr_block_get_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_xattr_block_get_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_split_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_split_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 493;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_split_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 493;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_split_event_t stats_key_v = {};
            struct kernel_bio_split_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 493;
            stats_key->ip = 493;
        
            
            
            
                        
            struct kernel_bio_split_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_split_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_truncate_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_truncate_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 494;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_truncate_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 494;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_truncate_event_t stats_key_v = {};
            struct kernel_ext4_truncate_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 494;
            stats_key->ip = 494;
        
            
            
            
                        
            struct kernel_ext4_truncate_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_truncate_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_file_read_iter_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_file_read_iter_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 495;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_file_read_iter_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 495;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_file_read_iter_event_t stats_key_v = {};
            struct kernel_ext4_file_read_iter_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 495;
            stats_key->ip = 495;
        
            
            
            
                        
            struct kernel_ext4_file_read_iter_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_file_read_iter_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_file_check_and_advance_wb_err_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_file_check_and_advance_wb_err_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 496;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_file_check_and_advance_wb_err_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 496;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_file_check_and_advance_wb_err_event_t stats_key_v = {};
            struct kernel_file_check_and_advance_wb_err_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 496;
            stats_key->ip = 496;
        
            
            
            
                        
            struct kernel_file_check_and_advance_wb_err_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_file_check_and_advance_wb_err_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_end_bio_bh_io_sync_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_end_bio_bh_io_sync_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 497;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_end_bio_bh_io_sync_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 497;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_end_bio_bh_io_sync_event_t stats_key_v = {};
            struct kernel_end_bio_bh_io_sync_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 497;
            stats_key->ip = 497;
        
            
            
            
                        
            struct kernel_end_bio_bh_io_sync_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_end_bio_bh_io_sync_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_node_page_state_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_node_page_state_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 498;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_node_page_state_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 498;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_node_page_state_pages_event_t stats_key_v = {};
            struct kernel_node_page_state_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 498;
            stats_key->ip = 498;
        
            
            
            
                        
            struct kernel_node_page_state_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_node_page_state_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_writepages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_writepages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 499;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_writepages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 499;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_writepages_event_t stats_key_v = {};
            struct kernel_ext4_writepages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 499;
            stats_key->ip = 499;
        
            
            
            
                        
            struct kernel_ext4_writepages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_writepages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_security_file_ioctl_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_security_file_ioctl_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 500;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_security_file_ioctl_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 500;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_security_file_ioctl_event_t stats_key_v = {};
            struct kernel_security_file_ioctl_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 500;
            stats_key->ip = 500;
        
            
            
            
                        
            struct kernel_security_file_ioctl_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_security_file_ioctl_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_lockless_pages_from_mm_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_lockless_pages_from_mm_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 501;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_lockless_pages_from_mm_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 501;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_lockless_pages_from_mm_event_t stats_key_v = {};
            struct kernel_lockless_pages_from_mm_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 501;
            stats_key->ip = 501;
        
            
            
            
                        
            struct kernel_lockless_pages_from_mm_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_lockless_pages_from_mm_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___rq_qos_done_bio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___rq_qos_done_bio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 502;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___rq_qos_done_bio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 502;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___rq_qos_done_bio_event_t stats_key_v = {};
            struct kernel___rq_qos_done_bio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 502;
            stats_key->ip = 502;
        
            
            
            
                        
            struct kernel___rq_qos_done_bio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___rq_qos_done_bio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_es_free_extent_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_es_free_extent_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 503;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_es_free_extent_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 503;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_es_free_extent_event_t stats_key_v = {};
            struct kernel_ext4_es_free_extent_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 503;
            stats_key->ip = 503;
        
            
            
            
                        
            struct kernel_ext4_es_free_extent_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_es_free_extent_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_mb_find_order_for_block_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_mb_find_order_for_block_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 504;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_mb_find_order_for_block_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 504;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_mb_find_order_for_block_event_t stats_key_v = {};
            struct kernel_mb_find_order_for_block_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 504;
            stats_key->ip = 504;
        
            
            
            
                        
            struct kernel_mb_find_order_for_block_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_mb_find_order_for_block_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___mnt_drop_write_file_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___mnt_drop_write_file_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 505;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___mnt_drop_write_file_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 505;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___mnt_drop_write_file_event_t stats_key_v = {};
            struct kernel___mnt_drop_write_file_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 505;
            stats_key->ip = 505;
        
            
            
            
                        
            struct kernel___mnt_drop_write_file_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___mnt_drop_write_file_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_do_numa_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_do_numa_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 506;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_do_numa_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 506;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_do_numa_page_event_t stats_key_v = {};
            struct kernel_do_numa_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 506;
            stats_key->ip = 506;
        
            
            
            
                        
            struct kernel_do_numa_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_do_numa_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_get_reserved_space_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_get_reserved_space_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 507;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_get_reserved_space_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 507;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_get_reserved_space_event_t stats_key_v = {};
            struct kernel_ext4_get_reserved_space_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 507;
            stats_key->ip = 507;
        
            
            
            
                        
            struct kernel_ext4_get_reserved_space_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_get_reserved_space_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_wait_block_bitmap_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_wait_block_bitmap_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 508;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_wait_block_bitmap_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 508;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_wait_block_bitmap_event_t stats_key_v = {};
            struct kernel_ext4_wait_block_bitmap_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 508;
            stats_key->ip = 508;
        
            
            
            
                        
            struct kernel_ext4_wait_block_bitmap_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_wait_block_bitmap_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_good_group_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_good_group_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 509;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_good_group_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 509;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_good_group_event_t stats_key_v = {};
            struct kernel_ext4_mb_good_group_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 509;
            stats_key->ip = 509;
        
            
            
            
                        
            struct kernel_ext4_mb_good_group_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_good_group_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_unload_buddy_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_unload_buddy_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 510;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_unload_buddy_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 510;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_unload_buddy_event_t stats_key_v = {};
            struct kernel_ext4_mb_unload_buddy_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 510;
            stats_key->ip = 510;
        
            
            
            
                        
            struct kernel_ext4_mb_unload_buddy_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_unload_buddy_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_free_tail_page_prepare_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_free_tail_page_prepare_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 511;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_free_tail_page_prepare_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 511;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_free_tail_page_prepare_event_t stats_key_v = {};
            struct kernel_free_tail_page_prepare_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 511;
            stats_key->ip = 511;
        
            
            
            
                        
            struct kernel_free_tail_page_prepare_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_free_tail_page_prepare_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_handle_inode_extension_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_handle_inode_extension_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 512;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_handle_inode_extension_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 512;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_handle_inode_extension_event_t stats_key_v = {};
            struct kernel_ext4_handle_inode_extension_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 512;
            stats_key->ip = 512;
        
            
            
            
                        
            struct kernel_ext4_handle_inode_extension_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_handle_inode_extension_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_apparmor_file_mprotect_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_apparmor_file_mprotect_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 513;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_apparmor_file_mprotect_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 513;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_apparmor_file_mprotect_event_t stats_key_v = {};
            struct kernel_apparmor_file_mprotect_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 513;
            stats_key->ip = 513;
        
            
            
            
                        
            struct kernel_apparmor_file_mprotect_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_apparmor_file_mprotect_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_wake_page_function_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_wake_page_function_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 514;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_wake_page_function_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 514;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_wake_page_function_event_t stats_key_v = {};
            struct kernel_wake_page_function_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 514;
            stats_key->ip = 514;
        
            
            
            
                        
            struct kernel_wake_page_function_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_wake_page_function_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_lookup_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_lookup_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 515;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_lookup_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 515;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_lookup_event_t stats_key_v = {};
            struct kernel_ext4_lookup_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 515;
            stats_key->ip = 515;
        
            
            
            
                        
            struct kernel_ext4_lookup_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_lookup_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_dx_readdir_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_dx_readdir_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 516;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_dx_readdir_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 516;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_dx_readdir_event_t stats_key_v = {};
            struct kernel_ext4_dx_readdir_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 516;
            stats_key->ip = 516;
        
            
            
            
                        
            struct kernel_ext4_dx_readdir_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_dx_readdir_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_file_update_time_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_file_update_time_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 517;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_file_update_time_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 517;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_file_update_time_event_t stats_key_v = {};
            struct kernel_file_update_time_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 517;
            stats_key->ip = 517;
        
            
            
            
                        
            struct kernel_file_update_time_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_file_update_time_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_set_inode_flags_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_set_inode_flags_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 518;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_set_inode_flags_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 518;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_set_inode_flags_event_t stats_key_v = {};
            struct kernel_ext4_set_inode_flags_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 518;
            stats_key->ip = 518;
        
            
            
            
                        
            struct kernel_ext4_set_inode_flags_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_set_inode_flags_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_init_acl_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_init_acl_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 519;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_init_acl_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 519;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_init_acl_event_t stats_key_v = {};
            struct kernel_ext4_init_acl_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 519;
            stats_key->ip = 519;
        
            
            
            
                        
            struct kernel_ext4_init_acl_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_init_acl_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_update_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_update_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 520;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_update_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 520;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_update_page_event_t stats_key_v = {};
            struct kernel_filemap_update_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 520;
            stats_key->ip = 520;
        
            
            
            
                        
            struct kernel_filemap_update_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_update_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_free_group_clusters_set_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_free_group_clusters_set_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 521;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_free_group_clusters_set_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 521;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_free_group_clusters_set_event_t stats_key_v = {};
            struct kernel_ext4_free_group_clusters_set_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 521;
            stats_key->ip = 521;
        
            
            
            
                        
            struct kernel_ext4_free_group_clusters_set_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_free_group_clusters_set_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_grow_indepth_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_grow_indepth_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 522;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_grow_indepth_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 522;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_grow_indepth_event_t stats_key_v = {};
            struct kernel_ext4_ext_grow_indepth_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 522;
            stats_key->ip = 522;
        
            
            
            
                        
            struct kernel_ext4_ext_grow_indepth_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_grow_indepth_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_mpage_submit_folio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_mpage_submit_folio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 523;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_mpage_submit_folio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 523;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_mpage_submit_folio_event_t stats_key_v = {};
            struct kernel_mpage_submit_folio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 523;
            stats_key->ip = 523;
        
            
            
            
                        
            struct kernel_mpage_submit_folio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_mpage_submit_folio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_apparmor_file_open_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_apparmor_file_open_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 524;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_apparmor_file_open_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 524;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_apparmor_file_open_event_t stats_key_v = {};
            struct kernel_apparmor_file_open_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 524;
            stats_key->ip = 524;
        
            
            
            
                        
            struct kernel_apparmor_file_open_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_apparmor_file_open_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_make_vfsgid_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_make_vfsgid_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 525;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_make_vfsgid_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 525;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_make_vfsgid_event_t stats_key_v = {};
            struct kernel_make_vfsgid_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 525;
            stats_key->ip = 525;
        
            
            
            
                        
            struct kernel_make_vfsgid_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_make_vfsgid_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_prep_compound_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_prep_compound_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 526;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_prep_compound_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 526;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_prep_compound_page_event_t stats_key_v = {};
            struct kernel_prep_compound_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 526;
            stats_key->ip = 526;
        
            
            
            
                        
            struct kernel_prep_compound_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_prep_compound_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_remove_blocks_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_remove_blocks_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 527;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_remove_blocks_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 527;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_remove_blocks_event_t stats_key_v = {};
            struct kernel_ext4_remove_blocks_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 527;
            stats_key->ip = 527;
        
            
            
            
                        
            struct kernel_ext4_remove_blocks_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_remove_blocks_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___filemap_get_folio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___filemap_get_folio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 528;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___filemap_get_folio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 528;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___filemap_get_folio_event_t stats_key_v = {};
            struct kernel___filemap_get_folio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 528;
            stats_key->ip = 528;
        
            
            
            
                        
            struct kernel___filemap_get_folio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___filemap_get_folio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_apparmor_mmap_file_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_apparmor_mmap_file_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 529;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_apparmor_mmap_file_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 529;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_apparmor_mmap_file_event_t stats_key_v = {};
            struct kernel_apparmor_mmap_file_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 529;
            stats_key->ip = 529;
        
            
            
            
                        
            struct kernel_apparmor_mmap_file_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_apparmor_mmap_file_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_add_entry_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_add_entry_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 530;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_add_entry_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 530;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_add_entry_event_t stats_key_v = {};
            struct kernel_ext4_add_entry_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 530;
            stats_key->ip = 530;
        
            
            
            
                        
            struct kernel_ext4_add_entry_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_add_entry_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ima_file_mprotect_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ima_file_mprotect_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 531;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ima_file_mprotect_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 531;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ima_file_mprotect_event_t stats_key_v = {};
            struct kernel_ima_file_mprotect_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 531;
            stats_key->ip = 531;
        
            
            
            
                        
            struct kernel_ima_file_mprotect_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ima_file_mprotect_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_buffered_write_iter_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_buffered_write_iter_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 532;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_buffered_write_iter_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 532;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_buffered_write_iter_event_t stats_key_v = {};
            struct kernel_ext4_buffered_write_iter_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 532;
            stats_key->ip = 532;
        
            
            
            
                        
            struct kernel_ext4_buffered_write_iter_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_buffered_write_iter_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_invalidate_inode_pages2_range_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_invalidate_inode_pages2_range_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 533;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_invalidate_inode_pages2_range_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 533;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_invalidate_inode_pages2_range_event_t stats_key_v = {};
            struct kernel_invalidate_inode_pages2_range_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 533;
            stats_key->ip = 533;
        
            
            
            
                        
            struct kernel_invalidate_inode_pages2_range_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_invalidate_inode_pages2_range_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_xattr_set_credits_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_xattr_set_credits_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 534;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_xattr_set_credits_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 534;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_xattr_set_credits_event_t stats_key_v = {};
            struct kernel___ext4_xattr_set_credits_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 534;
            stats_key->ip = 534;
        
            
            
            
                        
            struct kernel___ext4_xattr_set_credits_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_xattr_set_credits_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_get_group_no_and_offset_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_get_group_no_and_offset_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 535;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_get_group_no_and_offset_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 535;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_get_group_no_and_offset_event_t stats_key_v = {};
            struct kernel_ext4_get_group_no_and_offset_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 535;
            stats_key->ip = 535;
        
            
            
            
                        
            struct kernel_ext4_get_group_no_and_offset_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_get_group_no_and_offset_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_htree_store_dirent_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_htree_store_dirent_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 536;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_htree_store_dirent_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 536;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_htree_store_dirent_event_t stats_key_v = {};
            struct kernel_ext4_htree_store_dirent_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 536;
            stats_key->ip = 536;
        
            
            
            
                        
            struct kernel_ext4_htree_store_dirent_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_htree_store_dirent_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_put_io_end_defer_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_put_io_end_defer_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 537;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_put_io_end_defer_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 537;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_put_io_end_defer_event_t stats_key_v = {};
            struct kernel_ext4_put_io_end_defer_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 537;
            stats_key->ip = 537;
        
            
            
            
                        
            struct kernel_ext4_put_io_end_defer_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_put_io_end_defer_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_nr_hugepages_show_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_nr_hugepages_show_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 538;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_nr_hugepages_show_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 538;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_nr_hugepages_show_event_t stats_key_v = {};
            struct kernel_nr_hugepages_show_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 538;
            stats_key->ip = 538;
        
            
            
            
                        
            struct kernel_nr_hugepages_show_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_nr_hugepages_show_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_superblock_csum_set_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_superblock_csum_set_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 539;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_superblock_csum_set_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 539;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_superblock_csum_set_event_t stats_key_v = {};
            struct kernel_ext4_superblock_csum_set_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 539;
            stats_key->ip = 539;
        
            
            
            
                        
            struct kernel_ext4_superblock_csum_set_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_superblock_csum_set_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_do_writepages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_do_writepages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 540;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_do_writepages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 540;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_do_writepages_event_t stats_key_v = {};
            struct kernel_ext4_do_writepages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 540;
            stats_key->ip = 540;
        
            
            
            
                        
            struct kernel_ext4_do_writepages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_do_writepages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_readahead_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_readahead_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 541;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_readahead_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 541;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_readahead_event_t stats_key_v = {};
            struct kernel_ext4_readahead_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 541;
            stats_key->ip = 541;
        
            
            
            
                        
            struct kernel_ext4_readahead_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_readahead_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_correct_indexes_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_correct_indexes_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 542;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_correct_indexes_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 542;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_correct_indexes_event_t stats_key_v = {};
            struct kernel_ext4_ext_correct_indexes_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 542;
            stats_key->ip = 542;
        
            
            
            
                        
            struct kernel_ext4_ext_correct_indexes_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_correct_indexes_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_should_fail_bio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_should_fail_bio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 543;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_should_fail_bio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 543;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_should_fail_bio_event_t stats_key_v = {};
            struct kernel_should_fail_bio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 543;
            stats_key->ip = 543;
        
            
            
            
                        
            struct kernel_should_fail_bio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_should_fail_bio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_vmap_small_pages_range_noflush_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_vmap_small_pages_range_noflush_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 544;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_vmap_small_pages_range_noflush_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 544;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_vmap_small_pages_range_noflush_event_t stats_key_v = {};
            struct kernel_vmap_small_pages_range_noflush_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 544;
            stats_key->ip = 544;
        
            
            
            
                        
            struct kernel_vmap_small_pages_range_noflush_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_vmap_small_pages_range_noflush_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_sb_breadahead_unmovable_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_sb_breadahead_unmovable_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 545;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_sb_breadahead_unmovable_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 545;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_sb_breadahead_unmovable_event_t stats_key_v = {};
            struct kernel_ext4_sb_breadahead_unmovable_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 545;
            stats_key->ip = 545;
        
            
            
            
                        
            struct kernel_ext4_sb_breadahead_unmovable_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_sb_breadahead_unmovable_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_get_read_batch_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_get_read_batch_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 546;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_get_read_batch_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 546;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_get_read_batch_event_t stats_key_v = {};
            struct kernel_filemap_get_read_batch_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 546;
            stats_key->ip = 546;
        
            
            
            
                        
            struct kernel_filemap_get_read_batch_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_get_read_batch_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_release_io_end_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_release_io_end_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 547;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_release_io_end_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 547;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_release_io_end_event_t stats_key_v = {};
            struct kernel_ext4_release_io_end_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 547;
            stats_key->ip = 547;
        
            
            
            
                        
            struct kernel_ext4_release_io_end_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_release_io_end_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mark_iloc_dirty_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mark_iloc_dirty_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 548;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mark_iloc_dirty_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 548;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mark_iloc_dirty_event_t stats_key_v = {};
            struct kernel_ext4_mark_iloc_dirty_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 548;
            stats_key->ip = 548;
        
            
            
            
                        
            struct kernel_ext4_mark_iloc_dirty_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mark_iloc_dirty_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_security_file_alloc_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_security_file_alloc_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 549;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_security_file_alloc_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 549;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_security_file_alloc_event_t stats_key_v = {};
            struct kernel_security_file_alloc_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 549;
            stats_key->ip = 549;
        
            
            
            
                        
            struct kernel_security_file_alloc_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_security_file_alloc_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_security_file_permission_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_security_file_permission_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 550;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_security_file_permission_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 550;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_security_file_permission_event_t stats_key_v = {};
            struct kernel_security_file_permission_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 550;
            stats_key->ip = 550;
        
            
            
            
                        
            struct kernel_security_file_permission_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_security_file_permission_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_alloc_file_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_alloc_file_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 551;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_alloc_file_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 551;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_alloc_file_event_t stats_key_v = {};
            struct kernel_alloc_file_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 551;
            stats_key->ip = 551;
        
            
            
            
                        
            struct kernel_alloc_file_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_alloc_file_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_mark_inode_dirty_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_mark_inode_dirty_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 552;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_mark_inode_dirty_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 552;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_mark_inode_dirty_event_t stats_key_v = {};
            struct kernel___ext4_mark_inode_dirty_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 552;
            stats_key->ip = 552;
        
            
            
            
                        
            struct kernel___ext4_mark_inode_dirty_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_mark_inode_dirty_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_free_unref_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_free_unref_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 553;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_free_unref_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 553;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_free_unref_page_event_t stats_key_v = {};
            struct kernel_free_unref_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 553;
            stats_key->ip = 553;
        
            
            
            
                        
            struct kernel_free_unref_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_free_unref_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_rmapping_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_rmapping_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 554;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_rmapping_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 554;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_rmapping_event_t stats_key_v = {};
            struct kernel_page_rmapping_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 554;
            stats_key->ip = 554;
        
            
            
            
                        
            struct kernel_page_rmapping_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_rmapping_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_fc_track_inode_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_fc_track_inode_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 555;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_fc_track_inode_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 555;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_fc_track_inode_event_t stats_key_v = {};
            struct kernel_ext4_fc_track_inode_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 555;
            stats_key->ip = 555;
        
            
            
            
                        
            struct kernel_ext4_fc_track_inode_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_fc_track_inode_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_free_in_core_inode_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_free_in_core_inode_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 556;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_free_in_core_inode_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 556;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_free_in_core_inode_event_t stats_key_v = {};
            struct kernel_ext4_free_in_core_inode_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 556;
            stats_key->ip = 556;
        
            
            
            
                        
            struct kernel_ext4_free_in_core_inode_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_free_in_core_inode_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_khugepaged_enter_vma_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_khugepaged_enter_vma_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 557;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_khugepaged_enter_vma_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 557;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_khugepaged_enter_vma_event_t stats_key_v = {};
            struct kernel_khugepaged_enter_vma_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 557;
            stats_key->ip = 557;
        
            
            
            
                        
            struct kernel_khugepaged_enter_vma_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_khugepaged_enter_vma_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_dma_unmap_page_attrs_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_dma_unmap_page_attrs_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 558;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_dma_unmap_page_attrs_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 558;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_dma_unmap_page_attrs_event_t stats_key_v = {};
            struct kernel_dma_unmap_page_attrs_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 558;
            stats_key->ip = 558;
        
            
            
            
                        
            struct kernel_dma_unmap_page_attrs_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_dma_unmap_page_attrs_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_llseek_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_llseek_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 559;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_llseek_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 559;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_llseek_event_t stats_key_v = {};
            struct kernel_ext4_llseek_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 559;
            stats_key->ip = 559;
        
            
            
            
                        
            struct kernel_ext4_llseek_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_llseek_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_blk_mq_submit_bio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_blk_mq_submit_bio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 560;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_blk_mq_submit_bio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 560;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_blk_mq_submit_bio_event_t stats_key_v = {};
            struct kernel_blk_mq_submit_bio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 560;
            stats_key->ip = 560;
        
            
            
            
                        
            struct kernel_blk_mq_submit_bio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_blk_mq_submit_bio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_locks_check_ctx_file_list_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_locks_check_ctx_file_list_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 561;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_locks_check_ctx_file_list_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 561;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_locks_check_ctx_file_list_event_t stats_key_v = {};
            struct kernel_locks_check_ctx_file_list_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 561;
            stats_key->ip = 561;
        
            
            
            
                        
            struct kernel_locks_check_ctx_file_list_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_locks_check_ctx_file_list_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_generic_write_checks_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_generic_write_checks_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 562;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_generic_write_checks_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 562;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_generic_write_checks_event_t stats_key_v = {};
            struct kernel_ext4_generic_write_checks_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 562;
            stats_key->ip = 562;
        
            
            
            
                        
            struct kernel_ext4_generic_write_checks_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_generic_write_checks_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_insert_dentry_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_insert_dentry_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 563;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_insert_dentry_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 563;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_insert_dentry_event_t stats_key_v = {};
            struct kernel_ext4_insert_dentry_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 563;
            stats_key->ip = 563;
        
            
            
            
                        
            struct kernel_ext4_insert_dentry_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_insert_dentry_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_clear_bb_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_clear_bb_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 564;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_clear_bb_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 564;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_clear_bb_event_t stats_key_v = {};
            struct kernel_ext4_mb_clear_bb_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 564;
            stats_key->ip = 564;
        
            
            
            
                        
            struct kernel_ext4_mb_clear_bb_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_clear_bb_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_migrate_misplaced_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_migrate_misplaced_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 565;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_migrate_misplaced_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 565;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_migrate_misplaced_page_event_t stats_key_v = {};
            struct kernel_migrate_misplaced_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 565;
            stats_key->ip = 565;
        
            
            
            
                        
            struct kernel_migrate_misplaced_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_migrate_misplaced_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_fc_track_range_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_fc_track_range_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 566;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_fc_track_range_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 566;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_fc_track_range_event_t stats_key_v = {};
            struct kernel_ext4_fc_track_range_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 566;
            stats_key->ip = 566;
        
            
            
            
                        
            struct kernel_ext4_fc_track_range_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_fc_track_range_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_fname_setup_filename_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_fname_setup_filename_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 567;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_fname_setup_filename_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 567;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_fname_setup_filename_event_t stats_key_v = {};
            struct kernel_ext4_fname_setup_filename_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 567;
            stats_key->ip = 567;
        
            
            
            
                        
            struct kernel_ext4_fname_setup_filename_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_fname_setup_filename_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_use_best_found_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_use_best_found_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 568;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_use_best_found_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 568;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_use_best_found_event_t stats_key_v = {};
            struct kernel_ext4_mb_use_best_found_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 568;
            stats_key->ip = 568;
        
            
            
            
                        
            struct kernel_ext4_mb_use_best_found_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_use_best_found_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_itable_unused_set_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_itable_unused_set_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 569;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_itable_unused_set_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 569;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_itable_unused_set_event_t stats_key_v = {};
            struct kernel_ext4_itable_unused_set_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 569;
            stats_key->ip = 569;
        
            
            
            
                        
            struct kernel_ext4_itable_unused_set_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_itable_unused_set_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_cap_mmap_file_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_cap_mmap_file_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 570;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_cap_mmap_file_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 570;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_cap_mmap_file_event_t stats_key_v = {};
            struct kernel_cap_mmap_file_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 570;
            stats_key->ip = 570;
        
            
            
            
                        
            struct kernel_cap_mmap_file_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_cap_mmap_file_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4fs_dirhash_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4fs_dirhash_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 571;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4fs_dirhash_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 571;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4fs_dirhash_event_t stats_key_v = {};
            struct kernel_ext4fs_dirhash_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 571;
            stats_key->ip = 571;
        
            
            
            
                        
            struct kernel_ext4fs_dirhash_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4fs_dirhash_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_file_write_and_wait_range_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_file_write_and_wait_range_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 572;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_file_write_and_wait_range_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 572;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_file_write_and_wait_range_event_t stats_key_v = {};
            struct kernel_file_write_and_wait_range_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 572;
            stats_key->ip = 572;
        
            
            
            
                        
            struct kernel_file_write_and_wait_range_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_file_write_and_wait_range_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_pagerange_is_ram_callback_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_pagerange_is_ram_callback_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 573;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_pagerange_is_ram_callback_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 573;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_pagerange_is_ram_callback_event_t stats_key_v = {};
            struct kernel_pagerange_is_ram_callback_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 573;
            stats_key->ip = 573;
        
            
            
            
                        
            struct kernel_pagerange_is_ram_callback_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_pagerange_is_ram_callback_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___alloc_pages_bulk_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___alloc_pages_bulk_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 574;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___alloc_pages_bulk_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 574;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___alloc_pages_bulk_event_t stats_key_v = {};
            struct kernel___alloc_pages_bulk_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 574;
            stats_key->ip = 574;
        
            
            
            
                        
            struct kernel___alloc_pages_bulk_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___alloc_pages_bulk_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_xattr_inode_array_free_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_xattr_inode_array_free_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 575;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_xattr_inode_array_free_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 575;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_xattr_inode_array_free_event_t stats_key_v = {};
            struct kernel_ext4_xattr_inode_array_free_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 575;
            stats_key->ip = 575;
        
            
            
            
                        
            struct kernel_ext4_xattr_inode_array_free_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_xattr_inode_array_free_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_iov_iter_get_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_iov_iter_get_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 576;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_iov_iter_get_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 576;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_iov_iter_get_pages_event_t stats_key_v = {};
            struct kernel_bio_iov_iter_get_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 576;
            stats_key->ip = 576;
        
            
            
            
                        
            struct kernel_bio_iov_iter_get_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_iov_iter_get_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_check_dir_entry_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_check_dir_entry_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 577;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_check_dir_entry_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 577;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_check_dir_entry_event_t stats_key_v = {};
            struct kernel___ext4_check_dir_entry_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 577;
            stats_key->ip = 577;
        
            
            
            
                        
            struct kernel___ext4_check_dir_entry_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_check_dir_entry_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_from_vfsuid_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_from_vfsuid_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 578;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_from_vfsuid_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 578;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_from_vfsuid_event_t stats_key_v = {};
            struct kernel_from_vfsuid_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 578;
            stats_key->ip = 578;
        
            
            
            
                        
            struct kernel_from_vfsuid_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_from_vfsuid_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_endio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_endio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 579;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_endio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 579;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_endio_event_t stats_key_v = {};
            struct kernel_bio_endio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 579;
            stats_key->ip = 579;
        
            
            
            
                        
            struct kernel_bio_endio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_endio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_make_vfsuid_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_make_vfsuid_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 580;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_make_vfsuid_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 580;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_make_vfsuid_event_t stats_key_v = {};
            struct kernel_make_vfsuid_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 580;
            stats_key->ip = 580;
        
            
            
            
                        
            struct kernel_make_vfsuid_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_make_vfsuid_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_mark_diskspace_used_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_mark_diskspace_used_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 581;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_mark_diskspace_used_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 581;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_mark_diskspace_used_event_t stats_key_v = {};
            struct kernel_ext4_mb_mark_diskspace_used_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 581;
            stats_key->ip = 581;
        
            
            
            
                        
            struct kernel_ext4_mb_mark_diskspace_used_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_mark_diskspace_used_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_index_trans_blocks_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_index_trans_blocks_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 582;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_index_trans_blocks_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 582;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_index_trans_blocks_event_t stats_key_v = {};
            struct kernel_ext4_ext_index_trans_blocks_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 582;
            stats_key->ip = 582;
        
            
            
            
                        
            struct kernel_ext4_ext_index_trans_blocks_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_index_trans_blocks_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___ext4_find_entry_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___ext4_find_entry_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 583;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___ext4_find_entry_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 583;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___ext4_find_entry_event_t stats_key_v = {};
            struct kernel___ext4_find_entry_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 583;
            stats_key->ip = 583;
        
            
            
            
                        
            struct kernel___ext4_find_entry_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___ext4_find_entry_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_attempt_back_merge_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_attempt_back_merge_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 584;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_attempt_back_merge_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 584;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_attempt_back_merge_event_t stats_key_v = {};
            struct kernel_bio_attempt_back_merge_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 584;
            stats_key->ip = 584;
        
            
            
            
                        
            struct kernel_bio_attempt_back_merge_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_attempt_back_merge_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_bio_integrity_prep_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_bio_integrity_prep_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 585;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_bio_integrity_prep_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 585;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_bio_integrity_prep_event_t stats_key_v = {};
            struct kernel_bio_integrity_prep_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 585;
            stats_key->ip = 585;
        
            
            
            
                        
            struct kernel_bio_integrity_prep_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_bio_integrity_prep_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_kernfs_file_read_iter_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_kernfs_file_read_iter_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 586;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_kernfs_file_read_iter_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 586;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_kernfs_file_read_iter_event_t stats_key_v = {};
            struct kernel_kernfs_file_read_iter_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 586;
            stats_key->ip = 586;
        
            
            
            
                        
            struct kernel_kernfs_file_read_iter_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_kernfs_file_read_iter_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_mpage_end_io_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_mpage_end_io_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 587;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_mpage_end_io_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 587;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_mpage_end_io_event_t stats_key_v = {};
            struct kernel_mpage_end_io_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 587;
            stats_key->ip = 587;
        
            
            
            
                        
            struct kernel_mpage_end_io_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_mpage_end_io_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_mark_pa_deleted_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_mark_pa_deleted_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 588;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_mark_pa_deleted_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 588;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_mark_pa_deleted_event_t stats_key_v = {};
            struct kernel_ext4_mb_mark_pa_deleted_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 588;
            stats_key->ip = 588;
        
            
            
            
                        
            struct kernel_ext4_mb_mark_pa_deleted_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_mark_pa_deleted_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_inode_bitmap_csum_set_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_inode_bitmap_csum_set_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 589;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_inode_bitmap_csum_set_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 589;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_inode_bitmap_csum_set_event_t stats_key_v = {};
            struct kernel_ext4_inode_bitmap_csum_set_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 589;
            stats_key->ip = 589;
        
            
            
            
                        
            struct kernel_ext4_inode_bitmap_csum_set_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_inode_bitmap_csum_set_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_simple_scan_group_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_simple_scan_group_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 590;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_simple_scan_group_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 590;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_simple_scan_group_event_t stats_key_v = {};
            struct kernel_ext4_mb_simple_scan_group_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 590;
            stats_key->ip = 590;
        
            
            
            
                        
            struct kernel_ext4_mb_simple_scan_group_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_simple_scan_group_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_wp_page_copy_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_wp_page_copy_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 591;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_wp_page_copy_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 591;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_wp_page_copy_event_t stats_key_v = {};
            struct kernel_wp_page_copy_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 591;
            stats_key->ip = 591;
        
            
            
            
                        
            struct kernel_wp_page_copy_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_wp_page_copy_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_init_block_bitmap_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_init_block_bitmap_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 592;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_init_block_bitmap_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 592;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_init_block_bitmap_event_t stats_key_v = {};
            struct kernel_ext4_init_block_bitmap_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 592;
            stats_key->ip = 592;
        
            
            
            
                        
            struct kernel_ext4_init_block_bitmap_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_init_block_bitmap_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_follow_page_pte_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_follow_page_pte_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 593;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_follow_page_pte_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 593;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_follow_page_pte_event_t stats_key_v = {};
            struct kernel_follow_page_pte_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 593;
            stats_key->ip = 593;
        
            
            
            
                        
            struct kernel_follow_page_pte_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_follow_page_pte_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_bg_has_super_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_bg_has_super_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 594;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_bg_has_super_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 594;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_bg_has_super_event_t stats_key_v = {};
            struct kernel_ext4_bg_has_super_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 594;
            stats_key->ip = 594;
        
            
            
            
                        
            struct kernel_ext4_bg_has_super_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_bg_has_super_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_initialize_context_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_initialize_context_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 595;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_initialize_context_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 595;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_initialize_context_event_t stats_key_v = {};
            struct kernel_ext4_mb_initialize_context_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 595;
            stats_key->ip = 595;
        
            
            
            
                        
            struct kernel_ext4_mb_initialize_context_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_initialize_context_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_ext_truncate_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_ext_truncate_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 596;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_ext_truncate_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 596;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_ext_truncate_event_t stats_key_v = {};
            struct kernel_ext4_ext_truncate_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 596;
            stats_key->ip = 596;
        
            
            
            
                        
            struct kernel_ext4_ext_truncate_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_ext_truncate_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_file_ns_capable_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_file_ns_capable_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 597;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_file_ns_capable_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 597;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_file_ns_capable_event_t stats_key_v = {};
            struct kernel_file_ns_capable_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 597;
            stats_key->ip = 597;
        
            
            
            
                        
            struct kernel_file_ns_capable_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_file_ns_capable_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_blk_cgroup_bio_start_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_blk_cgroup_bio_start_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 598;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_blk_cgroup_bio_start_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 598;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_blk_cgroup_bio_start_event_t stats_key_v = {};
            struct kernel_blk_cgroup_bio_start_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 598;
            stats_key->ip = 598;
        
            
            
            
                        
            struct kernel_blk_cgroup_bio_start_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_blk_cgroup_bio_start_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_find_by_goal_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_find_by_goal_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 599;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_find_by_goal_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 599;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_find_by_goal_event_t stats_key_v = {};
            struct kernel_ext4_mb_find_by_goal_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 599;
            stats_key->ip = 599;
        
            
            
            
                        
            struct kernel_ext4_mb_find_by_goal_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_find_by_goal_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_release_dir_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_release_dir_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 600;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_release_dir_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 600;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_release_dir_event_t stats_key_v = {};
            struct kernel_ext4_release_dir_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 600;
            stats_key->ip = 600;
        
            
            
            
                        
            struct kernel_ext4_release_dir_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_release_dir_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_read_bh_nowait_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_read_bh_nowait_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 601;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_read_bh_nowait_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 601;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_read_bh_nowait_event_t stats_key_v = {};
            struct kernel_ext4_read_bh_nowait_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 601;
            stats_key->ip = 601;
        
            
            
            
                        
            struct kernel_ext4_read_bh_nowait_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_read_bh_nowait_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_mpage_map_one_extent_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_mpage_map_one_extent_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 602;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_mpage_map_one_extent_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 602;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_mpage_map_one_extent_event_t stats_key_v = {};
            struct kernel_mpage_map_one_extent_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 602;
            stats_key->ip = 602;
        
            
            
            
                        
            struct kernel_mpage_map_one_extent_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_mpage_map_one_extent_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_fscrypt_set_bio_crypt_ctx_bh_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_fscrypt_set_bio_crypt_ctx_bh_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 603;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_fscrypt_set_bio_crypt_ctx_bh_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 603;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_fscrypt_set_bio_crypt_ctx_bh_event_t stats_key_v = {};
            struct kernel_fscrypt_set_bio_crypt_ctx_bh_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 603;
            stats_key->ip = 603;
        
            
            
            
                        
            struct kernel_fscrypt_set_bio_crypt_ctx_bh_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_fscrypt_set_bio_crypt_ctx_bh_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_schedule_page_work_fn_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_schedule_page_work_fn_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 604;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_schedule_page_work_fn_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 604;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_schedule_page_work_fn_event_t stats_key_v = {};
            struct kernel_schedule_page_work_fn_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 604;
            stats_key->ip = 604;
        
            
            
            
                        
            struct kernel_schedule_page_work_fn_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_schedule_page_work_fn_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___vfs_getxattr_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___vfs_getxattr_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 605;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___vfs_getxattr_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 605;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___vfs_getxattr_event_t stats_key_v = {};
            struct kernel___vfs_getxattr_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 605;
            stats_key->ip = 605;
        
            
            
            
                        
            struct kernel___vfs_getxattr_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___vfs_getxattr_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_mb_load_buddy_gfp_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_mb_load_buddy_gfp_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 606;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_mb_load_buddy_gfp_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 606;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_mb_load_buddy_gfp_event_t stats_key_v = {};
            struct kernel_ext4_mb_load_buddy_gfp_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 606;
            stats_key->ip = 606;
        
            
            
            
                        
            struct kernel_ext4_mb_load_buddy_gfp_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_mb_load_buddy_gfp_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_vm_normal_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_vm_normal_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 607;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_vm_normal_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 607;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_vm_normal_page_event_t stats_key_v = {};
            struct kernel_vm_normal_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 607;
            stats_key->ip = 607;
        
            
            
            
                        
            struct kernel_vm_normal_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_vm_normal_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_group_desc_csum_set_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_group_desc_csum_set_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 608;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_group_desc_csum_set_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 608;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_group_desc_csum_set_event_t stats_key_v = {};
            struct kernel_ext4_group_desc_csum_set_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 608;
            stats_key->ip = 608;
        
            
            
            
                        
            struct kernel_ext4_group_desc_csum_set_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_group_desc_csum_set_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_es_cache_extent_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_es_cache_extent_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 609;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_es_cache_extent_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 609;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_es_cache_extent_event_t stats_key_v = {};
            struct kernel_ext4_es_cache_extent_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 609;
            stats_key->ip = 609;
        
            
            
            
                        
            struct kernel_ext4_es_cache_extent_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_es_cache_extent_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_find_timens_vvar_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_find_timens_vvar_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 610;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_find_timens_vvar_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 610;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_find_timens_vvar_page_event_t stats_key_v = {};
            struct kernel_find_timens_vvar_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 610;
            stats_key->ip = 610;
        
            
            
            
                        
            struct kernel_find_timens_vvar_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_find_timens_vvar_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_apparmor_file_alloc_security_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_apparmor_file_alloc_security_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 611;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_apparmor_file_alloc_security_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 611;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_apparmor_file_alloc_security_event_t stats_key_v = {};
            struct kernel_apparmor_file_alloc_security_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 611;
            stats_key->ip = 611;
        
            
            
            
                        
            struct kernel_apparmor_file_alloc_security_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_apparmor_file_alloc_security_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_block_write_end_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_block_write_end_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 612;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_block_write_end_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 612;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_block_write_end_event_t stats_key_v = {};
            struct kernel_block_write_end_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 612;
            stats_key->ip = 612;
        
            
            
            
                        
            struct kernel_block_write_end_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_block_write_end_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_read_pages_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_read_pages_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 613;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_read_pages_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 613;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_read_pages_event_t stats_key_v = {};
            struct kernel_read_pages_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 613;
            stats_key->ip = 613;
        
            
            
            
                        
            struct kernel_read_pages_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_read_pages_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_show_vfsmnt_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_show_vfsmnt_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 614;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_show_vfsmnt_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 614;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_show_vfsmnt_event_t stats_key_v = {};
            struct kernel_show_vfsmnt_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 614;
            stats_key->ip = 614;
        
            
            
            
                        
            struct kernel_show_vfsmnt_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_show_vfsmnt_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_elv_bio_merge_ok_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_elv_bio_merge_ok_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 615;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_elv_bio_merge_ok_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 615;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_elv_bio_merge_ok_event_t stats_key_v = {};
            struct kernel_elv_bio_merge_ok_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 615;
            stats_key->ip = 615;
        
            
            
            
                        
            struct kernel_elv_bio_merge_ok_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_elv_bio_merge_ok_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_filemap_remove_folio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_filemap_remove_folio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 616;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_filemap_remove_folio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 616;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_filemap_remove_folio_event_t stats_key_v = {};
            struct kernel_filemap_remove_folio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 616;
            stats_key->ip = 616;
        
            
            
            
                        
            struct kernel_filemap_remove_folio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_filemap_remove_folio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_generic_file_llseek_size_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_generic_file_llseek_size_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 617;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_generic_file_llseek_size_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 617;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_generic_file_llseek_size_event_t stats_key_v = {};
            struct kernel_generic_file_llseek_size_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 617;
            stats_key->ip = 617;
        
            
            
            
                        
            struct kernel_generic_file_llseek_size_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_generic_file_llseek_size_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_kblockd_mod_delayed_work_on_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_kblockd_mod_delayed_work_on_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 618;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_kblockd_mod_delayed_work_on_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 618;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_kblockd_mod_delayed_work_on_event_t stats_key_v = {};
            struct kernel_kblockd_mod_delayed_work_on_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 618;
            stats_key->ip = 618;
        
            
            
            
                        
            struct kernel_kblockd_mod_delayed_work_on_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_kblockd_mod_delayed_work_on_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_blk_mq_attempt_bio_merge_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_blk_mq_attempt_bio_merge_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 619;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_blk_mq_attempt_bio_merge_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 619;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_blk_mq_attempt_bio_merge_event_t stats_key_v = {};
            struct kernel_blk_mq_attempt_bio_merge_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 619;
            stats_key->ip = 619;
        
            
            
            
                        
            struct kernel_blk_mq_attempt_bio_merge_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_blk_mq_attempt_bio_merge_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_find_dest_de_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_find_dest_de_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 620;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_find_dest_de_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 620;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_find_dest_de_event_t stats_key_v = {};
            struct kernel_ext4_find_dest_de_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 620;
            stats_key->ip = 620;
        
            
            
            
                        
            struct kernel_ext4_find_dest_de_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_find_dest_de_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_inode_to_goal_block_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_inode_to_goal_block_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 621;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_inode_to_goal_block_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 621;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_inode_to_goal_block_event_t stats_key_v = {};
            struct kernel_ext4_inode_to_goal_block_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 621;
            stats_key->ip = 621;
        
            
            
            
                        
            struct kernel_ext4_inode_to_goal_block_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_inode_to_goal_block_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_alloc_inode_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_alloc_inode_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 622;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_alloc_inode_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 622;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_alloc_inode_event_t stats_key_v = {};
            struct kernel_ext4_alloc_inode_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 622;
            stats_key->ip = 622;
        
            
            
            
                        
            struct kernel_ext4_alloc_inode_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_alloc_inode_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_file_ra_state_init_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_file_ra_state_init_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 623;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_file_ra_state_init_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 623;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_file_ra_state_init_event_t stats_key_v = {};
            struct kernel_file_ra_state_init_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 623;
            stats_key->ip = 623;
        
            
            
            
                        
            struct kernel_file_ra_state_init_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_file_ra_state_init_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_xattr_delete_inode_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_xattr_delete_inode_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 624;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_xattr_delete_inode_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 624;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_xattr_delete_inode_event_t stats_key_v = {};
            struct kernel_ext4_xattr_delete_inode_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 624;
            stats_key->ip = 624;
        
            
            
            
                        
            struct kernel_ext4_xattr_delete_inode_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_xattr_delete_inode_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_jbd2_journal_blocks_per_page_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_jbd2_journal_blocks_per_page_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 625;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_jbd2_journal_blocks_per_page_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 625;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_jbd2_journal_blocks_per_page_event_t stats_key_v = {};
            struct kernel_jbd2_journal_blocks_per_page_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 625;
            stats_key->ip = 625;
        
            
            
            
                        
            struct kernel_jbd2_journal_blocks_per_page_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_jbd2_journal_blocks_per_page_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_fscrypt_limit_io_blocks_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_fscrypt_limit_io_blocks_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 626;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_fscrypt_limit_io_blocks_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 626;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_fscrypt_limit_io_blocks_event_t stats_key_v = {};
            struct kernel_fscrypt_limit_io_blocks_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 626;
            stats_key->ip = 626;
        
            
            
            
                        
            struct kernel_fscrypt_limit_io_blocks_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_fscrypt_limit_io_blocks_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_show_options_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_show_options_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 627;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_show_options_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 627;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_show_options_event_t stats_key_v = {};
            struct kernel_ext4_show_options_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 627;
            stats_key->ip = 627;
        
            
            
            
                        
            struct kernel_ext4_show_options_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_show_options_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_fc_del_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_fc_del_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 628;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_fc_del_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 628;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_fc_del_event_t stats_key_v = {};
            struct kernel_ext4_fc_del_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 628;
            stats_key->ip = 628;
        
            
            
            
                        
            struct kernel_ext4_fc_del_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_fc_del_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_cache_ra_order_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_cache_ra_order_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 629;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_cache_ra_order_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 629;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_cache_ra_order_event_t stats_key_v = {};
            struct kernel_page_cache_ra_order_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 629;
            stats_key->ip = 629;
        
            
            
            
                        
            struct kernel_page_cache_ra_order_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_cache_ra_order_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_page_counter_try_charge_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_page_counter_try_charge_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 630;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_page_counter_try_charge_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 630;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_page_counter_try_charge_event_t stats_key_v = {};
            struct kernel_page_counter_try_charge_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 630;
            stats_key->ip = 630;
        
            
            
            
                        
            struct kernel_page_counter_try_charge_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_page_counter_try_charge_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_locks_move_blocks_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_locks_move_blocks_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 631;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_locks_move_blocks_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 631;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_locks_move_blocks_event_t stats_key_v = {};
            struct kernel_locks_move_blocks_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 631;
            stats_key->ip = 631;
        
            
            
            
                        
            struct kernel_locks_move_blocks_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_locks_move_blocks_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel___filemap_add_folio_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel___filemap_add_folio_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 632;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel___filemap_add_folio_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 632;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel___filemap_add_folio_event_t stats_key_v = {};
            struct kernel___filemap_add_folio_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 632;
            stats_key->ip = 632;
        
            
            
            
                        
            struct kernel___filemap_add_folio_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel___filemap_add_folio_event_t), 0);
            
            return 0;
        }
        
        
        
            struct kernel_ext4_read_block_bitmap_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_kernel_ext4_read_block_bitmap_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 633;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_kernel_ext4_read_block_bitmap_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 633;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct kernel_ext4_read_block_bitmap_event_t stats_key_v = {};
            struct kernel_ext4_read_block_bitmap_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 633;
            stats_key->ip = 633;
        
            
            
            
                        
            struct kernel_ext4_read_block_bitmap_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct kernel_ext4_read_block_bitmap_event_t), 0);
            
            return 0;
        }
        
        
        
            struct os_cache_mark_buffer_dirty_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_os_cache_mark_buffer_dirty_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 634;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_os_cache_mark_buffer_dirty_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 634;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct os_cache_mark_buffer_dirty_event_t stats_key_v = {};
            struct os_cache_mark_buffer_dirty_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 634;
            stats_key->ip = 634;
        
            
            
            
                        
            struct os_cache_mark_buffer_dirty_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct os_cache_mark_buffer_dirty_event_t), 0);
            
            return 0;
        }
        
        
        
            struct os_cache_mark_page_accessed_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_os_cache_mark_page_accessed_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 635;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_os_cache_mark_page_accessed_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 635;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct os_cache_mark_page_accessed_event_t stats_key_v = {};
            struct os_cache_mark_page_accessed_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 635;
            stats_key->ip = 635;
        
            
            
            
                        
            struct os_cache_mark_page_accessed_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct os_cache_mark_page_accessed_event_t), 0);
            
            return 0;
        }
        
        
        
            struct vfs_rw_verify_area_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_vfs_rw_verify_area_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 636;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_vfs_rw_verify_area_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 636;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct vfs_rw_verify_area_event_t stats_key_v = {};
            struct vfs_rw_verify_area_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 636;
            stats_key->ip = 636;
        
            
            
            
                        
            struct vfs_rw_verify_area_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct vfs_rw_verify_area_event_t), 0);
            
            return 0;
        }
        
        
        
            struct vfs_vfs_write_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_vfs_vfs_write_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 637;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_vfs_vfs_write_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 637;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct vfs_vfs_write_event_t stats_key_v = {};
            struct vfs_vfs_write_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 637;
            stats_key->ip = 637;
        
            
            
            
                        
            struct vfs_vfs_write_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct vfs_vfs_write_event_t), 0);
            
            return 0;
        }
        
        
        
            struct vfs_vfs_read_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_vfs_vfs_read_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 638;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_vfs_vfs_read_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 638;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct vfs_vfs_read_event_t stats_key_v = {};
            struct vfs_vfs_read_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 638;
            stats_key->ip = 638;
        
            
            
            
                        
            struct vfs_vfs_read_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct vfs_vfs_read_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_AllocResults_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_AllocResults_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 639;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_AllocResults_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 639;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_AllocResults_event_t stats_key_v = {};
            struct app_AllocResults_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 639;
            stats_key->ip = 639;
        
            
            
            
                        
            struct app_AllocResults_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_AllocResults_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_CreateTest_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_CreateTest_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 640;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_CreateTest_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 640;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_CreateTest_event_t stats_key_v = {};
            struct app_CreateTest_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 640;
            stats_key->ip = 640;
        
            
            
            
                        
            struct app_CreateTest_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_CreateTest_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_CurrentTimeString_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_CurrentTimeString_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 641;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_CurrentTimeString_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 641;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_CurrentTimeString_event_t stats_key_v = {};
            struct app_CurrentTimeString_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 641;
            stats_key->ip = 641;
        
            
            
            
                        
            struct app_CurrentTimeString_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_CurrentTimeString_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_DecodeDirective_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_DecodeDirective_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 642;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_DecodeDirective_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 642;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_DecodeDirective_event_t stats_key_v = {};
            struct app_DecodeDirective_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 642;
            stats_key->ip = 642;
        
            
            
            
                        
            struct app_DecodeDirective_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_DecodeDirective_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_DelaySecs_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_DelaySecs_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 643;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_DelaySecs_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 643;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_DelaySecs_event_t stats_key_v = {};
            struct app_DelaySecs_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 643;
            stats_key->ip = 643;
        
            
            
            
                        
            struct app_DelaySecs_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_DelaySecs_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_DumpBuffer_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_DumpBuffer_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 644;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_DumpBuffer_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 644;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_DumpBuffer_event_t stats_key_v = {};
            struct app_DumpBuffer_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 644;
            stats_key->ip = 644;
        
            
            
            
                        
            struct app_DumpBuffer_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_DumpBuffer_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_ExtractHint_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_ExtractHint_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 645;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_ExtractHint_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 645;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_ExtractHint_event_t stats_key_v = {};
            struct app_ExtractHint_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 645;
            stats_key->ip = 645;
        
            
            
            
                        
            struct app_ExtractHint_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_ExtractHint_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_FailMessage_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_FailMessage_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 646;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_FailMessage_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 646;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_FailMessage_event_t stats_key_v = {};
            struct app_FailMessage_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 646;
            stats_key->ip = 646;
        
            
            
            
                        
            struct app_FailMessage_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_FailMessage_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_FreeResults_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_FreeResults_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 647;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_FreeResults_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 647;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_FreeResults_event_t stats_key_v = {};
            struct app_FreeResults_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 647;
            stats_key->ip = 647;
        
            
            
            
                        
            struct app_FreeResults_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_FreeResults_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_GetNumNodes_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_GetNumNodes_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 648;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_GetNumNodes_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 648;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_GetNumNodes_event_t stats_key_v = {};
            struct app_GetNumNodes_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 648;
            stats_key->ip = 648;
        
            
            
            
                        
            struct app_GetNumNodes_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_GetNumNodes_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_GetNumTasks_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_GetNumTasks_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 649;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_GetNumTasks_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 649;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_GetNumTasks_event_t stats_key_v = {};
            struct app_GetNumTasks_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 649;
            stats_key->ip = 649;
        
            
            
            
                        
            struct app_GetNumTasks_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_GetNumTasks_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_GetNumTasksOnNode0_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_GetNumTasksOnNode0_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 650;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_GetNumTasksOnNode0_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 650;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_GetNumTasksOnNode0_event_t stats_key_v = {};
            struct app_GetNumTasksOnNode0_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 650;
            stats_key->ip = 650;
        
            
            
            
                        
            struct app_GetNumTasksOnNode0_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_GetNumTasksOnNode0_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_GetOffsetArrayRandom_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_GetOffsetArrayRandom_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 651;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_GetOffsetArrayRandom_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 651;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_GetOffsetArrayRandom_event_t stats_key_v = {};
            struct app_GetOffsetArrayRandom_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 651;
            stats_key->ip = 651;
        
            
            
            
                        
            struct app_GetOffsetArrayRandom_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_GetOffsetArrayRandom_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_GetPlatformName_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_GetPlatformName_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 652;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_GetPlatformName_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 652;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_GetPlatformName_event_t stats_key_v = {};
            struct app_GetPlatformName_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 652;
            stats_key->ip = 652;
        
            
            
            
                        
            struct app_GetPlatformName_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_GetPlatformName_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_GetProcessorAndCore_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_GetProcessorAndCore_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 653;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_GetProcessorAndCore_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 653;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_GetProcessorAndCore_event_t stats_key_v = {};
            struct app_GetProcessorAndCore_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 653;
            stats_key->ip = 653;
        
            
            
            
                        
            struct app_GetProcessorAndCore_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_GetProcessorAndCore_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_GetTestFileName_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_GetTestFileName_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 654;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_GetTestFileName_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 654;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_GetTestFileName_event_t stats_key_v = {};
            struct app_GetTestFileName_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 654;
            stats_key->ip = 654;
        
            
            
            
                        
            struct app_GetTestFileName_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_GetTestFileName_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_GetTimeStamp_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_GetTimeStamp_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 655;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_GetTimeStamp_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 655;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_GetTimeStamp_event_t stats_key_v = {};
            struct app_GetTimeStamp_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 655;
            stats_key->ip = 655;
        
            
            
            
                        
            struct app_GetTimeStamp_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_GetTimeStamp_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_HumanReadable_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_HumanReadable_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 656;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_HumanReadable_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 656;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_HumanReadable_event_t stats_key_v = {};
            struct app_HumanReadable_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 656;
            stats_key->ip = 656;
        
            
            
            
                        
            struct app_HumanReadable_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_HumanReadable_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_MPIIO_Access_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_MPIIO_Access_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 657;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_MPIIO_Access_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 657;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_MPIIO_Access_event_t stats_key_v = {};
            struct app_MPIIO_Access_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 657;
            stats_key->ip = 657;
        
            
            
            
                        
            struct app_MPIIO_Access_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_MPIIO_Access_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_MPIIO_Delete_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_MPIIO_Delete_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 658;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_MPIIO_Delete_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 658;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_MPIIO_Delete_event_t stats_key_v = {};
            struct app_MPIIO_Delete_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 658;
            stats_key->ip = 658;
        
            
            
            
                        
            struct app_MPIIO_Delete_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_MPIIO_Delete_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_MPIIO_GetFileSize_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_MPIIO_GetFileSize_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 659;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_MPIIO_GetFileSize_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 659;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_MPIIO_GetFileSize_event_t stats_key_v = {};
            struct app_MPIIO_GetFileSize_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 659;
            stats_key->ip = 659;
        
            
            
            
                        
            struct app_MPIIO_GetFileSize_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_MPIIO_GetFileSize_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_MPIIO_xfer_hints_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_MPIIO_xfer_hints_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 660;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_MPIIO_xfer_hints_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 660;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_MPIIO_xfer_hints_event_t stats_key_v = {};
            struct app_MPIIO_xfer_hints_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 660;
            stats_key->ip = 660;
        
            
            
            
                        
            struct app_MPIIO_xfer_hints_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_MPIIO_xfer_hints_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_NodeMemoryStringToBytes_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_NodeMemoryStringToBytes_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 661;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_NodeMemoryStringToBytes_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 661;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_NodeMemoryStringToBytes_event_t stats_key_v = {};
            struct app_NodeMemoryStringToBytes_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 661;
            stats_key->ip = 661;
        
            
            
            
                        
            struct app_NodeMemoryStringToBytes_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_NodeMemoryStringToBytes_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_OpTimerFlush_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_OpTimerFlush_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 662;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_OpTimerFlush_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 662;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_OpTimerFlush_event_t stats_key_v = {};
            struct app_OpTimerFlush_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 662;
            stats_key->ip = 662;
        
            
            
            
                        
            struct app_OpTimerFlush_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_OpTimerFlush_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_OpTimerFree_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_OpTimerFree_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 663;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_OpTimerFree_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 663;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_OpTimerFree_event_t stats_key_v = {};
            struct app_OpTimerFree_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 663;
            stats_key->ip = 663;
        
            
            
            
                        
            struct app_OpTimerFree_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_OpTimerFree_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_OpTimerInit_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_OpTimerInit_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 664;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_OpTimerInit_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 664;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_OpTimerInit_event_t stats_key_v = {};
            struct app_OpTimerInit_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 664;
            stats_key->ip = 664;
        
            
            
            
                        
            struct app_OpTimerInit_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_OpTimerInit_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_OpTimerValue_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_OpTimerValue_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 665;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_OpTimerValue_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 665;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_OpTimerValue_event_t stats_key_v = {};
            struct app_OpTimerValue_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 665;
            stats_key->ip = 665;
        
            
            
            
                        
            struct app_OpTimerValue_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_OpTimerValue_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_POSIX_Close_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_POSIX_Close_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 666;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_POSIX_Close_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 666;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_POSIX_Close_event_t stats_key_v = {};
            struct app_POSIX_Close_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 666;
            stats_key->ip = 666;
        
            
            
            
                        
            struct app_POSIX_Close_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_POSIX_Close_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_POSIX_Create_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_POSIX_Create_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 667;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_POSIX_Create_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 667;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_POSIX_Create_event_t stats_key_v = {};
            struct app_POSIX_Create_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 667;
            stats_key->ip = 667;
        
            
            
            
                        
            struct app_POSIX_Create_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_POSIX_Create_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_POSIX_Delete_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_POSIX_Delete_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 668;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_POSIX_Delete_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 668;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_POSIX_Delete_event_t stats_key_v = {};
            struct app_POSIX_Delete_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 668;
            stats_key->ip = 668;
        
            
            
            
                        
            struct app_POSIX_Delete_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_POSIX_Delete_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_POSIX_Fsync_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_POSIX_Fsync_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 669;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_POSIX_Fsync_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 669;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_POSIX_Fsync_event_t stats_key_v = {};
            struct app_POSIX_Fsync_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 669;
            stats_key->ip = 669;
        
            
            
            
                        
            struct app_POSIX_Fsync_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_POSIX_Fsync_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_POSIX_GetFileSize_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_POSIX_GetFileSize_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 670;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_POSIX_GetFileSize_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 670;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_POSIX_GetFileSize_event_t stats_key_v = {};
            struct app_POSIX_GetFileSize_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 670;
            stats_key->ip = 670;
        
            
            
            
                        
            struct app_POSIX_GetFileSize_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_POSIX_GetFileSize_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_POSIX_Mknod_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_POSIX_Mknod_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 671;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_POSIX_Mknod_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 671;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_POSIX_Mknod_event_t stats_key_v = {};
            struct app_POSIX_Mknod_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 671;
            stats_key->ip = 671;
        
            
            
            
                        
            struct app_POSIX_Mknod_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_POSIX_Mknod_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_POSIX_Open_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_POSIX_Open_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 672;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_POSIX_Open_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 672;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_POSIX_Open_event_t stats_key_v = {};
            struct app_POSIX_Open_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 672;
            stats_key->ip = 672;
        
            
            
            
                        
            struct app_POSIX_Open_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_POSIX_Open_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_POSIX_Rename_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_POSIX_Rename_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 673;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_POSIX_Rename_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 673;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_POSIX_Rename_event_t stats_key_v = {};
            struct app_POSIX_Rename_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 673;
            stats_key->ip = 673;
        
            
            
            
                        
            struct app_POSIX_Rename_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_POSIX_Rename_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_POSIX_Sync_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_POSIX_Sync_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 674;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_POSIX_Sync_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 674;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_POSIX_Sync_event_t stats_key_v = {};
            struct app_POSIX_Sync_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 674;
            stats_key->ip = 674;
        
            
            
            
                        
            struct app_POSIX_Sync_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_POSIX_Sync_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_POSIX_check_params_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_POSIX_check_params_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 675;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_POSIX_check_params_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 675;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_POSIX_check_params_event_t stats_key_v = {};
            struct app_POSIX_check_params_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 675;
            stats_key->ip = 675;
        
            
            
            
                        
            struct app_POSIX_check_params_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_POSIX_check_params_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_POSIX_options_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_POSIX_options_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 676;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_POSIX_options_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 676;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_POSIX_options_event_t stats_key_v = {};
            struct app_POSIX_options_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 676;
            stats_key->ip = 676;
        
            
            
            
                        
            struct app_POSIX_options_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_POSIX_options_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_POSIX_xfer_hints_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_POSIX_xfer_hints_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 677;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_POSIX_xfer_hints_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 677;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_POSIX_xfer_hints_event_t stats_key_v = {};
            struct app_POSIX_xfer_hints_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 677;
            stats_key->ip = 677;
        
            
            
            
                        
            struct app_POSIX_xfer_hints_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_POSIX_xfer_hints_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_ParseCommandLine_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_ParseCommandLine_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 678;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_ParseCommandLine_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 678;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_ParseCommandLine_event_t stats_key_v = {};
            struct app_ParseCommandLine_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 678;
            stats_key->ip = 678;
        
            
            
            
                        
            struct app_ParseCommandLine_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_ParseCommandLine_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_ParseLine_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_ParseLine_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 679;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_ParseLine_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 679;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_ParseLine_event_t stats_key_v = {};
            struct app_ParseLine_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 679;
            stats_key->ip = 679;
        
            
            
            
                        
            struct app_ParseLine_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_ParseLine_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_PrintHeader_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_PrintHeader_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 680;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_PrintHeader_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 680;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_PrintHeader_event_t stats_key_v = {};
            struct app_PrintHeader_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 680;
            stats_key->ip = 680;
        
            
            
            
                        
            struct app_PrintHeader_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_PrintHeader_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_PrintKeyVal_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_PrintKeyVal_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 681;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_PrintKeyVal_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 681;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_PrintKeyVal_event_t stats_key_v = {};
            struct app_PrintKeyVal_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 681;
            stats_key->ip = 681;
        
            
            
            
                        
            struct app_PrintKeyVal_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_PrintKeyVal_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_PrintLongSummaryAllTests_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_PrintLongSummaryAllTests_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 682;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_PrintLongSummaryAllTests_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 682;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_PrintLongSummaryAllTests_event_t stats_key_v = {};
            struct app_PrintLongSummaryAllTests_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 682;
            stats_key->ip = 682;
        
            
            
            
                        
            struct app_PrintLongSummaryAllTests_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_PrintLongSummaryAllTests_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_PrintLongSummaryHeader_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_PrintLongSummaryHeader_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 683;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_PrintLongSummaryHeader_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 683;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_PrintLongSummaryHeader_event_t stats_key_v = {};
            struct app_PrintLongSummaryHeader_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 683;
            stats_key->ip = 683;
        
            
            
            
                        
            struct app_PrintLongSummaryHeader_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_PrintLongSummaryHeader_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_PrintLongSummaryOneTest_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_PrintLongSummaryOneTest_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 684;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_PrintLongSummaryOneTest_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 684;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_PrintLongSummaryOneTest_event_t stats_key_v = {};
            struct app_PrintLongSummaryOneTest_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 684;
            stats_key->ip = 684;
        
            
            
            
                        
            struct app_PrintLongSummaryOneTest_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_PrintLongSummaryOneTest_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_PrintReducedResult_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_PrintReducedResult_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 685;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_PrintReducedResult_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 685;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_PrintReducedResult_event_t stats_key_v = {};
            struct app_PrintReducedResult_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 685;
            stats_key->ip = 685;
        
            
            
            
                        
            struct app_PrintReducedResult_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_PrintReducedResult_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_PrintRemoveTiming_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_PrintRemoveTiming_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 686;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_PrintRemoveTiming_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 686;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_PrintRemoveTiming_event_t stats_key_v = {};
            struct app_PrintRemoveTiming_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 686;
            stats_key->ip = 686;
        
            
            
            
                        
            struct app_PrintRemoveTiming_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_PrintRemoveTiming_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_PrintRepeatEnd_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_PrintRepeatEnd_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 687;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_PrintRepeatEnd_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 687;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_PrintRepeatEnd_event_t stats_key_v = {};
            struct app_PrintRepeatEnd_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 687;
            stats_key->ip = 687;
        
            
            
            
                        
            struct app_PrintRepeatEnd_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_PrintRepeatEnd_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_PrintRepeatStart_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_PrintRepeatStart_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 688;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_PrintRepeatStart_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 688;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_PrintRepeatStart_event_t stats_key_v = {};
            struct app_PrintRepeatStart_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 688;
            stats_key->ip = 688;
        
            
            
            
                        
            struct app_PrintRepeatStart_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_PrintRepeatStart_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_PrintShortSummary_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_PrintShortSummary_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 689;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_PrintShortSummary_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 689;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_PrintShortSummary_event_t stats_key_v = {};
            struct app_PrintShortSummary_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 689;
            stats_key->ip = 689;
        
            
            
            
                        
            struct app_PrintShortSummary_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_PrintShortSummary_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_PrintTableHeader_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_PrintTableHeader_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 690;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_PrintTableHeader_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 690;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_PrintTableHeader_event_t stats_key_v = {};
            struct app_PrintTableHeader_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 690;
            stats_key->ip = 690;
        
            
            
            
                        
            struct app_PrintTableHeader_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_PrintTableHeader_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_PrintTestEnds_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_PrintTestEnds_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 691;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_PrintTestEnds_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 691;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_PrintTestEnds_event_t stats_key_v = {};
            struct app_PrintTestEnds_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 691;
            stats_key->ip = 691;
        
            
            
            
                        
            struct app_PrintTestEnds_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_PrintTestEnds_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_PrintTimestamp_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_PrintTimestamp_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 692;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_PrintTimestamp_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 692;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_PrintTimestamp_event_t stats_key_v = {};
            struct app_PrintTimestamp_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 692;
            stats_key->ip = 692;
        
            
            
            
                        
            struct app_PrintTimestamp_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_PrintTimestamp_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_QueryNodeMapping_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_QueryNodeMapping_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 693;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_QueryNodeMapping_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 693;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_QueryNodeMapping_event_t stats_key_v = {};
            struct app_QueryNodeMapping_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 693;
            stats_key->ip = 693;
        
            
            
            
                        
            struct app_QueryNodeMapping_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_QueryNodeMapping_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_ReadConfigScript_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_ReadConfigScript_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 694;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_ReadConfigScript_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 694;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_ReadConfigScript_event_t stats_key_v = {};
            struct app_ReadConfigScript_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 694;
            stats_key->ip = 694;
        
            
            
            
                        
            struct app_ReadConfigScript_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_ReadConfigScript_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_ReadStoneWallingIterations_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_ReadStoneWallingIterations_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 695;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_ReadStoneWallingIterations_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 695;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_ReadStoneWallingIterations_event_t stats_key_v = {};
            struct app_ReadStoneWallingIterations_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 695;
            stats_key->ip = 695;
        
            
            
            
                        
            struct app_ReadStoneWallingIterations_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_ReadStoneWallingIterations_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_Regex_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_Regex_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 696;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_Regex_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 696;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_Regex_event_t stats_key_v = {};
            struct app_Regex_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 696;
            stats_key->ip = 696;
        
            
            
            
                        
            struct app_Regex_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_Regex_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_SetHints_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_SetHints_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 697;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_SetHints_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 697;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_SetHints_event_t stats_key_v = {};
            struct app_SetHints_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 697;
            stats_key->ip = 697;
        
            
            
            
                        
            struct app_SetHints_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_SetHints_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_ShowFileSystemSize_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_ShowFileSystemSize_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 698;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_ShowFileSystemSize_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 698;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_ShowFileSystemSize_event_t stats_key_v = {};
            struct app_ShowFileSystemSize_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 698;
            stats_key->ip = 698;
        
            
            
            
                        
            struct app_ShowFileSystemSize_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_ShowFileSystemSize_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_ShowHints_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_ShowHints_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 699;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_ShowHints_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 699;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_ShowHints_event_t stats_key_v = {};
            struct app_ShowHints_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 699;
            stats_key->ip = 699;
        
            
            
            
                        
            struct app_ShowHints_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_ShowHints_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_ShowSetup_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_ShowSetup_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 700;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_ShowSetup_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 700;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_ShowSetup_event_t stats_key_v = {};
            struct app_ShowSetup_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 700;
            stats_key->ip = 700;
        
            
            
            
                        
            struct app_ShowSetup_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_ShowSetup_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_ShowTestEnd_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_ShowTestEnd_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 701;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_ShowTestEnd_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 701;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_ShowTestEnd_event_t stats_key_v = {};
            struct app_ShowTestEnd_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 701;
            stats_key->ip = 701;
        
            
            
            
                        
            struct app_ShowTestEnd_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_ShowTestEnd_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_ShowTestStart_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_ShowTestStart_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 702;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_ShowTestStart_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 702;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_ShowTestStart_event_t stats_key_v = {};
            struct app_ShowTestStart_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 702;
            stats_key->ip = 702;
        
            
            
            
                        
            struct app_ShowTestStart_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_ShowTestStart_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_StoreStoneWallingIterations_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_StoreStoneWallingIterations_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 703;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_StoreStoneWallingIterations_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 703;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_StoreStoneWallingIterations_event_t stats_key_v = {};
            struct app_StoreStoneWallingIterations_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 703;
            stats_key->ip = 703;
        
            
            
            
                        
            struct app_StoreStoneWallingIterations_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_StoreStoneWallingIterations_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_StringToBytes_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_StringToBytes_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 704;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_StringToBytes_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 704;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_StringToBytes_event_t stats_key_v = {};
            struct app_StringToBytes_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 704;
            stats_key->ip = 704;
        
            
            
            
                        
            struct app_StringToBytes_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_StringToBytes_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app__fini_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app__fini_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 705;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app__fini_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 705;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app__fini_event_t stats_key_v = {};
            struct app__fini_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 705;
            stats_key->ip = 705;
        
            
            
            
                        
            struct app__fini_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app__fini_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app__init_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app__init_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 706;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app__init_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 706;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app__init_event_t stats_key_v = {};
            struct app__init_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 706;
            stats_key->ip = 706;
        
            
            
            
                        
            struct app__init_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app__init_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app__start_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app__start_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 707;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app__start_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 707;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app__start_event_t stats_key_v = {};
            struct app__start_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 707;
            stats_key->ip = 707;
        
            
            
            
                        
            struct app__start_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app__start_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_aiori_count_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_aiori_count_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 708;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_aiori_count_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 708;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_aiori_count_event_t stats_key_v = {};
            struct app_aiori_count_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 708;
            stats_key->ip = 708;
        
            
            
            
                        
            struct app_aiori_count_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_aiori_count_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_aiori_default_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_aiori_default_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 709;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_aiori_default_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 709;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_aiori_default_event_t stats_key_v = {};
            struct app_aiori_default_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 709;
            stats_key->ip = 709;
        
            
            
            
                        
            struct app_aiori_default_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_aiori_default_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_aiori_get_version_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_aiori_get_version_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 710;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_aiori_get_version_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 710;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_aiori_get_version_event_t stats_key_v = {};
            struct app_aiori_get_version_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 710;
            stats_key->ip = 710;
        
            
            
            
                        
            struct app_aiori_get_version_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_aiori_get_version_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_aiori_posix_access_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_aiori_posix_access_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 711;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_aiori_posix_access_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 711;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_aiori_posix_access_event_t stats_key_v = {};
            struct app_aiori_posix_access_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 711;
            stats_key->ip = 711;
        
            
            
            
                        
            struct app_aiori_posix_access_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_aiori_posix_access_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_aiori_posix_mkdir_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_aiori_posix_mkdir_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 712;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_aiori_posix_mkdir_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 712;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_aiori_posix_mkdir_event_t stats_key_v = {};
            struct app_aiori_posix_mkdir_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 712;
            stats_key->ip = 712;
        
            
            
            
                        
            struct app_aiori_posix_mkdir_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_aiori_posix_mkdir_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_aiori_posix_rmdir_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_aiori_posix_rmdir_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 713;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_aiori_posix_rmdir_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 713;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_aiori_posix_rmdir_event_t stats_key_v = {};
            struct app_aiori_posix_rmdir_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 713;
            stats_key->ip = 713;
        
            
            
            
                        
            struct app_aiori_posix_rmdir_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_aiori_posix_rmdir_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_aiori_posix_stat_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_aiori_posix_stat_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 714;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_aiori_posix_stat_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 714;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_aiori_posix_stat_event_t stats_key_v = {};
            struct app_aiori_posix_stat_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 714;
            stats_key->ip = 714;
        
            
            
            
                        
            struct app_aiori_posix_stat_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_aiori_posix_stat_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_aiori_posix_statfs_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_aiori_posix_statfs_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 715;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_aiori_posix_statfs_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 715;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_aiori_posix_statfs_event_t stats_key_v = {};
            struct app_aiori_posix_statfs_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 715;
            stats_key->ip = 715;
        
            
            
            
                        
            struct app_aiori_posix_statfs_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_aiori_posix_statfs_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_aiori_select_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_aiori_select_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 716;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_aiori_select_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 716;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_aiori_select_event_t stats_key_v = {};
            struct app_aiori_select_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 716;
            stats_key->ip = 716;
        
            
            
            
                        
            struct app_aiori_select_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_aiori_select_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_aiori_supported_apis_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_aiori_supported_apis_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 717;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_aiori_supported_apis_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 717;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_aiori_supported_apis_event_t stats_key_v = {};
            struct app_aiori_supported_apis_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 717;
            stats_key->ip = 717;
        
            
            
            
                        
            struct app_aiori_supported_apis_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_aiori_supported_apis_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_airoi_create_all_module_options_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_airoi_create_all_module_options_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 718;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_airoi_create_all_module_options_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 718;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_airoi_create_all_module_options_event_t stats_key_v = {};
            struct app_airoi_create_all_module_options_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 718;
            stats_key->ip = 718;
        
            
            
            
                        
            struct app_airoi_create_all_module_options_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_airoi_create_all_module_options_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_airoi_update_module_options_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_airoi_update_module_options_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 719;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_airoi_update_module_options_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 719;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_airoi_update_module_options_event_t stats_key_v = {};
            struct app_airoi_update_module_options_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 719;
            stats_key->ip = 719;
        
            
            
            
                        
            struct app_airoi_update_module_options_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_airoi_update_module_options_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_aligned_buffer_alloc_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_aligned_buffer_alloc_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 720;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_aligned_buffer_alloc_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 720;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_aligned_buffer_alloc_event_t stats_key_v = {};
            struct app_aligned_buffer_alloc_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 720;
            stats_key->ip = 720;
        
            
            
            
                        
            struct app_aligned_buffer_alloc_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_aligned_buffer_alloc_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_aligned_buffer_free_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_aligned_buffer_free_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 721;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_aligned_buffer_free_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 721;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_aligned_buffer_free_event_t stats_key_v = {};
            struct app_aligned_buffer_free_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 721;
            stats_key->ip = 721;
        
            
            
            
                        
            struct app_aligned_buffer_free_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_aligned_buffer_free_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_contains_only_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_contains_only_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 722;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_contains_only_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 722;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_contains_only_event_t stats_key_v = {};
            struct app_contains_only_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 722;
            stats_key->ip = 722;
        
            
            
            
                        
            struct app_contains_only_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_contains_only_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_createGlobalOptions_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_createGlobalOptions_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 723;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_createGlobalOptions_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 723;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_createGlobalOptions_event_t stats_key_v = {};
            struct app_createGlobalOptions_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 723;
            stats_key->ip = 723;
        
            
            
            
                        
            struct app_createGlobalOptions_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_createGlobalOptions_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_generate_memory_pattern_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_generate_memory_pattern_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 724;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_generate_memory_pattern_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 724;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_generate_memory_pattern_event_t stats_key_v = {};
            struct app_generate_memory_pattern_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 724;
            stats_key->ip = 724;
        
            
            
            
                        
            struct app_generate_memory_pattern_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_generate_memory_pattern_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_initCUDA_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_initCUDA_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 725;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_initCUDA_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 725;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_initCUDA_event_t stats_key_v = {};
            struct app_initCUDA_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 725;
            stats_key->ip = 725;
        
            
            
            
                        
            struct app_initCUDA_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_initCUDA_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_init_IOR_Param_t_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_init_IOR_Param_t_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 726;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_init_IOR_Param_t_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 726;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_init_IOR_Param_t_event_t stats_key_v = {};
            struct app_init_IOR_Param_t_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 726;
            stats_key->ip = 726;
        
            
            
            
                        
            struct app_init_IOR_Param_t_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_init_IOR_Param_t_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_init_clock_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_init_clock_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 727;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_init_clock_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 727;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_init_clock_event_t stats_key_v = {};
            struct app_init_clock_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 727;
            stats_key->ip = 727;
        
            
            
            
                        
            struct app_init_clock_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_init_clock_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_invalidate_buffer_pattern_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_invalidate_buffer_pattern_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 728;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_invalidate_buffer_pattern_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 728;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_invalidate_buffer_pattern_event_t stats_key_v = {};
            struct app_invalidate_buffer_pattern_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 728;
            stats_key->ip = 728;
        
            
            
            
                        
            struct app_invalidate_buffer_pattern_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_invalidate_buffer_pattern_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_ior_main_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_ior_main_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 729;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_ior_main_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 729;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_ior_main_event_t stats_key_v = {};
            struct app_ior_main_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 729;
            stats_key->ip = 729;
        
            
            
            
                        
            struct app_ior_main_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_ior_main_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_ior_run_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_ior_run_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 730;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_ior_run_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 730;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_ior_run_event_t stats_key_v = {};
            struct app_ior_run_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 730;
            stats_key->ip = 730;
        
            
            
            
                        
            struct app_ior_run_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_ior_run_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_main_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_main_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 731;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_main_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 731;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_main_event_t stats_key_v = {};
            struct app_main_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 731;
            stats_key->ip = 731;
        
            
            
            
                        
            struct app_main_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_main_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_option_merge_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_option_merge_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 732;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_option_merge_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 732;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_option_merge_event_t stats_key_v = {};
            struct app_option_merge_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 732;
            stats_key->ip = 732;
        
            
            
            
                        
            struct app_option_merge_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_option_merge_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_option_parse_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_option_parse_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 733;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_option_parse_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 733;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_option_parse_event_t stats_key_v = {};
            struct app_option_parse_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 733;
            stats_key->ip = 733;
        
            
            
            
                        
            struct app_option_parse_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_option_parse_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_option_parse_key_value_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_option_parse_key_value_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 734;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_option_parse_key_value_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 734;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_option_parse_key_value_event_t stats_key_v = {};
            struct app_option_parse_key_value_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 734;
            stats_key->ip = 734;
        
            
            
            
                        
            struct app_option_parse_key_value_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_option_parse_key_value_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_option_parse_str_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_option_parse_str_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 735;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_option_parse_str_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 735;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_option_parse_str_event_t stats_key_v = {};
            struct app_option_parse_str_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 735;
            stats_key->ip = 735;
        
            
            
            
                        
            struct app_option_parse_str_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_option_parse_str_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_option_print_current_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_option_print_current_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 736;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_option_print_current_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 736;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_option_print_current_event_t stats_key_v = {};
            struct app_option_print_current_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 736;
            stats_key->ip = 736;
        
            
            
            
                        
            struct app_option_print_current_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_option_print_current_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_option_print_help_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_option_print_help_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 737;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_option_print_help_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 737;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_option_print_help_event_t stats_key_v = {};
            struct app_option_print_help_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 737;
            stats_key->ip = 737;
        
            
            
            
                        
            struct app_option_print_help_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_option_print_help_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_parsePacketType_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_parsePacketType_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 738;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_parsePacketType_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 738;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_parsePacketType_event_t stats_key_v = {};
            struct app_parsePacketType_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 738;
            stats_key->ip = 738;
        
            
            
            
                        
            struct app_parsePacketType_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_parsePacketType_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_safeMalloc_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_safeMalloc_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 739;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_safeMalloc_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 739;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_safeMalloc_event_t stats_key_v = {};
            struct app_safeMalloc_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 739;
            stats_key->ip = 739;
        
            
            
            
                        
            struct app_safeMalloc_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_safeMalloc_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_set_o_direct_flag_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_set_o_direct_flag_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 740;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_set_o_direct_flag_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 740;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_set_o_direct_flag_event_t stats_key_v = {};
            struct app_set_o_direct_flag_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 740;
            stats_key->ip = 740;
        
            
            
            
                        
            struct app_set_o_direct_flag_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_set_o_direct_flag_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_string_to_bytes_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_string_to_bytes_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 741;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_string_to_bytes_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 741;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_string_to_bytes_event_t stats_key_v = {};
            struct app_string_to_bytes_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 741;
            stats_key->ip = 741;
        
            
            
            
                        
            struct app_string_to_bytes_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_string_to_bytes_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_test_time_elapsed_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_test_time_elapsed_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 742;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_test_time_elapsed_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 742;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_test_time_elapsed_event_t stats_key_v = {};
            struct app_test_time_elapsed_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 742;
            stats_key->ip = 742;
        
            
            
            
                        
            struct app_test_time_elapsed_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_test_time_elapsed_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_updateParsedOptions_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_updateParsedOptions_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 743;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_updateParsedOptions_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 743;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_updateParsedOptions_event_t stats_key_v = {};
            struct app_updateParsedOptions_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 743;
            stats_key->ip = 743;
        
            
            
            
                        
            struct app_updateParsedOptions_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_updateParsedOptions_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_update_write_memory_pattern_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_update_write_memory_pattern_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 744;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_update_write_memory_pattern_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 744;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_update_write_memory_pattern_event_t stats_key_v = {};
            struct app_update_write_memory_pattern_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 744;
            stats_key->ip = 744;
        
            
            
            
                        
            struct app_update_write_memory_pattern_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_update_write_memory_pattern_event_t), 0);
            
            return 0;
        }
        
        
        
            struct app_verify_memory_pattern_event_t {                                                       
            u64 id;
            u64 event_id;
            u64 ip;
            u64 ts;                                                                   
            u64 dur;
            
            
        };
        
        
        int trace_app_verify_memory_pattern_entry(struct pt_regs *ctx ) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 745;
            struct fn_t fn = {};
            fn.ts = bpf_ktime_get_ns();
            fn_pid_map.update(&key, &fn);
        
            
            
            
            return 0;
        }

        int trace_app_verify_memory_pattern_exit(struct pt_regs *ctx) {
            
            u64 id = bpf_get_current_pid_tgid();
            u32 pid = id;
            u64* start_ts = pid_map.lookup(&pid);
            if (start_ts == 0 || pid == 0)                                      
                return 0;
        
            
            
            struct fn_key_t key = {};
            key.pid = pid;
            key.ip = 745;
            struct fn_t *fn = fn_pid_map.lookup(&key);
            if (fn == 0) return 0; // missed entry
        
            
            
            struct app_verify_memory_pattern_event_t stats_key_v = {};
            struct app_verify_memory_pattern_event_t *stats_key = &stats_key_v;
            stats_key->id = id;
            stats_key->event_id = 745;
            stats_key->ip = 745;
        
            
            
            
                        
            struct app_verify_memory_pattern_event_t* stats = stats_key;
            stats->ts = (fn->ts  - *start_ts);
            stats->dur = bpf_ktime_get_ns() - fn->ts;
        
            
            
            
            
                events.ringbuf_output(&stats_key_v, sizeof(struct app_verify_memory_pattern_event_t), 0);
            
            return 0;
        }
        